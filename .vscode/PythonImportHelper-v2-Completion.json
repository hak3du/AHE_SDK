[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "environ",
        "importPath": "os",
        "description": "os",
        "isExtraImport": true,
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v9_5",
        "importPath": "core.crypto",
        "description": "core.crypto",
        "isExtraImport": true,
        "detail": "core.crypto",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v9_5",
        "importPath": "core.crypto",
        "description": "core.crypto",
        "isExtraImport": true,
        "detail": "core.crypto",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "stdout",
        "importPath": "sys",
        "description": "sys",
        "isExtraImport": true,
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "stdout",
        "importPath": "sys",
        "description": "sys",
        "isExtraImport": true,
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "stdout",
        "importPath": "sys",
        "description": "sys",
        "isExtraImport": true,
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "stdout",
        "importPath": "sys",
        "description": "sys",
        "isExtraImport": true,
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "hashlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hashlib",
        "description": "hashlib",
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "sha256",
        "importPath": "hashlib",
        "description": "hashlib",
        "isExtraImport": true,
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "sha256",
        "importPath": "hashlib",
        "description": "hashlib",
        "isExtraImport": true,
        "detail": "hashlib",
        "documentation": {}
    },
    {
        "label": "secrets",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "secrets",
        "description": "secrets",
        "detail": "secrets",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "math",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "math",
        "description": "math",
        "detail": "math",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "socket",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "socket",
        "description": "socket",
        "detail": "socket",
        "documentation": {}
    },
    {
        "label": "uuid",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "uuid",
        "description": "uuid",
        "detail": "uuid",
        "documentation": {}
    },
    {
        "label": "hmac",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "hmac",
        "description": "hmac",
        "detail": "hmac",
        "documentation": {}
    },
    {
        "label": "base64",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "base64",
        "description": "base64",
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64encode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "urlsafe_b64decode",
        "importPath": "base64",
        "description": "base64",
        "isExtraImport": true,
        "detail": "base64",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "AES",
        "importPath": "Crypto.Cipher",
        "description": "Crypto.Cipher",
        "isExtraImport": true,
        "detail": "Crypto.Cipher",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "get_random_bytes",
        "importPath": "Crypto.Random",
        "description": "Crypto.Random",
        "isExtraImport": true,
        "detail": "Crypto.Random",
        "documentation": {}
    },
    {
        "label": "hash_secret_raw",
        "importPath": "argon2.low_level",
        "description": "argon2.low_level",
        "isExtraImport": true,
        "detail": "argon2.low_level",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "argon2.low_level",
        "description": "argon2.low_level",
        "isExtraImport": true,
        "detail": "argon2.low_level",
        "documentation": {}
    },
    {
        "label": "hash_secret_raw",
        "importPath": "argon2.low_level",
        "description": "argon2.low_level",
        "isExtraImport": true,
        "detail": "argon2.low_level",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "argon2.low_level",
        "description": "argon2.low_level",
        "isExtraImport": true,
        "detail": "argon2.low_level",
        "documentation": {}
    },
    {
        "label": "hash_secret_raw",
        "importPath": "argon2.low_level",
        "description": "argon2.low_level",
        "isExtraImport": true,
        "detail": "argon2.low_level",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "argon2.low_level",
        "description": "argon2.low_level",
        "isExtraImport": true,
        "detail": "argon2.low_level",
        "documentation": {}
    },
    {
        "label": "hash_secret_raw",
        "importPath": "argon2.low_level",
        "description": "argon2.low_level",
        "isExtraImport": true,
        "detail": "argon2.low_level",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "argon2.low_level",
        "description": "argon2.low_level",
        "isExtraImport": true,
        "detail": "argon2.low_level",
        "documentation": {}
    },
    {
        "label": "hash_secret_raw",
        "importPath": "argon2.low_level",
        "description": "argon2.low_level",
        "isExtraImport": true,
        "detail": "argon2.low_level",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "argon2.low_level",
        "description": "argon2.low_level",
        "isExtraImport": true,
        "detail": "argon2.low_level",
        "documentation": {}
    },
    {
        "label": "hash_secret_raw",
        "importPath": "argon2.low_level",
        "description": "argon2.low_level",
        "isExtraImport": true,
        "detail": "argon2.low_level",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "argon2.low_level",
        "description": "argon2.low_level",
        "isExtraImport": true,
        "detail": "argon2.low_level",
        "documentation": {}
    },
    {
        "label": "hash_secret_raw",
        "importPath": "argon2.low_level",
        "description": "argon2.low_level",
        "isExtraImport": true,
        "detail": "argon2.low_level",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "argon2.low_level",
        "description": "argon2.low_level",
        "isExtraImport": true,
        "detail": "argon2.low_level",
        "documentation": {}
    },
    {
        "label": "hash_secret_raw",
        "importPath": "argon2.low_level",
        "description": "argon2.low_level",
        "isExtraImport": true,
        "detail": "argon2.low_level",
        "documentation": {}
    },
    {
        "label": "Type",
        "importPath": "argon2.low_level",
        "description": "argon2.low_level",
        "isExtraImport": true,
        "detail": "argon2.low_level",
        "documentation": {}
    },
    {
        "label": "oqs",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "oqs",
        "description": "oqs",
        "detail": "oqs",
        "documentation": {}
    },
    {
        "label": "oqs_python_version",
        "importPath": "oqs",
        "description": "oqs",
        "isExtraImport": true,
        "detail": "oqs",
        "documentation": {}
    },
    {
        "label": "oqs_version",
        "importPath": "oqs",
        "description": "oqs",
        "isExtraImport": true,
        "detail": "oqs",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "importPath": "logger",
        "description": "logger",
        "isExtraImport": true,
        "detail": "logger",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "PBKDF2",
        "importPath": "Crypto.Protocol.KDF",
        "description": "Crypto.Protocol.KDF",
        "isExtraImport": true,
        "detail": "Crypto.Protocol.KDF",
        "documentation": {}
    },
    {
        "label": "PBKDF2",
        "importPath": "Crypto.Protocol.KDF",
        "description": "Crypto.Protocol.KDF",
        "isExtraImport": true,
        "detail": "Crypto.Protocol.KDF",
        "documentation": {}
    },
    {
        "label": "PBKDF2",
        "importPath": "Crypto.Protocol.KDF",
        "description": "Crypto.Protocol.KDF",
        "isExtraImport": true,
        "detail": "Crypto.Protocol.KDF",
        "documentation": {}
    },
    {
        "label": "PBKDF2",
        "importPath": "Crypto.Protocol.KDF",
        "description": "Crypto.Protocol.KDF",
        "isExtraImport": true,
        "detail": "Crypto.Protocol.KDF",
        "documentation": {}
    },
    {
        "label": "PBKDF2",
        "importPath": "Crypto.Protocol.KDF",
        "description": "Crypto.Protocol.KDF",
        "isExtraImport": true,
        "detail": "Crypto.Protocol.KDF",
        "documentation": {}
    },
    {
        "label": "HKDF",
        "importPath": "Crypto.Protocol.KDF",
        "description": "Crypto.Protocol.KDF",
        "isExtraImport": true,
        "detail": "Crypto.Protocol.KDF",
        "documentation": {}
    },
    {
        "label": "PBKDF2",
        "importPath": "Crypto.Protocol.KDF",
        "description": "Crypto.Protocol.KDF",
        "isExtraImport": true,
        "detail": "Crypto.Protocol.KDF",
        "documentation": {}
    },
    {
        "label": "PBKDF2",
        "importPath": "Crypto.Protocol.KDF",
        "description": "Crypto.Protocol.KDF",
        "isExtraImport": true,
        "detail": "Crypto.Protocol.KDF",
        "documentation": {}
    },
    {
        "label": "HKDF",
        "importPath": "Crypto.Protocol.KDF",
        "description": "Crypto.Protocol.KDF",
        "isExtraImport": true,
        "detail": "Crypto.Protocol.KDF",
        "documentation": {}
    },
    {
        "label": "PBKDF2",
        "importPath": "Crypto.Protocol.KDF",
        "description": "Crypto.Protocol.KDF",
        "isExtraImport": true,
        "detail": "Crypto.Protocol.KDF",
        "documentation": {}
    },
    {
        "label": "HKDF",
        "importPath": "Crypto.Protocol.KDF",
        "description": "Crypto.Protocol.KDF",
        "isExtraImport": true,
        "detail": "Crypto.Protocol.KDF",
        "documentation": {}
    },
    {
        "label": "HKDF",
        "importPath": "Crypto.Protocol.KDF",
        "description": "Crypto.Protocol.KDF",
        "isExtraImport": true,
        "detail": "Crypto.Protocol.KDF",
        "documentation": {}
    },
    {
        "label": "PBKDF2",
        "importPath": "Crypto.Protocol.KDF",
        "description": "Crypto.Protocol.KDF",
        "isExtraImport": true,
        "detail": "Crypto.Protocol.KDF",
        "documentation": {}
    },
    {
        "label": "PBKDF2",
        "importPath": "Crypto.Protocol.KDF",
        "description": "Crypto.Protocol.KDF",
        "isExtraImport": true,
        "detail": "Crypto.Protocol.KDF",
        "documentation": {}
    },
    {
        "label": "PBKDF2",
        "importPath": "Crypto.Protocol.KDF",
        "description": "Crypto.Protocol.KDF",
        "isExtraImport": true,
        "detail": "Crypto.Protocol.KDF",
        "documentation": {}
    },
    {
        "label": "pytest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pytest",
        "description": "pytest",
        "detail": "pytest",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "importPath": "aes.aes",
        "description": "aes.aes",
        "isExtraImport": true,
        "detail": "aes.aes",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "importPath": "aes.aes",
        "description": "aes.aes",
        "isExtraImport": true,
        "detail": "aes.aes",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "importPath": "aes.aes",
        "description": "aes.aes",
        "isExtraImport": true,
        "detail": "aes.aes",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "importPath": "aes.aes",
        "description": "aes.aes",
        "isExtraImport": true,
        "detail": "aes.aes",
        "documentation": {}
    },
    {
        "label": "encrypt_message",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "decrypt_latest",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "calculate_entropy",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "derive_key",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "encrypt_metadata",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "decrypt_metadata",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "STORAGE_DIR",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v9_5",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "ahe_decrypt_v9_5",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v9_5",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v9_5",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "encrypt_message",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "decrypt_latest",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "encrypt_message",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "decrypt_latest",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "encrypt_message",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "decrypt_latest",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "encrypt_message",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "decrypt_latest",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "calculate_entropy",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "derive_key",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "encrypt_metadata",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "decrypt_metadata",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "STORAGE_DIR",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v9_5",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "ahe_decrypt_v9_5",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v9_5",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v9_5",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "encrypt_message",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "decrypt_latest",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "encrypt_message",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "decrypt_latest",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "encrypt_message",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "decrypt_latest",
        "importPath": "core.core",
        "description": "core.core",
        "isExtraImport": true,
        "detail": "core.core",
        "documentation": {}
    },
    {
        "label": "unittest",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "unittest",
        "description": "unittest",
        "detail": "unittest",
        "documentation": {}
    },
    {
        "label": "detect_anomaly",
        "importPath": "utils.anomaly",
        "description": "utils.anomaly",
        "isExtraImport": true,
        "detail": "utils.anomaly",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_LOW",
        "importPath": "utils.anomaly",
        "description": "utils.anomaly",
        "isExtraImport": true,
        "detail": "utils.anomaly",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_HIGH",
        "importPath": "utils.anomaly",
        "description": "utils.anomaly",
        "isExtraImport": true,
        "detail": "utils.anomaly",
        "documentation": {}
    },
    {
        "label": "detect_anomaly",
        "importPath": "utils.anomaly",
        "description": "utils.anomaly",
        "isExtraImport": true,
        "detail": "utils.anomaly",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_LOW",
        "importPath": "utils.anomaly",
        "description": "utils.anomaly",
        "isExtraImport": true,
        "detail": "utils.anomaly",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_HIGH",
        "importPath": "utils.anomaly",
        "description": "utils.anomaly",
        "isExtraImport": true,
        "detail": "utils.anomaly",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "importPath": "crypto.crypto",
        "description": "crypto.crypto",
        "isExtraImport": true,
        "detail": "crypto.crypto",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "importPath": "crypto.crypto",
        "description": "crypto.crypto",
        "isExtraImport": true,
        "detail": "crypto.crypto",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "importPath": "crypto.crypto",
        "description": "crypto.crypto",
        "isExtraImport": true,
        "detail": "crypto.crypto",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "importPath": "crypto.crypto",
        "description": "crypto.crypto",
        "isExtraImport": true,
        "detail": "crypto.crypto",
        "documentation": {}
    },
    {
        "label": "shorten_bytes_for_display",
        "importPath": "utils.display",
        "description": "utils.display",
        "isExtraImport": true,
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "shorten_bytes_for_display",
        "importPath": "utils.display",
        "description": "utils.display",
        "isExtraImport": true,
        "detail": "utils.display",
        "documentation": {}
    },
    {
        "label": "patch",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "patch",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "patch",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "patch",
        "importPath": "unittest.mock",
        "description": "unittest.mock",
        "isExtraImport": true,
        "detail": "unittest.mock",
        "documentation": {}
    },
    {
        "label": "entropy",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "entropy",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "hash_stage",
        "importPath": "utils.hashing",
        "description": "utils.hashing",
        "isExtraImport": true,
        "detail": "utils.hashing",
        "documentation": {}
    },
    {
        "label": "multi_stage_hash",
        "importPath": "utils.hashing",
        "description": "utils.hashing",
        "isExtraImport": true,
        "detail": "utils.hashing",
        "documentation": {}
    },
    {
        "label": "HASH_ALGORITHMS",
        "importPath": "utils.hashing",
        "description": "utils.hashing",
        "isExtraImport": true,
        "detail": "utils.hashing",
        "documentation": {}
    },
    {
        "label": "hash_stage",
        "importPath": "utils.hashing",
        "description": "utils.hashing",
        "isExtraImport": true,
        "detail": "utils.hashing",
        "documentation": {}
    },
    {
        "label": "multi_stage_hash",
        "importPath": "utils.hashing",
        "description": "utils.hashing",
        "isExtraImport": true,
        "detail": "utils.hashing",
        "documentation": {}
    },
    {
        "label": "HASH_ALGORITHMS",
        "importPath": "utils.hashing",
        "description": "utils.hashing",
        "isExtraImport": true,
        "detail": "utils.hashing",
        "documentation": {}
    },
    {
        "label": "derive_key_argon2",
        "importPath": "kdf.kdf",
        "description": "kdf.kdf",
        "isExtraImport": true,
        "detail": "kdf.kdf",
        "documentation": {}
    },
    {
        "label": "derive_key_shake",
        "importPath": "kdf.kdf",
        "description": "kdf.kdf",
        "isExtraImport": true,
        "detail": "kdf.kdf",
        "documentation": {}
    },
    {
        "label": "derive_key_hkdf",
        "importPath": "kdf.kdf",
        "description": "kdf.kdf",
        "isExtraImport": true,
        "detail": "kdf.kdf",
        "documentation": {}
    },
    {
        "label": "derive_key_hybrid_with_pqc",
        "importPath": "kdf.kdf",
        "description": "kdf.kdf",
        "isExtraImport": true,
        "detail": "kdf.kdf",
        "documentation": {}
    },
    {
        "label": "derive_key_argon2",
        "importPath": "kdf.kdf",
        "description": "kdf.kdf",
        "isExtraImport": true,
        "detail": "kdf.kdf",
        "documentation": {}
    },
    {
        "label": "derive_key_shake",
        "importPath": "kdf.kdf",
        "description": "kdf.kdf",
        "isExtraImport": true,
        "detail": "kdf.kdf",
        "documentation": {}
    },
    {
        "label": "derive_key_hkdf",
        "importPath": "kdf.kdf",
        "description": "kdf.kdf",
        "isExtraImport": true,
        "detail": "kdf.kdf",
        "documentation": {}
    },
    {
        "label": "derive_key_hybrid_with_pqc",
        "importPath": "kdf.kdf",
        "description": "kdf.kdf",
        "isExtraImport": true,
        "detail": "kdf.kdf",
        "documentation": {}
    },
    {
        "label": "pqc_keypair",
        "importPath": "pqc.pqc",
        "description": "pqc.pqc",
        "isExtraImport": true,
        "detail": "pqc.pqc",
        "documentation": {}
    },
    {
        "label": "pqc_encapsulate",
        "importPath": "pqc.pqc",
        "description": "pqc.pqc",
        "isExtraImport": true,
        "detail": "pqc.pqc",
        "documentation": {}
    },
    {
        "label": "pqc_decapsulate",
        "importPath": "pqc.pqc",
        "description": "pqc.pqc",
        "isExtraImport": true,
        "detail": "pqc.pqc",
        "documentation": {}
    },
    {
        "label": "pqc_select_and_run",
        "importPath": "pqc.pqc",
        "description": "pqc.pqc",
        "isExtraImport": true,
        "detail": "pqc.pqc",
        "documentation": {}
    },
    {
        "label": "PQC_FAST_KEMS",
        "importPath": "pqc.pqc",
        "description": "pqc.pqc",
        "isExtraImport": true,
        "detail": "pqc.pqc",
        "documentation": {}
    },
    {
        "label": "PQC_STRONG_KEMS",
        "importPath": "pqc.pqc",
        "description": "pqc.pqc",
        "isExtraImport": true,
        "detail": "pqc.pqc",
        "documentation": {}
    },
    {
        "label": "pqc_keypair",
        "importPath": "pqc.pqc",
        "description": "pqc.pqc",
        "isExtraImport": true,
        "detail": "pqc.pqc",
        "documentation": {}
    },
    {
        "label": "pqc_encapsulate",
        "importPath": "pqc.pqc",
        "description": "pqc.pqc",
        "isExtraImport": true,
        "detail": "pqc.pqc",
        "documentation": {}
    },
    {
        "label": "pqc_decapsulate",
        "importPath": "pqc.pqc",
        "description": "pqc.pqc",
        "isExtraImport": true,
        "detail": "pqc.pqc",
        "documentation": {}
    },
    {
        "label": "pqc_select_and_run",
        "importPath": "pqc.pqc",
        "description": "pqc.pqc",
        "isExtraImport": true,
        "detail": "pqc.pqc",
        "documentation": {}
    },
    {
        "label": "PQC_FAST_KEMS",
        "importPath": "pqc.pqc",
        "description": "pqc.pqc",
        "isExtraImport": true,
        "detail": "pqc.pqc",
        "documentation": {}
    },
    {
        "label": "PQC_STRONG_KEMS",
        "importPath": "pqc.pqc",
        "description": "pqc.pqc",
        "isExtraImport": true,
        "detail": "pqc.pqc",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "FastAPI",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "HTTPException",
        "importPath": "fastapi",
        "description": "fastapi",
        "isExtraImport": true,
        "detail": "fastapi",
        "documentation": {}
    },
    {
        "label": "EncryptRequest",
        "importPath": "schemas",
        "description": "schemas",
        "isExtraImport": true,
        "detail": "schemas",
        "documentation": {}
    },
    {
        "label": "EncryptResponse",
        "importPath": "schemas",
        "description": "schemas",
        "isExtraImport": true,
        "detail": "schemas",
        "documentation": {}
    },
    {
        "label": "DecryptRequest",
        "importPath": "schemas",
        "description": "schemas",
        "isExtraImport": true,
        "detail": "schemas",
        "documentation": {}
    },
    {
        "label": "DecryptResponse",
        "importPath": "schemas",
        "description": "schemas",
        "isExtraImport": true,
        "detail": "schemas",
        "documentation": {}
    },
    {
        "label": "HealthResponse",
        "importPath": "schemas",
        "description": "schemas",
        "isExtraImport": true,
        "detail": "schemas",
        "documentation": {}
    },
    {
        "label": "EncryptRequest",
        "importPath": "schemas",
        "description": "schemas",
        "isExtraImport": true,
        "detail": "schemas",
        "documentation": {}
    },
    {
        "label": "EncryptResponse",
        "importPath": "schemas",
        "description": "schemas",
        "isExtraImport": true,
        "detail": "schemas",
        "documentation": {}
    },
    {
        "label": "DecryptRequest",
        "importPath": "schemas",
        "description": "schemas",
        "isExtraImport": true,
        "detail": "schemas",
        "documentation": {}
    },
    {
        "label": "DecryptResponse",
        "importPath": "schemas",
        "description": "schemas",
        "isExtraImport": true,
        "detail": "schemas",
        "documentation": {}
    },
    {
        "label": "HealthResponse",
        "importPath": "schemas",
        "description": "schemas",
        "isExtraImport": true,
        "detail": "schemas",
        "documentation": {}
    },
    {
        "label": "logging",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "logging",
        "description": "logging",
        "detail": "logging",
        "documentation": {}
    },
    {
        "label": "init",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Fore",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Style",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "init",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Fore",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "Style",
        "importPath": "colorama",
        "description": "colorama",
        "isExtraImport": true,
        "detail": "colorama",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "BaseModel",
        "importPath": "pydantic",
        "description": "pydantic",
        "isExtraImport": true,
        "detail": "pydantic",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Optional",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TYPE_CHECKING",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Any",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "ClassVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Final",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "TypeVar",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "Union",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "cast",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "glob",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "glob",
        "description": "glob",
        "detail": "glob",
        "documentation": {}
    },
    {
        "label": "jinja2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jinja2",
        "description": "jinja2",
        "detail": "jinja2",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "yaml",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "yaml",
        "description": "yaml",
        "detail": "yaml",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "update_upstream_alg_docs",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "update_upstream_alg_docs",
        "description": "update_upstream_alg_docs",
        "detail": "update_upstream_alg_docs",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "Enum",
        "importPath": "enum",
        "description": "enum",
        "isExtraImport": true,
        "detail": "enum",
        "documentation": {}
    },
    {
        "label": "git",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "git",
        "description": "git",
        "detail": "git",
        "documentation": {}
    },
    {
        "label": "tabulate",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tabulate",
        "description": "tabulate",
        "detail": "tabulate",
        "documentation": {}
    },
    {
        "label": "functools",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "functools",
        "description": "functools",
        "detail": "functools",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "helpers",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "helpers",
        "description": "helpers",
        "detail": "helpers",
        "documentation": {}
    },
    {
        "label": "ssl",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ssl",
        "description": "ssl",
        "detail": "ssl",
        "documentation": {}
    },
    {
        "label": "urllib.request",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "urllib.request",
        "description": "urllib.request",
        "detail": "urllib.request",
        "documentation": {}
    },
    {
        "label": "pformat",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "pformat",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "oqs.rand",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "oqs.rand",
        "description": "oqs.rand",
        "detail": "oqs.rand",
        "documentation": {}
    },
    {
        "label": "annotations",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "ctypes",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ctypes",
        "description": "ctypes",
        "detail": "ctypes",
        "documentation": {}
    },
    {
        "label": "ctypes.util",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ctypes.util",
        "description": "ctypes.util",
        "detail": "ctypes.util",
        "documentation": {}
    },
    {
        "label": "importlib.metadata",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "importlib.metadata",
        "description": "importlib.metadata",
        "detail": "importlib.metadata",
        "documentation": {}
    },
    {
        "label": "tempfile",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tempfile",
        "description": "tempfile",
        "detail": "tempfile",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "Signature",
        "importPath": "oqs.oqs",
        "description": "oqs.oqs",
        "isExtraImport": true,
        "detail": "oqs.oqs",
        "documentation": {}
    },
    {
        "label": "SHA512",
        "importPath": "Crypto.Hash",
        "description": "Crypto.Hash",
        "isExtraImport": true,
        "detail": "Crypto.Hash",
        "documentation": {}
    },
    {
        "label": "SHA512",
        "importPath": "Crypto.Hash",
        "description": "Crypto.Hash",
        "isExtraImport": true,
        "detail": "Crypto.Hash",
        "documentation": {}
    },
    {
        "label": "SHA512",
        "importPath": "Crypto.Hash",
        "description": "Crypto.Hash",
        "isExtraImport": true,
        "detail": "Crypto.Hash",
        "documentation": {}
    },
    {
        "label": "SHA512",
        "importPath": "Crypto.Hash",
        "description": "Crypto.Hash",
        "isExtraImport": true,
        "detail": "Crypto.Hash",
        "documentation": {}
    },
    {
        "label": "SHA512",
        "importPath": "Crypto.Hash",
        "description": "Crypto.Hash",
        "isExtraImport": true,
        "detail": "Crypto.Hash",
        "documentation": {}
    },
    {
        "label": "SHA256",
        "importPath": "Crypto.Hash",
        "description": "Crypto.Hash",
        "isExtraImport": true,
        "detail": "Crypto.Hash",
        "documentation": {}
    },
    {
        "label": "SHA512",
        "importPath": "Crypto.Hash",
        "description": "Crypto.Hash",
        "isExtraImport": true,
        "detail": "Crypto.Hash",
        "documentation": {}
    },
    {
        "label": "HMAC",
        "importPath": "Crypto.Hash",
        "description": "Crypto.Hash",
        "isExtraImport": true,
        "detail": "Crypto.Hash",
        "documentation": {}
    },
    {
        "label": "SHA256",
        "importPath": "Crypto.Hash",
        "description": "Crypto.Hash",
        "isExtraImport": true,
        "detail": "Crypto.Hash",
        "documentation": {}
    },
    {
        "label": "SHA256",
        "importPath": "Crypto.Hash",
        "description": "Crypto.Hash",
        "isExtraImport": true,
        "detail": "Crypto.Hash",
        "documentation": {}
    },
    {
        "label": "SHA512",
        "importPath": "Crypto.Hash",
        "description": "Crypto.Hash",
        "isExtraImport": true,
        "detail": "Crypto.Hash",
        "documentation": {}
    },
    {
        "label": "SHA512",
        "importPath": "Crypto.Hash",
        "description": "Crypto.Hash",
        "isExtraImport": true,
        "detail": "Crypto.Hash",
        "documentation": {}
    },
    {
        "label": "psutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "psutil",
        "description": "psutil",
        "detail": "psutil",
        "documentation": {}
    },
    {
        "label": "generate_keypair",
        "importPath": "pqcrypto.kem.kyber512",
        "description": "pqcrypto.kem.kyber512",
        "isExtraImport": true,
        "detail": "pqcrypto.kem.kyber512",
        "documentation": {}
    },
    {
        "label": "encrypt",
        "importPath": "pqcrypto.kem.kyber512",
        "description": "pqcrypto.kem.kyber512",
        "isExtraImport": true,
        "detail": "pqcrypto.kem.kyber512",
        "documentation": {}
    },
    {
        "label": "decrypt",
        "importPath": "pqcrypto.kem.kyber512",
        "description": "pqcrypto.kem.kyber512",
        "isExtraImport": true,
        "detail": "pqcrypto.kem.kyber512",
        "documentation": {}
    },
    {
        "label": "generate_keypair",
        "importPath": "pqcrypto.sign.dilithium2",
        "description": "pqcrypto.sign.dilithium2",
        "isExtraImport": true,
        "detail": "pqcrypto.sign.dilithium2",
        "documentation": {}
    },
    {
        "label": "sign",
        "importPath": "pqcrypto.sign.dilithium2",
        "description": "pqcrypto.sign.dilithium2",
        "isExtraImport": true,
        "detail": "pqcrypto.sign.dilithium2",
        "documentation": {}
    },
    {
        "label": "verify",
        "importPath": "pqcrypto.sign.dilithium2",
        "description": "pqcrypto.sign.dilithium2",
        "isExtraImport": true,
        "detail": "pqcrypto.sign.dilithium2",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def main():\n    print(\"=== Adaptive Hashing Encryption (AHE) v9.5 SDK ===\")\n    message = input(\"Enter message to encrypt: \")\n    encrypted = ahe_encrypt_v9_5(message)\n    print(\"\\\\n--- Encrypted Output ---\")\n    print(encrypted)\nif _name_ == \"_main_\":\n    main()\n\"\"\",\n    \"AHE_SDK/core/crypto.py\": \"\"\"\\",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "calculate_shannon_entropy",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def calculate_shannon_entropy(data: bytes) -> float:\n    if not data: return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (str(uuid.getnode())+str(platform.system())+str(platform.release())+\n           str(os.cpu_count())+str(os.getpid())+str(time.time())+\n           str(socket.gethostname())).encode()\n    return hashlib.sha3_512(raw).digest()\ndef detect_anomaly(input_data: str, entropy_score: float) -> tuple:",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "get_environment_entropy",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def get_environment_entropy() -> bytes:\n    raw = (str(uuid.getnode())+str(platform.system())+str(platform.release())+\n           str(os.cpu_count())+str(os.getpid())+str(time.time())+\n           str(socket.gethostname())).encode()\n    return hashlib.sha3_512(raw).digest()\ndef detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    suspicious_chars = \"0123456789+/=\\\\n\"\n    reasons = []\n    if any(c in input_data for c in suspicious_chars):\n        reasons.append(\"suspicious characters detected\")",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "detect_anomaly",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    suspicious_chars = \"0123456789+/=\\\\n\"\n    reasons = []\n    if any(c in input_data for c in suspicious_chars):\n        reasons.append(\"suspicious characters detected\")\n    if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:\n        reasons.append(\"entropy out of range\")\n    return (len(reasons) > 0), reasons\ndef hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "hash_stage",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)\n    h.update(data)\n    return h.digest()\ndef aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),\n        \"nonce\": urlsafe_b64encode(nonce).decode(),\n        \"tag\": urlsafe_b64encode(tag).decode()\n    }\ndef aes_decrypt(bundle: dict, key: bytes) -> str:",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def aes_decrypt(bundle: dict, key: bytes) -> str:\n    nonce = urlsafe_b64decode(bundle[\"nonce\"])\n    tag = urlsafe_b64decode(bundle[\"tag\"])\n    ciphertext = urlsafe_b64decode(bundle[\"ciphertext\"])\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag).decode()\ndef derive_key_argon2(password: bytes, salt: bytes) -> bytes:\n    return hash_secret_raw(secret=password, salt=salt, time_cost=4, memory_cost=102400,\n                           parallelism=8, hash_len=AES_KEY_SIZE, type=Type.ID)\ndef derive_key_shake(password: bytes, salt: bytes, bits: int=256) -> bytes:",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "derive_key_argon2",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def derive_key_argon2(password: bytes, salt: bytes) -> bytes:\n    return hash_secret_raw(secret=password, salt=salt, time_cost=4, memory_cost=102400,\n                           parallelism=8, hash_len=AES_KEY_SIZE, type=Type.ID)\ndef derive_key_shake(password: bytes, salt: bytes, bits: int=256) -> bytes:\n    shake = hashlib.shake_128() if bits == 128 else hashlib.shake_256()\n    shake.update(password + salt)\n    return shake.digest(AES_KEY_SIZE)\ndef hkdf_extract(salt: bytes, input_key_material: bytes, hash_algo=hashlib.sha256) -> bytes:\n    return hmac.new(salt, input_key_material, hash_algo).digest()\ndef hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "derive_key_shake",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def derive_key_shake(password: bytes, salt: bytes, bits: int=256) -> bytes:\n    shake = hashlib.shake_128() if bits == 128 else hashlib.shake_256()\n    shake.update(password + salt)\n    return shake.digest(AES_KEY_SIZE)\ndef hkdf_extract(salt: bytes, input_key_material: bytes, hash_algo=hashlib.sha256) -> bytes:\n    return hmac.new(salt, input_key_material, hash_algo).digest()\ndef hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:\n    hash_len = hash_algo().digest_size\n    blocks_needed = (length + hash_len - 1) // hash_len\n    okm = b\"\"",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "hkdf_extract",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def hkdf_extract(salt: bytes, input_key_material: bytes, hash_algo=hashlib.sha256) -> bytes:\n    return hmac.new(salt, input_key_material, hash_algo).digest()\ndef hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:\n    hash_len = hash_algo().digest_size\n    blocks_needed = (length + hash_len - 1) // hash_len\n    okm = b\"\"\n    output_block = b\"\"\n    for counter in range(1, blocks_needed + 1):\n        output_block = hmac.new(prk, output_block + info + bytes([counter]), hash_algo).digest()\n        okm += output_block",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "hkdf_expand",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:\n    hash_len = hash_algo().digest_size\n    blocks_needed = (length + hash_len - 1) // hash_len\n    okm = b\"\"\n    output_block = b\"\"\n    for counter in range(1, blocks_needed + 1):\n        output_block = hmac.new(prk, output_block + info + bytes([counter]), hash_algo).digest()\n        okm += output_block\n    return okm[:length]\ndef derive_key_hkdf(password: bytes, salt: bytes) -> bytes:",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "derive_key_hkdf",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def derive_key_hkdf(password: bytes, salt: bytes) -> bytes:\n    prk = hkdf_extract(salt, password)\n    return hkdf_expand(prk, b\"AHE-HKDF\", AES_KEY_SIZE)\ndef pqc_keypair(kem_name: str):\n    kem = oqs.KeyEncapsulation(kem_name)\n    public_key = kem.generate_keypair()\n    return kem, public_key\ndef pqc_encapsulate(kem, public_key: bytes):\n    return kem.encap_secret(public_key)\ndef pqc_decapsulate(kem, ciphertext: bytes):",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "pqc_keypair",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def pqc_keypair(kem_name: str):\n    kem = oqs.KeyEncapsulation(kem_name)\n    public_key = kem.generate_keypair()\n    return kem, public_key\ndef pqc_encapsulate(kem, public_key: bytes):\n    return kem.encap_secret(public_key)\ndef pqc_decapsulate(kem, ciphertext: bytes):\n    return kem.decap_secret(ciphertext)\ndef derive_key_hybrid_with_pqc(password: bytes, salt: bytes, anomaly: bool) -> tuple:\n    pqc_candidates = PQC_STRONG_KEMS.copy() if anomaly else PQC_FAST_KEMS.copy()",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "pqc_encapsulate",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def pqc_encapsulate(kem, public_key: bytes):\n    return kem.encap_secret(public_key)\ndef pqc_decapsulate(kem, ciphertext: bytes):\n    return kem.decap_secret(ciphertext)\ndef derive_key_hybrid_with_pqc(password: bytes, salt: bytes, anomaly: bool) -> tuple:\n    pqc_candidates = PQC_STRONG_KEMS.copy() if anomaly else PQC_FAST_KEMS.copy()\n    random.shuffle(pqc_candidates)\n    if anomaly:\n        if random.choice([True, False]):\n            intermediate_key = derive_key_argon2(password, salt)",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "pqc_decapsulate",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def pqc_decapsulate(kem, ciphertext: bytes):\n    return kem.decap_secret(ciphertext)\ndef derive_key_hybrid_with_pqc(password: bytes, salt: bytes, anomaly: bool) -> tuple:\n    pqc_candidates = PQC_STRONG_KEMS.copy() if anomaly else PQC_FAST_KEMS.copy()\n    random.shuffle(pqc_candidates)\n    if anomaly:\n        if random.choice([True, False]):\n            intermediate_key = derive_key_argon2(password, salt)\n        else:\n            intermediate_key = derive_key_shake(password, salt, random.choice([128,256]))",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "derive_key_hybrid_with_pqc",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def derive_key_hybrid_with_pqc(password: bytes, salt: bytes, anomaly: bool) -> tuple:\n    pqc_candidates = PQC_STRONG_KEMS.copy() if anomaly else PQC_FAST_KEMS.copy()\n    random.shuffle(pqc_candidates)\n    if anomaly:\n        if random.choice([True, False]):\n            intermediate_key = derive_key_argon2(password, salt)\n        else:\n            intermediate_key = derive_key_shake(password, salt, random.choice([128,256]))\n    else:\n        intermediate_key = derive_key_hkdf(password, salt)",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v9_5",
        "kind": 2,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "def ahe_encrypt_v9_5(message: str) -> dict:\n    input_bytes = message.encode()\n    input_entropy = calculate_shannon_entropy(input_bytes)\n    system_entropy = get_environment_entropy()\n    fused_input = bytes(a ^ b for a, b in zip(input_bytes, system_entropy[:len(input_bytes)]))\n    anomaly, reasons = detect_anomaly(message, input_entropy)\n    output = fused_input\n    for algo in random.sample(HASH_ALGORITHMS, len(HASH_ALGORITHMS)):\n        output = hash_stage(output + system_entropy, algo)\n    salt = system_entropy[:16]",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "folders",
        "kind": 5,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "folders = [\n    \"AHE_SDK/core\",\n    \"AHE_SDK/utils\",\n    \"AHE_SDK/pqc\",\n    \"AHE_SDK/kdf\",\n    \"AHE_SDK/aes\",\n]\n# === Files and their content ===\nfiles_content = {\n    \"AHE_SDK/core/main.py\": \"\"\"\\",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "files_content",
        "kind": 5,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "files_content = {\n    \"AHE_SDK/core/main.py\": \"\"\"\\\nfrom core.crypto import ahe_encrypt_v9_5\nimport sys\ndef main():\n    print(\"=== Adaptive Hashing Encryption (AHE) v9.5 SDK ===\")\n    message = input(\"Enter message to encrypt: \")\n    encrypted = ahe_encrypt_v9_5(message)\n    print(\"\\\\n--- Encrypted Output ---\")\n    print(encrypted)",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_LOW",
        "kind": 5,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_LOW = 3.5\nENTROPY_WARN_THRESHOLD_HIGH = 4.75\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha256\", \"sha512\", \"sha3_256\", \"sha3_512\"]\nPQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\nPQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data: return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_HIGH",
        "kind": 5,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_HIGH = 4.75\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha256\", \"sha512\", \"sha3_256\", \"sha3_512\"]\nPQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\nPQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data: return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "AES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha256\", \"sha512\", \"sha3_256\", \"sha3_512\"]\nPQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\nPQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data: return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (str(uuid.getnode())+str(platform.system())+str(platform.release())+",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "HASH_ALGORITHMS",
        "kind": 5,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "HASH_ALGORITHMS = [\"sha256\", \"sha512\", \"sha3_256\", \"sha3_512\"]\nPQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\nPQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data: return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (str(uuid.getnode())+str(platform.system())+str(platform.release())+\n           str(os.cpu_count())+str(os.getpid())+str(time.time())+",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "PQC_FAST_KEMS",
        "kind": 5,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "PQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\nPQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data: return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (str(uuid.getnode())+str(platform.system())+str(platform.release())+\n           str(os.cpu_count())+str(os.getpid())+str(time.time())+\n           str(socket.gethostname())).encode()",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "PQC_STRONG_KEMS",
        "kind": 5,
        "importPath": "ahe-env.ahesteup",
        "description": "ahe-env.ahesteup",
        "peekOfCode": "PQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data: return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (str(uuid.getnode())+str(platform.system())+str(platform.release())+\n           str(os.cpu_count())+str(os.getpid())+str(time.time())+\n           str(socket.gethostname())).encode()\n    return hashlib.sha3_512(raw).digest()",
        "detail": "ahe-env.ahesteup",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def main():\n    print(\"=== Adaptive Hashing Encryption (AHE) v9.5 SDK ===\")\n    message = input(\"Enter message to encrypt: \")\n    encrypted = ahe_encrypt_v9_5(message)\n    print(\"\\\\n--- Encrypted Output ---\")\n    print(encrypted)\nif _name_ == \"_main_\":\n    main()\n\"\"\",\n    \"AHE_SDK/core/crypto.py\": \"\"\"\\",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "calculate_shannon_entropy",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def calculate_shannon_entropy(data: bytes) -> float:\n    if not data: return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (str(uuid.getnode())+str(platform.system())+str(platform.release())+\n           str(os.cpu_count())+str(os.getpid())+str(time.time())+\n           str(socket.gethostname())).encode()\n    return hashlib.sha3_512(raw).digest()\ndef detect_anomaly(input_data: str, entropy_score: float) -> tuple:",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "get_environment_entropy",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def get_environment_entropy() -> bytes:\n    raw = (str(uuid.getnode())+str(platform.system())+str(platform.release())+\n           str(os.cpu_count())+str(os.getpid())+str(time.time())+\n           str(socket.gethostname())).encode()\n    return hashlib.sha3_512(raw).digest()\ndef detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    suspicious_chars = \"0123456789+/=\\\\n\"\n    reasons = []\n    if any(c in input_data for c in suspicious_chars):\n        reasons.append(\"suspicious characters detected\")",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "detect_anomaly",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    suspicious_chars = \"0123456789+/=\\\\n\"\n    reasons = []\n    if any(c in input_data for c in suspicious_chars):\n        reasons.append(\"suspicious characters detected\")\n    if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:\n        reasons.append(\"entropy out of range\")\n    return (len(reasons) > 0), reasons\ndef hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "hash_stage",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)\n    h.update(data)\n    return h.digest()\ndef aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),\n        \"nonce\": urlsafe_b64encode(nonce).decode(),\n        \"tag\": urlsafe_b64encode(tag).decode()\n    }\ndef aes_decrypt(bundle: dict, key: bytes) -> str:",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def aes_decrypt(bundle: dict, key: bytes) -> str:\n    nonce = urlsafe_b64decode(bundle[\"nonce\"])\n    tag = urlsafe_b64decode(bundle[\"tag\"])\n    ciphertext = urlsafe_b64decode(bundle[\"ciphertext\"])\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag).decode()\ndef derive_key_argon2(password: bytes, salt: bytes) -> bytes:\n    return hash_secret_raw(secret=password, salt=salt, time_cost=4, memory_cost=102400,\n                           parallelism=8, hash_len=AES_KEY_SIZE, type=Type.ID)\ndef derive_key_shake(password: bytes, salt: bytes, bits: int=256) -> bytes:",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "derive_key_argon2",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def derive_key_argon2(password: bytes, salt: bytes) -> bytes:\n    return hash_secret_raw(secret=password, salt=salt, time_cost=4, memory_cost=102400,\n                           parallelism=8, hash_len=AES_KEY_SIZE, type=Type.ID)\ndef derive_key_shake(password: bytes, salt: bytes, bits: int=256) -> bytes:\n    shake = hashlib.shake_128() if bits == 128 else hashlib.shake_256()\n    shake.update(password + salt)\n    return shake.digest(AES_KEY_SIZE)\ndef hkdf_extract(salt: bytes, input_key_material: bytes, hash_algo=hashlib.sha256) -> bytes:\n    return hmac.new(salt, input_key_material, hash_algo).digest()\ndef hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "derive_key_shake",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def derive_key_shake(password: bytes, salt: bytes, bits: int=256) -> bytes:\n    shake = hashlib.shake_128() if bits == 128 else hashlib.shake_256()\n    shake.update(password + salt)\n    return shake.digest(AES_KEY_SIZE)\ndef hkdf_extract(salt: bytes, input_key_material: bytes, hash_algo=hashlib.sha256) -> bytes:\n    return hmac.new(salt, input_key_material, hash_algo).digest()\ndef hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:\n    hash_len = hash_algo().digest_size\n    blocks_needed = (length + hash_len - 1) // hash_len\n    okm = b\"\"",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "hkdf_extract",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def hkdf_extract(salt: bytes, input_key_material: bytes, hash_algo=hashlib.sha256) -> bytes:\n    return hmac.new(salt, input_key_material, hash_algo).digest()\ndef hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:\n    hash_len = hash_algo().digest_size\n    blocks_needed = (length + hash_len - 1) // hash_len\n    okm = b\"\"\n    output_block = b\"\"\n    for counter in range(1, blocks_needed + 1):\n        output_block = hmac.new(prk, output_block + info + bytes([counter]), hash_algo).digest()\n        okm += output_block",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "hkdf_expand",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:\n    hash_len = hash_algo().digest_size\n    blocks_needed = (length + hash_len - 1) // hash_len\n    okm = b\"\"\n    output_block = b\"\"\n    for counter in range(1, blocks_needed + 1):\n        output_block = hmac.new(prk, output_block + info + bytes([counter]), hash_algo).digest()\n        okm += output_block\n    return okm[:length]\ndef derive_key_hkdf(password: bytes, salt: bytes) -> bytes:",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "derive_key_hkdf",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def derive_key_hkdf(password: bytes, salt: bytes) -> bytes:\n    prk = hkdf_extract(salt, password)\n    return hkdf_expand(prk, b\"AHE-HKDF\", AES_KEY_SIZE)\ndef pqc_keypair(kem_name: str):\n    kem = oqs.KeyEncapsulation(kem_name)\n    public_key = kem.generate_keypair()\n    return kem, public_key\ndef pqc_encapsulate(kem, public_key: bytes):\n    return kem.encap_secret(public_key)\ndef pqc_decapsulate(kem, ciphertext: bytes):",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "pqc_keypair",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def pqc_keypair(kem_name: str):\n    kem = oqs.KeyEncapsulation(kem_name)\n    public_key = kem.generate_keypair()\n    return kem, public_key\ndef pqc_encapsulate(kem, public_key: bytes):\n    return kem.encap_secret(public_key)\ndef pqc_decapsulate(kem, ciphertext: bytes):\n    return kem.decap_secret(ciphertext)\ndef derive_key_hybrid_with_pqc(password: bytes, salt: bytes, anomaly: bool) -> tuple:\n    pqc_candidates = PQC_STRONG_KEMS.copy() if anomaly else PQC_FAST_KEMS.copy()",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "pqc_encapsulate",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def pqc_encapsulate(kem, public_key: bytes):\n    return kem.encap_secret(public_key)\ndef pqc_decapsulate(kem, ciphertext: bytes):\n    return kem.decap_secret(ciphertext)\ndef derive_key_hybrid_with_pqc(password: bytes, salt: bytes, anomaly: bool) -> tuple:\n    pqc_candidates = PQC_STRONG_KEMS.copy() if anomaly else PQC_FAST_KEMS.copy()\n    random.shuffle(pqc_candidates)\n    if anomaly:\n        if random.choice([True, False]):\n            intermediate_key = derive_key_argon2(password, salt)",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "pqc_decapsulate",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def pqc_decapsulate(kem, ciphertext: bytes):\n    return kem.decap_secret(ciphertext)\ndef derive_key_hybrid_with_pqc(password: bytes, salt: bytes, anomaly: bool) -> tuple:\n    pqc_candidates = PQC_STRONG_KEMS.copy() if anomaly else PQC_FAST_KEMS.copy()\n    random.shuffle(pqc_candidates)\n    if anomaly:\n        if random.choice([True, False]):\n            intermediate_key = derive_key_argon2(password, salt)\n        else:\n            intermediate_key = derive_key_shake(password, salt, random.choice([128,256]))",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "derive_key_hybrid_with_pqc",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def derive_key_hybrid_with_pqc(password: bytes, salt: bytes, anomaly: bool) -> tuple:\n    pqc_candidates = PQC_STRONG_KEMS.copy() if anomaly else PQC_FAST_KEMS.copy()\n    random.shuffle(pqc_candidates)\n    if anomaly:\n        if random.choice([True, False]):\n            intermediate_key = derive_key_argon2(password, salt)\n        else:\n            intermediate_key = derive_key_shake(password, salt, random.choice([128,256]))\n    else:\n        intermediate_key = derive_key_hkdf(password, salt)",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v9_5",
        "kind": 2,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "def ahe_encrypt_v9_5(message: str) -> dict:\n    input_bytes = message.encode()\n    input_entropy = calculate_shannon_entropy(input_bytes)\n    system_entropy = get_environment_entropy()\n    fused_input = bytes(a ^ b for a, b in zip(input_bytes, system_entropy[:len(input_bytes)]))\n    anomaly, reasons = detect_anomaly(message, input_entropy)\n    output = fused_input\n    for algo in random.sample(HASH_ALGORITHMS, len(HASH_ALGORITHMS)):\n        output = hash_stage(output + system_entropy, algo)\n    salt = system_entropy[:16]",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "folders",
        "kind": 5,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "folders = [\n    \"AHE_SDK/core\",\n    \"AHE_SDK/utils\",\n    \"AHE_SDK/pqc\",\n    \"AHE_SDK/kdf\",\n    \"AHE_SDK/aes\",\n]\n# === Files and their content ===\nfiles_content = {\n    \"AHE_SDK/core/main.py\": \"\"\"\\",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "files_content",
        "kind": 5,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "files_content = {\n    \"AHE_SDK/core/main.py\": \"\"\"\\\nfrom core.crypto import ahe_encrypt_v9_5\nimport sys\ndef main():\n    print(\"=== Adaptive Hashing Encryption (AHE) v9.5 SDK ===\")\n    message = input(\"Enter message to encrypt: \")\n    encrypted = ahe_encrypt_v9_5(message)\n    print(\"\\\\n--- Encrypted Output ---\")\n    print(encrypted)",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_LOW",
        "kind": 5,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_LOW = 3.5\nENTROPY_WARN_THRESHOLD_HIGH = 4.75\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha256\", \"sha512\", \"sha3_256\", \"sha3_512\"]\nPQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\nPQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data: return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_HIGH",
        "kind": 5,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_HIGH = 4.75\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha256\", \"sha512\", \"sha3_256\", \"sha3_512\"]\nPQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\nPQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data: return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "AES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha256\", \"sha512\", \"sha3_256\", \"sha3_512\"]\nPQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\nPQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data: return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (str(uuid.getnode())+str(platform.system())+str(platform.release())+",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "HASH_ALGORITHMS",
        "kind": 5,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "HASH_ALGORITHMS = [\"sha256\", \"sha512\", \"sha3_256\", \"sha3_512\"]\nPQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\nPQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data: return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (str(uuid.getnode())+str(platform.system())+str(platform.release())+\n           str(os.cpu_count())+str(os.getpid())+str(time.time())+",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "PQC_FAST_KEMS",
        "kind": 5,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "PQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\nPQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data: return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (str(uuid.getnode())+str(platform.system())+str(platform.release())+\n           str(os.cpu_count())+str(os.getpid())+str(time.time())+\n           str(socket.gethostname())).encode()",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "PQC_STRONG_KEMS",
        "kind": 5,
        "importPath": "ahe-env.newahesdk",
        "description": "ahe-env.newahesdk",
        "peekOfCode": "PQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data: return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (str(uuid.getnode())+str(platform.system())+str(platform.release())+\n           str(os.cpu_count())+str(os.getpid())+str(time.time())+\n           str(socket.gethostname())).encode()\n    return hashlib.sha3_512(raw).digest()",
        "detail": "ahe-env.newahesdk",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "AHE_SDK.aes.aes",
        "description": "AHE_SDK.aes.aes",
        "peekOfCode": "def aes_encrypt(message: str, key: bytes) -> dict:\n    logger.info(\"Starting AES encryption\")\n    try:\n        nonce = get_random_bytes(12)\n        cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n        ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n        logger.info(\"AES encryption successful\")\n        return {\n            \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),\n            \"nonce\": urlsafe_b64encode(nonce).decode(),",
        "detail": "AHE_SDK.aes.aes",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "AHE_SDK.aes.aes",
        "description": "AHE_SDK.aes.aes",
        "peekOfCode": "def aes_decrypt(bundle: dict, key: bytes) -> str:\n    logger.info(\"Starting AES decryption\")\n    try:\n        nonce = urlsafe_b64decode(bundle[\"nonce\"])\n        tag = urlsafe_b64decode(bundle[\"tag\"])\n        ciphertext = urlsafe_b64decode(bundle[\"ciphertext\"])\n        cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n        plaintext = cipher.decrypt_and_verify(ciphertext, tag)\n        logger.info(\"AES decryption successful\")\n        return plaintext.decode()",
        "detail": "AHE_SDK.aes.aes",
        "documentation": {}
    },
    {
        "label": "calculate_entropy",
        "kind": 2,
        "importPath": "AHE_SDK.core.core",
        "description": "AHE_SDK.core.core",
        "peekOfCode": "def calculate_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef detect_anomaly(entropy_score: float, message: str):\n    reasons = []\n    suspicious_chars = \"0123456789+/=\\n\"\n    if any(c in message for c in suspicious_chars):\n        reasons.append(\"Suspicious characters detected\")",
        "detail": "AHE_SDK.core.core",
        "documentation": {}
    },
    {
        "label": "detect_anomaly",
        "kind": 2,
        "importPath": "AHE_SDK.core.core",
        "description": "AHE_SDK.core.core",
        "peekOfCode": "def detect_anomaly(entropy_score: float, message: str):\n    reasons = []\n    suspicious_chars = \"0123456789+/=\\n\"\n    if any(c in message for c in suspicious_chars):\n        reasons.append(\"Suspicious characters detected\")\n    if entropy_score < ENTROPY_WARN_LOW or entropy_score > ENTROPY_WARN_HIGH:\n        reasons.append(\"Entropy out of normal range\")\n    return (len(reasons) > 0), reasons\ndef derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes",
        "detail": "AHE_SDK.core.core",
        "documentation": {}
    },
    {
        "label": "derive_key",
        "kind": 2,
        "importPath": "AHE_SDK.core.core",
        "description": "AHE_SDK.core.core",
        "peekOfCode": "def derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    logger.debug(\"[TRACE] Fusion key derivation initiated\")\n    return hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\ndef aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext_bytes)\n    logger.debug(\"[INTEGRITY] AES-GCM tag generated\")\n    return ciphertext, nonce, tag",
        "detail": "AHE_SDK.core.core",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "AHE_SDK.core.core",
        "description": "AHE_SDK.core.core",
        "peekOfCode": "def aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext_bytes)\n    logger.debug(\"[INTEGRITY] AES-GCM tag generated\")\n    return ciphertext, nonce, tag\ndef aes_decrypt(ciphertext, nonce, tag, key):\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag)\n# === METADATA ENCRYPTION ===",
        "detail": "AHE_SDK.core.core",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "AHE_SDK.core.core",
        "description": "AHE_SDK.core.core",
        "peekOfCode": "def aes_decrypt(ciphertext, nonce, tag, key):\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag)\n# === METADATA ENCRYPTION ===\ndef encrypt_metadata(metadata_dict, password):\n    metadata_json = json.dumps(metadata_dict)\n    metadata_bytes = metadata_json.encode('utf-8')\n    salt = get_random_bytes(16)\n    key = PBKDF2(password, salt, dkLen=32, count=100_000)\n    nonce = get_random_bytes(12)",
        "detail": "AHE_SDK.core.core",
        "documentation": {}
    },
    {
        "label": "encrypt_metadata",
        "kind": 2,
        "importPath": "AHE_SDK.core.core",
        "description": "AHE_SDK.core.core",
        "peekOfCode": "def encrypt_metadata(metadata_dict, password):\n    metadata_json = json.dumps(metadata_dict)\n    metadata_bytes = metadata_json.encode('utf-8')\n    salt = get_random_bytes(16)\n    key = PBKDF2(password, salt, dkLen=32, count=100_000)\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(metadata_bytes)\n    logger.debug(\"[ZERO-KNOWLEDGE] Metadata encapsulated securely\")\n    return json.dumps({",
        "detail": "AHE_SDK.core.core",
        "documentation": {}
    },
    {
        "label": "decrypt_metadata",
        "kind": 2,
        "importPath": "AHE_SDK.core.core",
        "description": "AHE_SDK.core.core",
        "peekOfCode": "def decrypt_metadata(encrypted_blob_json, password):\n    encrypted_blob = json.loads(encrypted_blob_json)\n    salt = base64.b64decode(encrypted_blob[\"salt\"])\n    nonce = base64.b64decode(encrypted_blob[\"nonce\"])\n    tag = base64.b64decode(encrypted_blob[\"tag\"])\n    ciphertext = base64.b64decode(encrypted_blob[\"ciphertext\"])\n    key = PBKDF2(password, salt, dkLen=32, count=100_000)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    metadata_bytes = cipher.decrypt_and_verify(ciphertext, tag)\n    return json.loads(metadata_bytes.decode('utf-8'))",
        "detail": "AHE_SDK.core.core",
        "documentation": {}
    },
    {
        "label": "encrypt_message",
        "kind": 2,
        "importPath": "AHE_SDK.core.core",
        "description": "AHE_SDK.core.core",
        "peekOfCode": "def encrypt_message(message, password):\n    logger.info(\"=== [START] AHE Encryption ===\")\n    start_time = time.time()\n    # 1. Entropy & Anomaly\n    plaintext = message.encode()\n    input_entropy = calculate_entropy(plaintext)\n    anomaly, reasons = detect_anomaly(input_entropy, message)\n    logger.info(f\"[AUDIT] Input entropy: {input_entropy:.4f} | Anomaly: {anomaly}\")\n    if anomaly:\n        logger.warning(f\"[AUDIT] Anomaly reasons: {', '.join(reasons)}\")",
        "detail": "AHE_SDK.core.core",
        "documentation": {}
    },
    {
        "label": "decrypt_latest",
        "kind": 2,
        "importPath": "AHE_SDK.core.core",
        "description": "AHE_SDK.core.core",
        "peekOfCode": "def decrypt_latest(password):\n    logger.info(\"=== [START] AHE Decryption ===\")\n    start_time = time.time()\n    files = sorted([f for f in os.listdir(STORAGE_DIR) if f.endswith(ENC_EXT)])\n    metas = sorted([f for f in os.listdir(STORAGE_DIR) if f.endswith(META_EXT)])\n    if not files or not metas:\n        raise FileNotFoundError(\"No encrypted data found in secure_storage.\")\n    enc_path = os.path.join(STORAGE_DIR, files[-1])\n    meta_path = os.path.join(STORAGE_DIR, metas[-1])\n    logger.info(f\"[INFO] Using ciphertext: {enc_path}\")",
        "detail": "AHE_SDK.core.core",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "AHE_SDK.core.core",
        "description": "AHE_SDK.core.core",
        "peekOfCode": "AES_KEY_SIZE = 32\nMETA_EXT = \".meta\"\nENC_EXT = \".ahe\"\nPQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\nSTORAGE_DIR = \"secure_storage\"\nENTROPY_WARN_LOW = 3.5\nENTROPY_WARN_HIGH = 4.75\nos.makedirs(STORAGE_DIR, exist_ok=True)\n# === UTILITIES ===\ndef calculate_entropy(data: bytes) -> float:",
        "detail": "AHE_SDK.core.core",
        "documentation": {}
    },
    {
        "label": "META_EXT",
        "kind": 5,
        "importPath": "AHE_SDK.core.core",
        "description": "AHE_SDK.core.core",
        "peekOfCode": "META_EXT = \".meta\"\nENC_EXT = \".ahe\"\nPQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\nSTORAGE_DIR = \"secure_storage\"\nENTROPY_WARN_LOW = 3.5\nENTROPY_WARN_HIGH = 4.75\nos.makedirs(STORAGE_DIR, exist_ok=True)\n# === UTILITIES ===\ndef calculate_entropy(data: bytes) -> float:\n    if not data:",
        "detail": "AHE_SDK.core.core",
        "documentation": {}
    },
    {
        "label": "ENC_EXT",
        "kind": 5,
        "importPath": "AHE_SDK.core.core",
        "description": "AHE_SDK.core.core",
        "peekOfCode": "ENC_EXT = \".ahe\"\nPQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\nSTORAGE_DIR = \"secure_storage\"\nENTROPY_WARN_LOW = 3.5\nENTROPY_WARN_HIGH = 4.75\nos.makedirs(STORAGE_DIR, exist_ok=True)\n# === UTILITIES ===\ndef calculate_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0",
        "detail": "AHE_SDK.core.core",
        "documentation": {}
    },
    {
        "label": "PQC_KEMS",
        "kind": 5,
        "importPath": "AHE_SDK.core.core",
        "description": "AHE_SDK.core.core",
        "peekOfCode": "PQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\nSTORAGE_DIR = \"secure_storage\"\nENTROPY_WARN_LOW = 3.5\nENTROPY_WARN_HIGH = 4.75\nos.makedirs(STORAGE_DIR, exist_ok=True)\n# === UTILITIES ===\ndef calculate_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}",
        "detail": "AHE_SDK.core.core",
        "documentation": {}
    },
    {
        "label": "STORAGE_DIR",
        "kind": 5,
        "importPath": "AHE_SDK.core.core",
        "description": "AHE_SDK.core.core",
        "peekOfCode": "STORAGE_DIR = \"secure_storage\"\nENTROPY_WARN_LOW = 3.5\nENTROPY_WARN_HIGH = 4.75\nos.makedirs(STORAGE_DIR, exist_ok=True)\n# === UTILITIES ===\ndef calculate_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())",
        "detail": "AHE_SDK.core.core",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_LOW",
        "kind": 5,
        "importPath": "AHE_SDK.core.core",
        "description": "AHE_SDK.core.core",
        "peekOfCode": "ENTROPY_WARN_LOW = 3.5\nENTROPY_WARN_HIGH = 4.75\nos.makedirs(STORAGE_DIR, exist_ok=True)\n# === UTILITIES ===\ndef calculate_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef detect_anomaly(entropy_score: float, message: str):",
        "detail": "AHE_SDK.core.core",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_HIGH",
        "kind": 5,
        "importPath": "AHE_SDK.core.core",
        "description": "AHE_SDK.core.core",
        "peekOfCode": "ENTROPY_WARN_HIGH = 4.75\nos.makedirs(STORAGE_DIR, exist_ok=True)\n# === UTILITIES ===\ndef calculate_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef detect_anomaly(entropy_score: float, message: str):\n    reasons = []",
        "detail": "AHE_SDK.core.core",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "AHE_SDK.crypto.crypto",
        "description": "AHE_SDK.crypto.crypto",
        "peekOfCode": "def aes_encrypt(message, key: bytes) -> tuple:\n    \"\"\"\n    Encrypts message using AES-GCM.\n    Accepts str or bytes.\n    Returns (ciphertext, nonce, tag) as raw bytes.\n    \"\"\"\n    logger.info(\"Starting AES encryption process\")\n    try:\n        if isinstance(message, str):\n            message = message.encode()",
        "detail": "AHE_SDK.crypto.crypto",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "AHE_SDK.crypto.crypto",
        "description": "AHE_SDK.crypto.crypto",
        "peekOfCode": "def aes_decrypt(ciphertext: bytes, key: bytes, nonce: bytes, tag: bytes) -> bytes:\n    \"\"\"\n    Decrypts AES-GCM encrypted data.\n    Returns plaintext as bytes.\n    \"\"\"\n    logger.info(\"Starting AES decryption process\")\n    try:\n        cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n        plaintext = cipher.decrypt_and_verify(ciphertext, tag)\n        logger.info(\"AES decryption completed successfully\")",
        "detail": "AHE_SDK.crypto.crypto",
        "documentation": {}
    },
    {
        "label": "derive_key_argon2",
        "kind": 2,
        "importPath": "AHE_SDK.kdf.kdf",
        "description": "AHE_SDK.kdf.kdf",
        "peekOfCode": "def derive_key_argon2(password: bytes, salt: bytes) -> bytes:\n    logger.info(\"Starting Argon2id key derivation\")\n    try:\n        key = hash_secret_raw(\n            secret=password,\n            salt=salt,\n            time_cost=4,\n            memory_cost=102400,\n            parallelism=8,\n            hash_len=AES_KEY_SIZE,",
        "detail": "AHE_SDK.kdf.kdf",
        "documentation": {}
    },
    {
        "label": "derive_key_shake",
        "kind": 2,
        "importPath": "AHE_SDK.kdf.kdf",
        "description": "AHE_SDK.kdf.kdf",
        "peekOfCode": "def derive_key_shake(password: bytes, salt: bytes, bits: int=256) -> bytes:\n    logger.info(f\"Starting SHAKE-{bits} key derivation\")\n    try:\n        shake = hashlib.shake_128() if bits == 128 else hashlib.shake_256()\n        shake.update(password + salt)\n        key = shake.digest(AES_KEY_SIZE)\n        logger.info(f\"SHAKE-{bits} key derivation completed\")\n        return key\n    except Exception as e:\n        logger.error(f\"SHAKE-{bits} derivation failed: {e}\", exc_info=True)",
        "detail": "AHE_SDK.kdf.kdf",
        "documentation": {}
    },
    {
        "label": "hkdf_extract",
        "kind": 2,
        "importPath": "AHE_SDK.kdf.kdf",
        "description": "AHE_SDK.kdf.kdf",
        "peekOfCode": "def hkdf_extract(salt: bytes, input_key_material: bytes, hash_algo=hashlib.sha256) -> bytes:\n    return hmac.new(salt, input_key_material, hash_algo).digest()\ndef hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:\n    hash_len = hash_algo().digest_size\n    blocks_needed = (length + hash_len - 1) // hash_len\n    okm = b\"\"\n    output_block = b\"\"\n    for counter in range(1, blocks_needed + 1):\n        output_block = hmac.new(prk, output_block + info + bytes([counter]), hash_algo).digest()\n        okm += output_block",
        "detail": "AHE_SDK.kdf.kdf",
        "documentation": {}
    },
    {
        "label": "hkdf_expand",
        "kind": 2,
        "importPath": "AHE_SDK.kdf.kdf",
        "description": "AHE_SDK.kdf.kdf",
        "peekOfCode": "def hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:\n    hash_len = hash_algo().digest_size\n    blocks_needed = (length + hash_len - 1) // hash_len\n    okm = b\"\"\n    output_block = b\"\"\n    for counter in range(1, blocks_needed + 1):\n        output_block = hmac.new(prk, output_block + info + bytes([counter]), hash_algo).digest()\n        okm += output_block\n    return okm[:length]\ndef derive_key_hkdf(password: bytes, salt: bytes) -> bytes:",
        "detail": "AHE_SDK.kdf.kdf",
        "documentation": {}
    },
    {
        "label": "derive_key_hkdf",
        "kind": 2,
        "importPath": "AHE_SDK.kdf.kdf",
        "description": "AHE_SDK.kdf.kdf",
        "peekOfCode": "def derive_key_hkdf(password: bytes, salt: bytes) -> bytes:\n    logger.info(\"Starting HKDF key derivation\")\n    try:\n        prk = hkdf_extract(salt, password)\n        key = hkdf_expand(prk, b\"AHE-HKDF\", AES_KEY_SIZE)\n        logger.info(\"HKDF key derivation completed\")\n        return key\n    except Exception as e:\n        logger.error(f\"HKDF derivation failed: {e}\", exc_info=True)\n        raise",
        "detail": "AHE_SDK.kdf.kdf",
        "documentation": {}
    },
    {
        "label": "derive_key_hybrid_with_pqc",
        "kind": 2,
        "importPath": "AHE_SDK.kdf.kdf",
        "description": "AHE_SDK.kdf.kdf",
        "peekOfCode": "def derive_key_hybrid_with_pqc(password: bytes, salt: bytes, anomaly: bool) -> tuple:\n    PQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\n    PQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\n    if anomaly:\n        pqc_candidates = PQC_STRONG_KEMS.copy()\n    else:\n        pqc_candidates = PQC_FAST_KEMS.copy()\n    random.shuffle(pqc_candidates)\n    try:\n        if anomaly:",
        "detail": "AHE_SDK.kdf.kdf",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "AHE_SDK.kdf.kdf",
        "description": "AHE_SDK.kdf.kdf",
        "peekOfCode": "AES_KEY_SIZE = 32\n# === Key Derivation Functions ===\ndef derive_key_argon2(password: bytes, salt: bytes) -> bytes:\n    logger.info(\"Starting Argon2id key derivation\")\n    try:\n        key = hash_secret_raw(\n            secret=password,\n            salt=salt,\n            time_cost=4,\n            memory_cost=102400,",
        "detail": "AHE_SDK.kdf.kdf",
        "documentation": {}
    },
    {
        "label": "pqc_keypair",
        "kind": 2,
        "importPath": "AHE_SDK.pqc.pqc",
        "description": "AHE_SDK.pqc.pqc",
        "peekOfCode": "def pqc_keypair(kem_name: str):\n    logger.info(f\"Generating keypair for PQC KEM: {kem_name}\")\n    kem = oqs.KeyEncapsulation(kem_name)\n    public_key = kem.generate_keypair()\n    logger.info(f\"Keypair generated for PQC KEM: {kem_name}\")\n    return kem, public_key\ndef pqc_encapsulate(kem, public_key: bytes):\n    logger.info(\"Starting PQC encapsulation\")\n    ct, ss = kem.encap_secret(public_key)\n    logger.info(\"PQC encapsulation completed\")",
        "detail": "AHE_SDK.pqc.pqc",
        "documentation": {}
    },
    {
        "label": "pqc_encapsulate",
        "kind": 2,
        "importPath": "AHE_SDK.pqc.pqc",
        "description": "AHE_SDK.pqc.pqc",
        "peekOfCode": "def pqc_encapsulate(kem, public_key: bytes):\n    logger.info(\"Starting PQC encapsulation\")\n    ct, ss = kem.encap_secret(public_key)\n    logger.info(\"PQC encapsulation completed\")\n    return ct, ss\ndef pqc_decapsulate(kem, ciphertext: bytes):\n    logger.info(\"Starting PQC decapsulation\")\n    ss = kem.decap_secret(ciphertext)\n    logger.info(\"PQC decapsulation completed\")\n    return ss",
        "detail": "AHE_SDK.pqc.pqc",
        "documentation": {}
    },
    {
        "label": "pqc_decapsulate",
        "kind": 2,
        "importPath": "AHE_SDK.pqc.pqc",
        "description": "AHE_SDK.pqc.pqc",
        "peekOfCode": "def pqc_decapsulate(kem, ciphertext: bytes):\n    logger.info(\"Starting PQC decapsulation\")\n    ss = kem.decap_secret(ciphertext)\n    logger.info(\"PQC decapsulation completed\")\n    return ss\ndef pqc_select_and_run(anomaly: bool):\n    pqc_candidates = PQC_STRONG_KEMS.copy() if anomaly else PQC_FAST_KEMS.copy()\n    random.shuffle(pqc_candidates)\n    for kem_name in pqc_candidates:\n        try:",
        "detail": "AHE_SDK.pqc.pqc",
        "documentation": {}
    },
    {
        "label": "pqc_select_and_run",
        "kind": 2,
        "importPath": "AHE_SDK.pqc.pqc",
        "description": "AHE_SDK.pqc.pqc",
        "peekOfCode": "def pqc_select_and_run(anomaly: bool):\n    pqc_candidates = PQC_STRONG_KEMS.copy() if anomaly else PQC_FAST_KEMS.copy()\n    random.shuffle(pqc_candidates)\n    for kem_name in pqc_candidates:\n        try:\n            logger.info(f\"Trying PQC KEM: {kem_name}\")\n            start = time.time()\n            kem, public_key = pqc_keypair(kem_name)\n            ciphertext, shared_secret = pqc_encapsulate(kem, public_key)\n            shared_secret_check = pqc_decapsulate(kem, ciphertext)",
        "detail": "AHE_SDK.pqc.pqc",
        "documentation": {}
    },
    {
        "label": "PQC_FAST_KEMS",
        "kind": 5,
        "importPath": "AHE_SDK.pqc.pqc",
        "description": "AHE_SDK.pqc.pqc",
        "peekOfCode": "PQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\nPQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\ndef pqc_keypair(kem_name: str):\n    logger.info(f\"Generating keypair for PQC KEM: {kem_name}\")\n    kem = oqs.KeyEncapsulation(kem_name)\n    public_key = kem.generate_keypair()\n    logger.info(f\"Keypair generated for PQC KEM: {kem_name}\")\n    return kem, public_key\ndef pqc_encapsulate(kem, public_key: bytes):\n    logger.info(\"Starting PQC encapsulation\")",
        "detail": "AHE_SDK.pqc.pqc",
        "documentation": {}
    },
    {
        "label": "PQC_STRONG_KEMS",
        "kind": 5,
        "importPath": "AHE_SDK.pqc.pqc",
        "description": "AHE_SDK.pqc.pqc",
        "peekOfCode": "PQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\ndef pqc_keypair(kem_name: str):\n    logger.info(f\"Generating keypair for PQC KEM: {kem_name}\")\n    kem = oqs.KeyEncapsulation(kem_name)\n    public_key = kem.generate_keypair()\n    logger.info(f\"Keypair generated for PQC KEM: {kem_name}\")\n    return kem, public_key\ndef pqc_encapsulate(kem, public_key: bytes):\n    logger.info(\"Starting PQC encapsulation\")\n    ct, ss = kem.encap_secret(public_key)",
        "detail": "AHE_SDK.pqc.pqc",
        "documentation": {}
    },
    {
        "label": "test_aes_encrypt_and_decrypt",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_aes",
        "description": "AHE_SDK.tests.test_aes",
        "peekOfCode": "def test_aes_encrypt_and_decrypt():\n    key = os.urandom(32)  # AES-256 key\n    plaintext = \"Adaptive Hashing Encryption - AES Test\"\n    # Encrypt\n    bundle = aes_encrypt(plaintext, key)\n    assert \"ciphertext\" in bundle\n    assert \"nonce\" in bundle\n    assert \"tag\" in bundle\n    # Decrypt\n    decrypted = aes_decrypt(bundle, key)",
        "detail": "AHE_SDK.tests.test_aes",
        "documentation": {}
    },
    {
        "label": "test_aes_encrypt_decrypt_empty_data",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_aes",
        "description": "AHE_SDK.tests.test_aes",
        "peekOfCode": "def test_aes_encrypt_decrypt_empty_data():\n    key = os.urandom(32)\n    plaintext = \"\"\n    bundle = aes_encrypt(plaintext, key)\n    decrypted = aes_decrypt(bundle, key)\n    assert decrypted == plaintext\ndef test_aes_encrypt_decrypt_large_data():\n    key = os.urandom(32)\n    plaintext = \"A\" * (1024 * 1024)  # 1 MB string\n    bundle = aes_encrypt(plaintext, key)",
        "detail": "AHE_SDK.tests.test_aes",
        "documentation": {}
    },
    {
        "label": "test_aes_encrypt_decrypt_large_data",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_aes",
        "description": "AHE_SDK.tests.test_aes",
        "peekOfCode": "def test_aes_encrypt_decrypt_large_data():\n    key = os.urandom(32)\n    plaintext = \"A\" * (1024 * 1024)  # 1 MB string\n    bundle = aes_encrypt(plaintext, key)\n    decrypted = aes_decrypt(bundle, key)\n    assert decrypted == plaintext\ndef test_aes_decrypt_with_wrong_key():\n    key = os.urandom(32)\n    wrong_key = os.urandom(32)\n    plaintext = \"Testing wrong key behavior\"",
        "detail": "AHE_SDK.tests.test_aes",
        "documentation": {}
    },
    {
        "label": "test_aes_decrypt_with_wrong_key",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_aes",
        "description": "AHE_SDK.tests.test_aes",
        "peekOfCode": "def test_aes_decrypt_with_wrong_key():\n    key = os.urandom(32)\n    wrong_key = os.urandom(32)\n    plaintext = \"Testing wrong key behavior\"\n    bundle = aes_encrypt(plaintext, key)\n    with pytest.raises(Exception):\n        aes_decrypt(bundle, wrong_key)",
        "detail": "AHE_SDK.tests.test_aes",
        "documentation": {}
    },
    {
        "label": "test_entropy_calculation",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_ahe",
        "description": "AHE_SDK.tests.test_ahe",
        "peekOfCode": "def test_entropy_calculation():\n    data = b\"abcdef\"\n    entropy = calculate_entropy(data)\n    assert entropy > 0, \"Entropy should be positive for non-empty data\"\ndef test_key_derivation():\n    key = derive_key(b\"pass\", b\"pubkey\", b\"cipher\")\n    assert len(key) == AES_KEY_SIZE, \"Derived key length mismatch\"\ndef test_metadata_encrypt_decrypt():\n    metadata = {\"nonce\": \"123\", \"tag\": \"abc\", \"kem\": \"Kyber\"}\n    encrypted = encrypt_metadata(metadata, TEST_PASSWORD)",
        "detail": "AHE_SDK.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "test_key_derivation",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_ahe",
        "description": "AHE_SDK.tests.test_ahe",
        "peekOfCode": "def test_key_derivation():\n    key = derive_key(b\"pass\", b\"pubkey\", b\"cipher\")\n    assert len(key) == AES_KEY_SIZE, \"Derived key length mismatch\"\ndef test_metadata_encrypt_decrypt():\n    metadata = {\"nonce\": \"123\", \"tag\": \"abc\", \"kem\": \"Kyber\"}\n    encrypted = encrypt_metadata(metadata, TEST_PASSWORD)\n    decrypted = decrypt_metadata(encrypted, TEST_PASSWORD)\n    assert decrypted == metadata, \"Metadata encryption/decryption failed\"\n# === Integration Tests ===\ndef test_full_encryption_decryption_flow():",
        "detail": "AHE_SDK.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "test_metadata_encrypt_decrypt",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_ahe",
        "description": "AHE_SDK.tests.test_ahe",
        "peekOfCode": "def test_metadata_encrypt_decrypt():\n    metadata = {\"nonce\": \"123\", \"tag\": \"abc\", \"kem\": \"Kyber\"}\n    encrypted = encrypt_metadata(metadata, TEST_PASSWORD)\n    decrypted = decrypt_metadata(encrypted, TEST_PASSWORD)\n    assert decrypted == metadata, \"Metadata encryption/decryption failed\"\n# === Integration Tests ===\ndef test_full_encryption_decryption_flow():\n    # Clean storage\n    for f in os.listdir(STORAGE_DIR):\n        os.remove(os.path.join(STORAGE_DIR, f))",
        "detail": "AHE_SDK.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "test_full_encryption_decryption_flow",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_ahe",
        "description": "AHE_SDK.tests.test_ahe",
        "peekOfCode": "def test_full_encryption_decryption_flow():\n    # Clean storage\n    for f in os.listdir(STORAGE_DIR):\n        os.remove(os.path.join(STORAGE_DIR, f))\n    # Encrypt\n    encrypt_message(TEST_MESSAGE, TEST_PASSWORD)\n    # Verify files exist\n    files = [f for f in os.listdir(STORAGE_DIR) if f.endswith(ENC_EXT)]\n    metas = [f for f in os.listdir(STORAGE_DIR) if f.endswith(META_EXT)]\n    assert files and metas, \"Ciphertext and metadata files not created\"",
        "detail": "AHE_SDK.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "test_decrypt_with_wrong_password",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_ahe",
        "description": "AHE_SDK.tests.test_ahe",
        "peekOfCode": "def test_decrypt_with_wrong_password():\n    # Should raise exception or fail integrity\n    with pytest.raises(Exception):\n        decrypt_latest(WRONG_PASSWORD)\ndef test_metadata_tampering_detection():\n    metas = sorted([f for f in os.listdir(STORAGE_DIR) if f.endswith(META_EXT)])\n    meta_path = os.path.join(STORAGE_DIR, metas[-1])\n    with open(meta_path, \"r+\") as f:\n        content = json.load(f)\n        content[\"nonce\"] = base64.b64encode(b\"fake_nonce\").decode()",
        "detail": "AHE_SDK.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "test_metadata_tampering_detection",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_ahe",
        "description": "AHE_SDK.tests.test_ahe",
        "peekOfCode": "def test_metadata_tampering_detection():\n    metas = sorted([f for f in os.listdir(STORAGE_DIR) if f.endswith(META_EXT)])\n    meta_path = os.path.join(STORAGE_DIR, metas[-1])\n    with open(meta_path, \"r+\") as f:\n        content = json.load(f)\n        content[\"nonce\"] = base64.b64encode(b\"fake_nonce\").decode()\n        f.seek(0)\n        json.dump(content, f)\n        f.truncate()\n    with pytest.raises(Exception):",
        "detail": "AHE_SDK.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "test_ciphertext_tampering_detection",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_ahe",
        "description": "AHE_SDK.tests.test_ahe",
        "peekOfCode": "def test_ciphertext_tampering_detection():\n    files = sorted([f for f in os.listdir(STORAGE_DIR) if f.endswith(ENC_EXT)])\n    enc_path = os.path.join(STORAGE_DIR, files[-1])\n    with open(enc_path, \"r+b\") as f:\n        f.seek(0)\n        f.write(b\"corrupt\")\n    with pytest.raises(Exception):\n        decrypt_latest(TEST_PASSWORD)\ndef test_performance_benchmark():\n    import time",
        "detail": "AHE_SDK.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "test_performance_benchmark",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_ahe",
        "description": "AHE_SDK.tests.test_ahe",
        "peekOfCode": "def test_performance_benchmark():\n    import time\n    start = time.time()\n    encrypt_message(\"Performance test message\", TEST_PASSWORD)\n    elapsed = time.time() - start\n    assert elapsed < 10, \"Encryption took too long (>10s)\"\n# === Anomaly & Security Checks ===\ndef test_entropy_and_anomaly_reporting(caplog):\n    encrypt_message(\"1234567890////\", TEST_PASSWORD)\n    logs = caplog.text",
        "detail": "AHE_SDK.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "test_entropy_and_anomaly_reporting",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_ahe",
        "description": "AHE_SDK.tests.test_ahe",
        "peekOfCode": "def test_entropy_and_anomaly_reporting(caplog):\n    encrypt_message(\"1234567890////\", TEST_PASSWORD)\n    logs = caplog.text\n    assert \"Entropy\" in logs or \"Anomaly\" in logs, \"Anomaly detection log missing\"",
        "detail": "AHE_SDK.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "TEST_MESSAGE",
        "kind": 5,
        "importPath": "AHE_SDK.tests.test_ahe",
        "description": "AHE_SDK.tests.test_ahe",
        "peekOfCode": "TEST_MESSAGE = \"This is a secret test message for AHE.\"\nTEST_PASSWORD = \"StrongPassword123\"\nWRONG_PASSWORD = \"WrongPass\"\nMETA_EXT = \".meta\"\nENC_EXT = \".ahe\"\n# === Utility Tests ===\ndef test_entropy_calculation():\n    data = b\"abcdef\"\n    entropy = calculate_entropy(data)\n    assert entropy > 0, \"Entropy should be positive for non-empty data\"",
        "detail": "AHE_SDK.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "TEST_PASSWORD",
        "kind": 5,
        "importPath": "AHE_SDK.tests.test_ahe",
        "description": "AHE_SDK.tests.test_ahe",
        "peekOfCode": "TEST_PASSWORD = \"StrongPassword123\"\nWRONG_PASSWORD = \"WrongPass\"\nMETA_EXT = \".meta\"\nENC_EXT = \".ahe\"\n# === Utility Tests ===\ndef test_entropy_calculation():\n    data = b\"abcdef\"\n    entropy = calculate_entropy(data)\n    assert entropy > 0, \"Entropy should be positive for non-empty data\"\ndef test_key_derivation():",
        "detail": "AHE_SDK.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "WRONG_PASSWORD",
        "kind": 5,
        "importPath": "AHE_SDK.tests.test_ahe",
        "description": "AHE_SDK.tests.test_ahe",
        "peekOfCode": "WRONG_PASSWORD = \"WrongPass\"\nMETA_EXT = \".meta\"\nENC_EXT = \".ahe\"\n# === Utility Tests ===\ndef test_entropy_calculation():\n    data = b\"abcdef\"\n    entropy = calculate_entropy(data)\n    assert entropy > 0, \"Entropy should be positive for non-empty data\"\ndef test_key_derivation():\n    key = derive_key(b\"pass\", b\"pubkey\", b\"cipher\")",
        "detail": "AHE_SDK.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "META_EXT",
        "kind": 5,
        "importPath": "AHE_SDK.tests.test_ahe",
        "description": "AHE_SDK.tests.test_ahe",
        "peekOfCode": "META_EXT = \".meta\"\nENC_EXT = \".ahe\"\n# === Utility Tests ===\ndef test_entropy_calculation():\n    data = b\"abcdef\"\n    entropy = calculate_entropy(data)\n    assert entropy > 0, \"Entropy should be positive for non-empty data\"\ndef test_key_derivation():\n    key = derive_key(b\"pass\", b\"pubkey\", b\"cipher\")\n    assert len(key) == AES_KEY_SIZE, \"Derived key length mismatch\"",
        "detail": "AHE_SDK.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "ENC_EXT",
        "kind": 5,
        "importPath": "AHE_SDK.tests.test_ahe",
        "description": "AHE_SDK.tests.test_ahe",
        "peekOfCode": "ENC_EXT = \".ahe\"\n# === Utility Tests ===\ndef test_entropy_calculation():\n    data = b\"abcdef\"\n    entropy = calculate_entropy(data)\n    assert entropy > 0, \"Entropy should be positive for non-empty data\"\ndef test_key_derivation():\n    key = derive_key(b\"pass\", b\"pubkey\", b\"cipher\")\n    assert len(key) == AES_KEY_SIZE, \"Derived key length mismatch\"\ndef test_metadata_encrypt_decrypt():",
        "detail": "AHE_SDK.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "TestAnomalyDetection",
        "kind": 6,
        "importPath": "AHE_SDK.tests.test_anomaly",
        "description": "AHE_SDK.tests.test_anomaly",
        "peekOfCode": "class TestAnomalyDetection(unittest.TestCase):\n    def test_no_anomaly_normal_entropy(self):\n        # No suspicious chars, entropy in normal range\n        input_str = \"HelloWorld\"\n        entropy = (ENTROPY_WARN_THRESHOLD_LOW + ENTROPY_WARN_THRESHOLD_HIGH) / 2\n        anomaly, reasons = detect_anomaly(input_str, entropy)\n        self.assertFalse(anomaly)\n        self.assertEqual(reasons, [])\n    def test_suspicious_characters_only(self):\n        # Suspicious chars present, entropy normal",
        "detail": "AHE_SDK.tests.test_anomaly",
        "documentation": {}
    },
    {
        "label": "test_ahe_encrypt_basic",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_core",
        "description": "AHE_SDK.tests.test_core",
        "peekOfCode": "def test_ahe_encrypt_basic():\n    message = \"Test encryption message\"\n    encrypted = ahe_encrypt_v9_5(message)\n    # Check the structure of returned dictionary\n    assert \"aes_encrypted\" in encrypted\n    assert \"pqc\" in encrypted\n    assert \"timing\" in encrypted\n    aes_bundle = encrypted[\"aes_encrypted\"]\n    assert \"ciphertext\" in aes_bundle\n    assert \"nonce\" in aes_bundle",
        "detail": "AHE_SDK.tests.test_core",
        "documentation": {}
    },
    {
        "label": "test_ahe_encrypt_decrypt_cycle",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_core",
        "description": "AHE_SDK.tests.test_core",
        "peekOfCode": "def test_ahe_encrypt_decrypt_cycle():\n    message = \"Another test message\"\n    encrypted = ahe_encrypt_v9_5(message)\n    # You will need the AES key for decryption  \n    # In current core.py, the AES key is derived internally in the encryption function.\n    # For test purpose, you might want to adjust core.py to return the AES key for this test,\n    # or mock derive_key_hybrid_with_pqc to expose the key.\n    # For demonstration, let's say you modify ahe_encrypt_v9_5 to also return AES key:\n    # encrypted, aes_key = ahe_encrypt_v9_5(message)\n    # Then do:",
        "detail": "AHE_SDK.tests.test_core",
        "documentation": {}
    },
    {
        "label": "test_ahe_decrypt",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_core",
        "description": "AHE_SDK.tests.test_core",
        "peekOfCode": "def test_ahe_decrypt():\n    # This test will be added later after we refactor key management\n    pass",
        "detail": "AHE_SDK.tests.test_core",
        "documentation": {}
    },
    {
        "label": "test_aes_encrypt_and_decrypt",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_crypto",
        "description": "AHE_SDK.tests.test_crypto",
        "peekOfCode": "def test_aes_encrypt_and_decrypt():\n    key = os.urandom(32)  # AES-256 key\n    plaintext = b\"Adaptive Hashing Encryption - AES Test\"\n    ciphertext, nonce, tag = aes_encrypt(plaintext, key)\n    decrypted = aes_decrypt(ciphertext, key, nonce, tag)\n    assert decrypted == plaintext\n# Test 2: Empty Message\ndef test_aes_encrypt_decrypt_empty_message():\n    key = os.urandom(32)\n    plaintext = b\"\"",
        "detail": "AHE_SDK.tests.test_crypto",
        "documentation": {}
    },
    {
        "label": "test_aes_encrypt_decrypt_empty_message",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_crypto",
        "description": "AHE_SDK.tests.test_crypto",
        "peekOfCode": "def test_aes_encrypt_decrypt_empty_message():\n    key = os.urandom(32)\n    plaintext = b\"\"\n    ciphertext, nonce, tag = aes_encrypt(plaintext, key)\n    decrypted = aes_decrypt(ciphertext, key, nonce, tag)\n    assert decrypted == plaintext\n# Test 3: Large Data (1 MB)\ndef test_aes_encrypt_decrypt_large_data():\n    key = os.urandom(32)\n    plaintext = os.urandom(1024 * 1024)  # 1 MB random data",
        "detail": "AHE_SDK.tests.test_crypto",
        "documentation": {}
    },
    {
        "label": "test_aes_encrypt_decrypt_large_data",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_crypto",
        "description": "AHE_SDK.tests.test_crypto",
        "peekOfCode": "def test_aes_encrypt_decrypt_large_data():\n    key = os.urandom(32)\n    plaintext = os.urandom(1024 * 1024)  # 1 MB random data\n    start = time.time()\n    ciphertext, nonce, tag = aes_encrypt(plaintext, key)\n    decrypted = aes_decrypt(ciphertext, key, nonce, tag)\n    duration = time.time() - start\n    assert decrypted == plaintext\n    print(f\"\\n[PERF] 1MB AES-GCM Encrypt+Decrypt took {duration:.4f} seconds\")\n# Test 4: Wrong Key",
        "detail": "AHE_SDK.tests.test_crypto",
        "documentation": {}
    },
    {
        "label": "test_aes_decrypt_with_wrong_key",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_crypto",
        "description": "AHE_SDK.tests.test_crypto",
        "peekOfCode": "def test_aes_decrypt_with_wrong_key():\n    key = os.urandom(32)\n    wrong_key = os.urandom(32)\n    plaintext = b\"Testing wrong key behavior\"\n    ciphertext, nonce, tag = aes_encrypt(plaintext, key)\n    with pytest.raises(ValueError):\n        aes_decrypt(ciphertext, wrong_key, nonce, tag)\n# Test 5: Tampered Ciphertext\ndef test_aes_decrypt_with_tampered_ciphertext():\n    key = os.urandom(32)",
        "detail": "AHE_SDK.tests.test_crypto",
        "documentation": {}
    },
    {
        "label": "test_aes_decrypt_with_tampered_ciphertext",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_crypto",
        "description": "AHE_SDK.tests.test_crypto",
        "peekOfCode": "def test_aes_decrypt_with_tampered_ciphertext():\n    key = os.urandom(32)\n    plaintext = b\"Testing tampered ciphertext\"\n    ciphertext, nonce, tag = aes_encrypt(plaintext, key)\n    # Modify ciphertext\n    tampered_ciphertext = bytearray(ciphertext)\n    tampered_ciphertext[0] ^= 0x01  # Flip a bit\n    with pytest.raises(ValueError):\n        aes_decrypt(bytes(tampered_ciphertext), key, nonce, tag)",
        "detail": "AHE_SDK.tests.test_crypto",
        "documentation": {}
    },
    {
        "label": "TestDisplayUtils",
        "kind": 6,
        "importPath": "AHE_SDK.tests.test_display",
        "description": "AHE_SDK.tests.test_display",
        "peekOfCode": "class TestDisplayUtils(unittest.TestCase):\n    def test_full_display_when_length_is_small(self):\n        data = b\"\\x01\\x02\\x03\"\n        result = shorten_bytes_for_display(data, length=10)\n        self.assertEqual(result, data.hex())\n    def test_truncated_display_when_length_is_large(self):\n        data = b\"\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\x09\\x0A\\x0B\\x0C\"\n        result = shorten_bytes_for_display(data, length=5)\n        expected_prefix = data[:5].hex() + \"...\"\n        self.assertEqual(result, expected_prefix)",
        "detail": "AHE_SDK.tests.test_display",
        "documentation": {}
    },
    {
        "label": "TestEntropyFunctions",
        "kind": 6,
        "importPath": "AHE_SDK.tests.test_entropy",
        "description": "AHE_SDK.tests.test_entropy",
        "peekOfCode": "class TestEntropyFunctions(unittest.TestCase):\n    def test_calculate_shannon_entropy_normal(self):\n        data = b\"aaaabbbbccccdddd\"\n        entropy_val = entropy.calculate_shannon_entropy(data)\n        self.assertGreater(entropy_val, 0)\n        self.assertLessEqual(entropy_val, 4)\n    def test_calculate_shannon_entropy_empty(self):\n        data = b\"\"\n        entropy_val = entropy.calculate_shannon_entropy(data)\n        self.assertEqual(entropy_val, 0)",
        "detail": "AHE_SDK.tests.test_entropy",
        "documentation": {}
    },
    {
        "label": "TestHashingFunctions",
        "kind": 6,
        "importPath": "AHE_SDK.tests.test_hashing",
        "description": "AHE_SDK.tests.test_hashing",
        "peekOfCode": "class TestHashingFunctions(unittest.TestCase):\n    def test_hash_stage_sha256(self):\n        data = b\"test\"\n        result = hash_stage(data, \"sha256\")\n        self.assertEqual(len(result), hashlib.sha256().digest_size)\n        self.assertIsInstance(result, bytes)\n    def test_hash_stage_sha512(self):\n        data = b\"test\"\n        result = hash_stage(data, \"sha512\")\n        self.assertEqual(len(result), hashlib.sha512().digest_size)",
        "detail": "AHE_SDK.tests.test_hashing",
        "documentation": {}
    },
    {
        "label": "TestAHEPipeline",
        "kind": 6,
        "importPath": "AHE_SDK.tests.test_intergrated",
        "description": "AHE_SDK.tests.test_intergrated",
        "peekOfCode": "class TestAHEPipeline(unittest.TestCase):\n    def test_encryption_pipeline(self):\n        message = \"Hello Adaptive Hashing Encryption!\"  # Test input\n        result = ahe_encrypt_v9_5(message)\n        # Validate result structure\n        self.assertIn(\"aes_encrypted\", result)\n        self.assertIn(\"pqc\", result)\n        self.assertIn(\"timing\", result)\n        # Check AES structure\n        aes_bundle = result[\"aes_encrypted\"]",
        "detail": "AHE_SDK.tests.test_intergrated",
        "documentation": {}
    },
    {
        "label": "TestIntegratedEC",
        "kind": 6,
        "importPath": "AHE_SDK.tests.test_intergrated_EC",
        "description": "AHE_SDK.tests.test_intergrated_EC",
        "peekOfCode": "class TestIntegratedEC(unittest.TestCase):\n    \"\"\"Integration Test: Full AHE Encryption Pipeline Only\"\"\"\n    def test_full_encryption_pipeline(self):\n        message = \"The future of cryptography is adaptive and quantum-secure.\"\n        print(\"\\n=== Running AHE v9.5 Encryption Pipeline Test ===\")\n        print(f\" Input Message: {message}\")\n        start_time = time.time()\n        result = ahe_encrypt_v9_5(message)\n        elapsed_time = time.time() - start_time\n        #  Basic Structure Checks",
        "detail": "AHE_SDK.tests.test_intergrated_EC",
        "documentation": {}
    },
    {
        "label": "test_derive_key_argon2",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_kdf",
        "description": "AHE_SDK.tests.test_kdf",
        "peekOfCode": "def test_derive_key_argon2():\n    password = b\"password123\"\n    salt = os.urandom(16)\n    key = derive_key_argon2(password, salt)\n    assert isinstance(key, bytes)\n    assert len(key) == 32\ndef test_derive_key_shake():\n    password = b\"password123\"\n    salt = os.urandom(16)\n    key_128 = derive_key_shake(password, salt, 128)",
        "detail": "AHE_SDK.tests.test_kdf",
        "documentation": {}
    },
    {
        "label": "test_derive_key_shake",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_kdf",
        "description": "AHE_SDK.tests.test_kdf",
        "peekOfCode": "def test_derive_key_shake():\n    password = b\"password123\"\n    salt = os.urandom(16)\n    key_128 = derive_key_shake(password, salt, 128)\n    key_256 = derive_key_shake(password, salt, 256)\n    assert isinstance(key_128, bytes)\n    assert len(key_128) == 32\n    assert isinstance(key_256, bytes)\n    assert len(key_256) == 32\ndef test_derive_key_hkdf():",
        "detail": "AHE_SDK.tests.test_kdf",
        "documentation": {}
    },
    {
        "label": "test_derive_key_hkdf",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_kdf",
        "description": "AHE_SDK.tests.test_kdf",
        "peekOfCode": "def test_derive_key_hkdf():\n    password = b\"password123\"\n    salt = os.urandom(16)\n    key = derive_key_hkdf(password, salt)\n    assert isinstance(key, bytes)\n    assert len(key) == 32\n@pytest.mark.parametrize(\"anomaly\", [True, False])\ndef test_derive_key_hybrid_with_pqc(anomaly):\n    password = b\"password123\"\n    salt = os.urandom(16)",
        "detail": "AHE_SDK.tests.test_kdf",
        "documentation": {}
    },
    {
        "label": "test_derive_key_hybrid_with_pqc",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_kdf",
        "description": "AHE_SDK.tests.test_kdf",
        "peekOfCode": "def test_derive_key_hybrid_with_pqc(anomaly):\n    password = b\"password123\"\n    salt = os.urandom(16)\n    # Run the full hybrid KDF with real oqs.KeyEncapsulation calls\n    result = derive_key_hybrid_with_pqc(password, salt, anomaly)\n    # Unpack results\n    final_key, shake_time, kem_time, kem_name, public_key, ciphertext, shared_secret = result\n    # Basic assertions on outputs\n    assert isinstance(final_key, bytes)\n    assert len(final_key) == 32",
        "detail": "AHE_SDK.tests.test_kdf",
        "documentation": {}
    },
    {
        "label": "test_pqc_keypair_generation",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_pqc",
        "description": "AHE_SDK.tests.test_pqc",
        "peekOfCode": "def test_pqc_keypair_generation(kem_name):\n    \"\"\"\n    Test that all supported PQC KEMs generate valid keypairs.\n    EXPECTED:\n    - kem: Valid KeyEncapsulation object\n    - public_key: Non-empty bytes\n    \"\"\"\n    kem, public_key = pqc_keypair(kem_name)\n    assert kem is not None, f\"KEM object is None for {kem_name}\"\n    assert isinstance(public_key, bytes), f\"Public key is not bytes for {kem_name}\"",
        "detail": "AHE_SDK.tests.test_pqc",
        "documentation": {}
    },
    {
        "label": "test_pqc_encapsulate_and_decapsulate",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_pqc",
        "description": "AHE_SDK.tests.test_pqc",
        "peekOfCode": "def test_pqc_encapsulate_and_decapsulate(kem_name):\n    \"\"\"\n    Test correctness: Encapsulation followed by decapsulation\n    MUST result in the same shared secret.\n    \"\"\"\n    kem, public_key = pqc_keypair(kem_name)\n    ciphertext, shared_secret = pqc_encapsulate(kem, public_key)\n    assert isinstance(ciphertext, bytes), \"Ciphertext is not bytes\"\n    assert isinstance(shared_secret, bytes), \"Shared secret is not bytes\"\n    # Decapsulate and compare secrets",
        "detail": "AHE_SDK.tests.test_pqc",
        "documentation": {}
    },
    {
        "label": "test_pqc_wrong_key_decapsulation",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_pqc",
        "description": "AHE_SDK.tests.test_pqc",
        "peekOfCode": "def test_pqc_wrong_key_decapsulation():\n    \"\"\"\n    WRONG KEY TEST:\n    - Encapsulate with kem1, decapsulate with kem2.\n    EXPECTED:\n    - No error thrown\n    - Derived shared secret is DIFFERENT (by design for IND-CCA2 security).\n    \"\"\"\n    kem1, pk1 = pqc_keypair(\"Kyber512\")\n    kem2, pk2 = pqc_keypair(\"Kyber512\")",
        "detail": "AHE_SDK.tests.test_pqc",
        "documentation": {}
    },
    {
        "label": "test_pqc_select_and_run",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_pqc",
        "description": "AHE_SDK.tests.test_pqc",
        "peekOfCode": "def test_pqc_select_and_run(anomaly):\n    \"\"\"\n    Test adaptive PQC selection:\n    - anomaly=True  Strong KEMs (e.g., Kyber1024)\n    - anomaly=False  Fast KEMs (e.g., Kyber512)\n    EXPECTED:\n    - Successfully completes without exception.\n    \"\"\"\n    kem_name, pk, ct, ss = pqc_select_and_run(anomaly)\n    assert kem_name in (PQC_FAST_KEMS + PQC_STRONG_KEMS), \"Returned KEM not in supported list\"",
        "detail": "AHE_SDK.tests.test_pqc",
        "documentation": {}
    },
    {
        "label": "test_pqc_performance",
        "kind": 2,
        "importPath": "AHE_SDK.tests.test_pqc",
        "description": "AHE_SDK.tests.test_pqc",
        "peekOfCode": "def test_pqc_performance():\n    \"\"\"\n    Performance Benchmark:\n    Ensure that PQC encapsulation + decapsulation completes under PERFORMANCE_THRESHOLD.\n    \"\"\"\n    kem, pk = pqc_keypair(\"Kyber512\")\n    start = time.time()\n    ct, ss = pqc_encapsulate(kem, pk)\n    pqc_decapsulate(kem, ct)\n    elapsed = time.time() - start",
        "detail": "AHE_SDK.tests.test_pqc",
        "documentation": {}
    },
    {
        "label": "PERFORMANCE_THRESHOLD",
        "kind": 5,
        "importPath": "AHE_SDK.tests.test_pqc",
        "description": "AHE_SDK.tests.test_pqc",
        "peekOfCode": "PERFORMANCE_THRESHOLD = 0.5\n@pytest.mark.parametrize(\"kem_name\", PQC_FAST_KEMS + PQC_STRONG_KEMS)\ndef test_pqc_keypair_generation(kem_name):\n    \"\"\"\n    Test that all supported PQC KEMs generate valid keypairs.\n    EXPECTED:\n    - kem: Valid KeyEncapsulation object\n    - public_key: Non-empty bytes\n    \"\"\"\n    kem, public_key = pqc_keypair(kem_name)",
        "detail": "AHE_SDK.tests.test_pqc",
        "documentation": {}
    },
    {
        "label": "pytestmark",
        "kind": 5,
        "importPath": "AHE_SDK.tests.test_pqc",
        "description": "AHE_SDK.tests.test_pqc",
        "peekOfCode": "pytestmark = pytest.mark.functional",
        "detail": "AHE_SDK.tests.test_pqc",
        "documentation": {}
    },
    {
        "label": "detect_anomaly",
        "kind": 2,
        "importPath": "AHE_SDK.utils.anomaly",
        "description": "AHE_SDK.utils.anomaly",
        "peekOfCode": "def detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    try:\n        suspicious_chars = \"0123456789+/=\\n\"\n        reasons = []\n        if any(c in input_data for c in suspicious_chars):\n            reasons.append(\"Suspicious characters detected\")\n            logger.info(\"Anomaly check: Suspicious characters detected.\")\n        if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:\n            reasons.append(\"Entropy out of range\")\n            logger.info(f\"Anomaly check: Entropy score {entropy_score} out of range.\")",
        "detail": "AHE_SDK.utils.anomaly",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_LOW",
        "kind": 5,
        "importPath": "AHE_SDK.utils.anomaly",
        "description": "AHE_SDK.utils.anomaly",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_LOW = 3.5\nENTROPY_WARN_THRESHOLD_HIGH = 4.75\ndef detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    try:\n        suspicious_chars = \"0123456789+/=\\n\"\n        reasons = []\n        if any(c in input_data for c in suspicious_chars):\n            reasons.append(\"Suspicious characters detected\")\n            logger.info(\"Anomaly check: Suspicious characters detected.\")\n        if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:",
        "detail": "AHE_SDK.utils.anomaly",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_HIGH",
        "kind": 5,
        "importPath": "AHE_SDK.utils.anomaly",
        "description": "AHE_SDK.utils.anomaly",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_HIGH = 4.75\ndef detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    try:\n        suspicious_chars = \"0123456789+/=\\n\"\n        reasons = []\n        if any(c in input_data for c in suspicious_chars):\n            reasons.append(\"Suspicious characters detected\")\n            logger.info(\"Anomaly check: Suspicious characters detected.\")\n        if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:\n            reasons.append(\"Entropy out of range\")",
        "detail": "AHE_SDK.utils.anomaly",
        "documentation": {}
    },
    {
        "label": "shorten_bytes_for_display",
        "kind": 2,
        "importPath": "AHE_SDK.utils.display",
        "description": "AHE_SDK.utils.display",
        "peekOfCode": "def shorten_bytes_for_display(data: bytes, length=10):\n    try:\n        if len(data) <= length:\n            result = data.hex()\n            logger.info(f\"Shortened bytes for display (full): {result}\")\n            return result\n        result = data[:length].hex() + \"...\"\n        logger.info(f\"Shortened bytes for display (truncated): {result}\")\n        return result\n    except Exception as e:",
        "detail": "AHE_SDK.utils.display",
        "documentation": {}
    },
    {
        "label": "calculate_shannon_entropy",
        "kind": 2,
        "importPath": "AHE_SDK.utils.entropy",
        "description": "AHE_SDK.utils.entropy",
        "peekOfCode": "def calculate_shannon_entropy(data: bytes) -> float:\n    try:\n        if not data:\n            logger.warning(\"Empty data passed to calculate_shannon_entropy\")\n            return 0.0\n        freq = {b: data.count(b)/len(data) for b in set(data)}\n        entropy = -sum(p * math.log2(p) for p in freq.values())\n        logger.info(f\"Calculated Shannon entropy: {entropy:.4f}\")\n        return entropy\n    except Exception as e:",
        "detail": "AHE_SDK.utils.entropy",
        "documentation": {}
    },
    {
        "label": "get_environment_entropy",
        "kind": 2,
        "importPath": "AHE_SDK.utils.entropy",
        "description": "AHE_SDK.utils.entropy",
        "peekOfCode": "def get_environment_entropy() -> bytes:\n    try:\n        raw = (\n            str(uuid.getnode()) +\n            str(platform.system()) +\n            str(platform.release()) +\n            str(os.cpu_count()) +\n            str(os.getpid()) +\n            str(time.time()) +\n            str(socket.gethostname())",
        "detail": "AHE_SDK.utils.entropy",
        "documentation": {}
    },
    {
        "label": "hash_stage",
        "kind": 2,
        "importPath": "AHE_SDK.utils.hashing",
        "description": "AHE_SDK.utils.hashing",
        "peekOfCode": "def hash_stage(data: bytes, algo: str) -> bytes:\n    try:\n        h = hashlib.new(algo)\n        h.update(data)\n        logger.info(f\"Hashed data using {algo}\")\n        return h.digest()\n    except Exception as e:\n        logger.error(f\"Error hashing data with {algo}: {e}\", exc_info=True)\n        return b\"\"\ndef multi_stage_hash(data: bytes, extra_entropy: bytes) -> bytes:",
        "detail": "AHE_SDK.utils.hashing",
        "documentation": {}
    },
    {
        "label": "multi_stage_hash",
        "kind": 2,
        "importPath": "AHE_SDK.utils.hashing",
        "description": "AHE_SDK.utils.hashing",
        "peekOfCode": "def multi_stage_hash(data: bytes, extra_entropy: bytes) -> bytes:\n    try:\n        output = data\n        shuffled_algos = random.sample(HASH_ALGORITHMS, len(HASH_ALGORITHMS))\n        logger.info(f\"Hash algorithms order: {shuffled_algos}\")\n        for algo in shuffled_algos:\n            output = hash_stage(output + extra_entropy, algo)\n        logger.info(\"Completed multi-stage hashing\")\n        return output\n    except Exception as e:",
        "detail": "AHE_SDK.utils.hashing",
        "documentation": {}
    },
    {
        "label": "HASH_ALGORITHMS",
        "kind": 5,
        "importPath": "AHE_SDK.utils.hashing",
        "description": "AHE_SDK.utils.hashing",
        "peekOfCode": "HASH_ALGORITHMS = [\n    \"sha256\",\n    \"sha512\",\n    \"sha3_256\",\n    \"sha3_512\"\n]\ndef hash_stage(data: bytes, algo: str) -> bytes:\n    try:\n        h = hashlib.new(algo)\n        h.update(data)",
        "detail": "AHE_SDK.utils.hashing",
        "documentation": {}
    },
    {
        "label": "AHEClient",
        "kind": 6,
        "importPath": "AHE_SDK.ahe_sdk",
        "description": "AHE_SDK.ahe_sdk",
        "peekOfCode": "class AHEClient:\n    def _init_(self, storage_dir=\"secure_storage\"):\n        self.storage_dir = storage_dir\n        if not os.path.exists(self.storage_dir):\n            os.makedirs(self.storage_dir)\n        logger.info(\"[INIT] AHEClient initialized with storage directory\")\n    def encrypt(self, message: str, password: str) -> dict:\n        \"\"\"\n        Encrypt a message using AHE and return metadata info.\n        \"\"\"",
        "detail": "AHE_SDK.ahe_sdk",
        "documentation": {}
    },
    {
        "label": "custom_openapi",
        "kind": 2,
        "importPath": "AHE_SDK.api",
        "description": "AHE_SDK.api",
        "peekOfCode": "def custom_openapi():\n    if app.openapi_schema:\n        return app.openapi_schema\n    openapi_schema = original_openapi()\n    for path in openapi_schema.get(\"paths\", {}).values():\n        for method in path.values():\n            responses = method.get(\"responses\", {})\n            responses.pop(\"422\", None)\n            responses.pop(\"500\", None)\n    app.openapi_schema = openapi_schema",
        "detail": "AHE_SDK.api",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "AHE_SDK.api",
        "description": "AHE_SDK.api",
        "peekOfCode": "app = FastAPI(\n    title=\"Adaptive Hashing Encryption API\",\n    description=\"Elite Quantum-Safe Encryption API\",\n    version=\"1.0.0\"\n)\n# Remove 422 & 500 from docs\noriginal_openapi = app.openapi\ndef custom_openapi():\n    if app.openapi_schema:\n        return app.openapi_schema",
        "detail": "AHE_SDK.api",
        "documentation": {}
    },
    {
        "label": "original_openapi",
        "kind": 5,
        "importPath": "AHE_SDK.api",
        "description": "AHE_SDK.api",
        "peekOfCode": "original_openapi = app.openapi\ndef custom_openapi():\n    if app.openapi_schema:\n        return app.openapi_schema\n    openapi_schema = original_openapi()\n    for path in openapi_schema.get(\"paths\", {}).values():\n        for method in path.values():\n            responses = method.get(\"responses\", {})\n            responses.pop(\"422\", None)\n            responses.pop(\"500\", None)",
        "detail": "AHE_SDK.api",
        "documentation": {}
    },
    {
        "label": "app.openapi",
        "kind": 5,
        "importPath": "AHE_SDK.api",
        "description": "AHE_SDK.api",
        "peekOfCode": "app.openapi = custom_openapi\n@app.get(\"/health\", response_model=HealthResponse)\nasync def health_check():\n    return {\"status\": \"healthy\"}\n@app.post(\"/encrypt\", response_model=EncryptResponse)\nasync def encrypt(req: EncryptRequest):\n    try:\n        logger.info(\"[ENCRYPT] Processing request...\")\n        data = encrypt_message(req.message, req.password)\n        return {",
        "detail": "AHE_SDK.api",
        "documentation": {}
    },
    {
        "label": "ColorFormatter",
        "kind": 6,
        "importPath": "AHE_SDK.logger",
        "description": "AHE_SDK.logger",
        "peekOfCode": "class ColorFormatter(logging.Formatter):\n    COLORS = {\n        'DEBUG': Fore.CYAN,\n        'INFO': Fore.GREEN,\n        'WARNING': Fore.YELLOW,\n        'ERROR': Fore.RED,\n        'CRITICAL': Fore.RED + Style.BRIGHT,\n    }\n    # Custom keywords to color-code messages\n    KEYWORD_COLORS = {",
        "detail": "AHE_SDK.logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "AHE_SDK.logger",
        "description": "AHE_SDK.logger",
        "peekOfCode": "logger = logging.getLogger(\"AHE_SDK\")\nlogger.setLevel(logging.DEBUG)  # Capture all levels\nfile_handler = logging.FileHandler(\"logs/ahe_sdk.log\")\nfile_handler.setLevel(logging.DEBUG)\nfile_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler.setFormatter(file_formatter)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.DEBUG)\nconsole_formatter = ColorFormatter('%(asctime)s - %(levelname)s - %(message)s')\nconsole_handler.setFormatter(console_formatter)",
        "detail": "AHE_SDK.logger",
        "documentation": {}
    },
    {
        "label": "file_handler",
        "kind": 5,
        "importPath": "AHE_SDK.logger",
        "description": "AHE_SDK.logger",
        "peekOfCode": "file_handler = logging.FileHandler(\"logs/ahe_sdk.log\")\nfile_handler.setLevel(logging.DEBUG)\nfile_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler.setFormatter(file_formatter)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.DEBUG)\nconsole_formatter = ColorFormatter('%(asctime)s - %(levelname)s - %(message)s')\nconsole_handler.setFormatter(console_formatter)\nlogger.addHandler(file_handler)\nlogger.addHandler(console_handler)",
        "detail": "AHE_SDK.logger",
        "documentation": {}
    },
    {
        "label": "file_formatter",
        "kind": 5,
        "importPath": "AHE_SDK.logger",
        "description": "AHE_SDK.logger",
        "peekOfCode": "file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler.setFormatter(file_formatter)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.DEBUG)\nconsole_formatter = ColorFormatter('%(asctime)s - %(levelname)s - %(message)s')\nconsole_handler.setFormatter(console_formatter)\nlogger.addHandler(file_handler)\nlogger.addHandler(console_handler)",
        "detail": "AHE_SDK.logger",
        "documentation": {}
    },
    {
        "label": "console_handler",
        "kind": 5,
        "importPath": "AHE_SDK.logger",
        "description": "AHE_SDK.logger",
        "peekOfCode": "console_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.DEBUG)\nconsole_formatter = ColorFormatter('%(asctime)s - %(levelname)s - %(message)s')\nconsole_handler.setFormatter(console_formatter)\nlogger.addHandler(file_handler)\nlogger.addHandler(console_handler)",
        "detail": "AHE_SDK.logger",
        "documentation": {}
    },
    {
        "label": "console_formatter",
        "kind": 5,
        "importPath": "AHE_SDK.logger",
        "description": "AHE_SDK.logger",
        "peekOfCode": "console_formatter = ColorFormatter('%(asctime)s - %(levelname)s - %(message)s')\nconsole_handler.setFormatter(console_formatter)\nlogger.addHandler(file_handler)\nlogger.addHandler(console_handler)",
        "detail": "AHE_SDK.logger",
        "documentation": {}
    },
    {
        "label": "interactive_menu",
        "kind": 2,
        "importPath": "AHE_SDK.main",
        "description": "AHE_SDK.main",
        "peekOfCode": "def interactive_menu():\n    print(\"=== Adaptive Hashing Encryption SDK ===\")\n    while True:\n        print(\"\\nOptions:\")\n        print(\"1. Encrypt a message\")\n        print(\"2. Decrypt the latest message\")\n        print(\"3. Exit\")\n        choice = input(\"Choice: \").strip()\n        if choice == \"1\":\n            message = input(\"Enter message to encrypt: \").strip()",
        "detail": "AHE_SDK.main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "AHE_SDK.main",
        "description": "AHE_SDK.main",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=\"Adaptive Hashing Encryption (AHE) CLI Tool\")\n    parser.add_argument(\"--encrypt\", type=str, help=\"Message to encrypt\")\n    parser.add_argument(\"--decrypt\", action=\"store_true\", help=\"Decrypt the latest message\")\n    parser.add_argument(\"--password\", type=str, help=\"Password for encryption/decryption\")\n    args = parser.parse_args()\n    if args.encrypt and args.password:\n        encrypt_message(args.encrypt, args.password)\n    elif args.decrypt and args.password:\n        try:",
        "detail": "AHE_SDK.main",
        "documentation": {}
    },
    {
        "label": "EncryptRequest",
        "kind": 6,
        "importPath": "AHE_SDK.schemas",
        "description": "AHE_SDK.schemas",
        "peekOfCode": "class EncryptRequest(BaseModel):\n    message: str\n    password: str\nclass EncryptResponse(BaseModel):\n    status: str\n    ciphertext_path: Optional[str]\n    metadata_path: Optional[str]\n    pqc_profile: Optional[str]\n    entropy_score: Optional[float]\n    anomaly_detected: Optional[bool]",
        "detail": "AHE_SDK.schemas",
        "documentation": {}
    },
    {
        "label": "EncryptResponse",
        "kind": 6,
        "importPath": "AHE_SDK.schemas",
        "description": "AHE_SDK.schemas",
        "peekOfCode": "class EncryptResponse(BaseModel):\n    status: str\n    ciphertext_path: Optional[str]\n    metadata_path: Optional[str]\n    pqc_profile: Optional[str]\n    entropy_score: Optional[float]\n    anomaly_detected: Optional[bool]\nclass DecryptRequest(BaseModel):\n    password: str\nclass DecryptResponse(BaseModel):",
        "detail": "AHE_SDK.schemas",
        "documentation": {}
    },
    {
        "label": "DecryptRequest",
        "kind": 6,
        "importPath": "AHE_SDK.schemas",
        "description": "AHE_SDK.schemas",
        "peekOfCode": "class DecryptRequest(BaseModel):\n    password: str\nclass DecryptResponse(BaseModel):\n    status: str\n    decrypted_message: Optional[str]\n    pqc_profile: Optional[str]\n    entropy_score: Optional[float]\n    anomaly_detected: Optional[bool]\nclass HealthResponse(BaseModel):\n    status: str",
        "detail": "AHE_SDK.schemas",
        "documentation": {}
    },
    {
        "label": "DecryptResponse",
        "kind": 6,
        "importPath": "AHE_SDK.schemas",
        "description": "AHE_SDK.schemas",
        "peekOfCode": "class DecryptResponse(BaseModel):\n    status: str\n    decrypted_message: Optional[str]\n    pqc_profile: Optional[str]\n    entropy_score: Optional[float]\n    anomaly_detected: Optional[bool]\nclass HealthResponse(BaseModel):\n    status: str",
        "detail": "AHE_SDK.schemas",
        "documentation": {}
    },
    {
        "label": "HealthResponse",
        "kind": 6,
        "importPath": "AHE_SDK.schemas",
        "description": "AHE_SDK.schemas",
        "peekOfCode": "class HealthResponse(BaseModel):\n    status: str",
        "detail": "AHE_SDK.schemas",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "AHE_SDK_V6.aes.aes",
        "description": "AHE_SDK_V6.aes.aes",
        "peekOfCode": "def aes_encrypt(message: str, key: bytes) -> dict:\n    logger.info(\"Starting AES encryption\")\n    try:\n        nonce = get_random_bytes(12)\n        cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n        ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n        logger.info(\"AES encryption successful\")\n        return {\n            \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),\n            \"nonce\": urlsafe_b64encode(nonce).decode(),",
        "detail": "AHE_SDK_V6.aes.aes",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "AHE_SDK_V6.aes.aes",
        "description": "AHE_SDK_V6.aes.aes",
        "peekOfCode": "def aes_decrypt(bundle: dict, key: bytes) -> str:\n    logger.info(\"Starting AES decryption\")\n    try:\n        nonce = urlsafe_b64decode(bundle[\"nonce\"])\n        tag = urlsafe_b64decode(bundle[\"tag\"])\n        ciphertext = urlsafe_b64decode(bundle[\"ciphertext\"])\n        cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n        plaintext = cipher.decrypt_and_verify(ciphertext, tag)\n        logger.info(\"AES decryption successful\")\n        return plaintext.decode()",
        "detail": "AHE_SDK_V6.aes.aes",
        "documentation": {}
    },
    {
        "label": "calculate_entropy",
        "kind": 2,
        "importPath": "AHE_SDK_V6.core.core",
        "description": "AHE_SDK_V6.core.core",
        "peekOfCode": "def calculate_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef detect_anomaly(entropy_score: float, message: str):\n    reasons = []\n    suspicious_chars = \"0123456789+/=\\n\"\n    if any(c in message for c in suspicious_chars):\n        reasons.append(\"Suspicious characters detected\")",
        "detail": "AHE_SDK_V6.core.core",
        "documentation": {}
    },
    {
        "label": "detect_anomaly",
        "kind": 2,
        "importPath": "AHE_SDK_V6.core.core",
        "description": "AHE_SDK_V6.core.core",
        "peekOfCode": "def detect_anomaly(entropy_score: float, message: str):\n    reasons = []\n    suspicious_chars = \"0123456789+/=\\n\"\n    if any(c in message for c in suspicious_chars):\n        reasons.append(\"Suspicious characters detected\")\n    if entropy_score < ENTROPY_WARN_LOW or entropy_score > ENTROPY_WARN_HIGH:\n        reasons.append(\"Entropy out of normal range\")\n    return (len(reasons) > 0), reasons\ndef derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes",
        "detail": "AHE_SDK_V6.core.core",
        "documentation": {}
    },
    {
        "label": "derive_key",
        "kind": 2,
        "importPath": "AHE_SDK_V6.core.core",
        "description": "AHE_SDK_V6.core.core",
        "peekOfCode": "def derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    logger.debug(\"[TRACE] Fusion key derivation initiated\")\n    return hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\ndef aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext_bytes)\n    logger.debug(\"[INTEGRITY] AES-GCM tag generated\")\n    return ciphertext, nonce, tag",
        "detail": "AHE_SDK_V6.core.core",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "AHE_SDK_V6.core.core",
        "description": "AHE_SDK_V6.core.core",
        "peekOfCode": "def aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext_bytes)\n    logger.debug(\"[INTEGRITY] AES-GCM tag generated\")\n    return ciphertext, nonce, tag\ndef aes_decrypt(ciphertext, nonce, tag, key):\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag)\n# === METADATA ENCRYPTION ===",
        "detail": "AHE_SDK_V6.core.core",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "AHE_SDK_V6.core.core",
        "description": "AHE_SDK_V6.core.core",
        "peekOfCode": "def aes_decrypt(ciphertext, nonce, tag, key):\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag)\n# === METADATA ENCRYPTION ===\ndef encrypt_metadata(metadata_dict, password):\n    metadata_json = json.dumps(metadata_dict)\n    metadata_bytes = metadata_json.encode('utf-8')\n    salt = get_random_bytes(16)\n    key = PBKDF2(password, salt, dkLen=32, count=100_000)\n    nonce = get_random_bytes(12)",
        "detail": "AHE_SDK_V6.core.core",
        "documentation": {}
    },
    {
        "label": "encrypt_metadata",
        "kind": 2,
        "importPath": "AHE_SDK_V6.core.core",
        "description": "AHE_SDK_V6.core.core",
        "peekOfCode": "def encrypt_metadata(metadata_dict, password):\n    metadata_json = json.dumps(metadata_dict)\n    metadata_bytes = metadata_json.encode('utf-8')\n    salt = get_random_bytes(16)\n    key = PBKDF2(password, salt, dkLen=32, count=100_000)\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(metadata_bytes)\n    logger.debug(\"[ZERO-KNOWLEDGE] Metadata encapsulated securely\")\n    return json.dumps({",
        "detail": "AHE_SDK_V6.core.core",
        "documentation": {}
    },
    {
        "label": "decrypt_metadata",
        "kind": 2,
        "importPath": "AHE_SDK_V6.core.core",
        "description": "AHE_SDK_V6.core.core",
        "peekOfCode": "def decrypt_metadata(encrypted_blob_json, password):\n    encrypted_blob = json.loads(encrypted_blob_json)\n    salt = base64.b64decode(encrypted_blob[\"salt\"])\n    nonce = base64.b64decode(encrypted_blob[\"nonce\"])\n    tag = base64.b64decode(encrypted_blob[\"tag\"])\n    ciphertext = base64.b64decode(encrypted_blob[\"ciphertext\"])\n    key = PBKDF2(password, salt, dkLen=32, count=100_000)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    metadata_bytes = cipher.decrypt_and_verify(ciphertext, tag)\n    return json.loads(metadata_bytes.decode('utf-8'))",
        "detail": "AHE_SDK_V6.core.core",
        "documentation": {}
    },
    {
        "label": "encrypt_message",
        "kind": 2,
        "importPath": "AHE_SDK_V6.core.core",
        "description": "AHE_SDK_V6.core.core",
        "peekOfCode": "def encrypt_message(message, password):\n    logger.info(\"=== [START] AHE Encryption ===\")\n    start_time = time.time()\n    # 1. Entropy & Anomaly\n    plaintext = message.encode()\n    input_entropy = calculate_entropy(plaintext)\n    anomaly, reasons = detect_anomaly(input_entropy, message)\n    logger.info(f\"[AUDIT] Input entropy: {input_entropy:.4f} | Anomaly: {anomaly}\")\n    if anomaly:\n        logger.warning(f\"[AUDIT] Anomaly reasons: {', '.join(reasons)}\")",
        "detail": "AHE_SDK_V6.core.core",
        "documentation": {}
    },
    {
        "label": "decrypt_latest",
        "kind": 2,
        "importPath": "AHE_SDK_V6.core.core",
        "description": "AHE_SDK_V6.core.core",
        "peekOfCode": "def decrypt_latest(password):\n    logger.info(\"=== [START] AHE Decryption ===\")\n    start_time = time.time()\n    files = sorted([f for f in os.listdir(STORAGE_DIR) if f.endswith(ENC_EXT)])\n    metas = sorted([f for f in os.listdir(STORAGE_DIR) if f.endswith(META_EXT)])\n    if not files or not metas:\n        raise FileNotFoundError(\"No encrypted data found in secure_storage.\")\n    enc_path = os.path.join(STORAGE_DIR, files[-1])\n    meta_path = os.path.join(STORAGE_DIR, metas[-1])\n    logger.info(f\"[INFO] Using ciphertext: {enc_path}\")",
        "detail": "AHE_SDK_V6.core.core",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "AHE_SDK_V6.core.core",
        "description": "AHE_SDK_V6.core.core",
        "peekOfCode": "AES_KEY_SIZE = 32\nMETA_EXT = \".meta\"\nENC_EXT = \".ahe\"\nPQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\nSTORAGE_DIR = \"secure_storage\"\nENTROPY_WARN_LOW = 3.5\nENTROPY_WARN_HIGH = 4.75\nos.makedirs(STORAGE_DIR, exist_ok=True)\n# === UTILITIES ===\ndef calculate_entropy(data: bytes) -> float:",
        "detail": "AHE_SDK_V6.core.core",
        "documentation": {}
    },
    {
        "label": "META_EXT",
        "kind": 5,
        "importPath": "AHE_SDK_V6.core.core",
        "description": "AHE_SDK_V6.core.core",
        "peekOfCode": "META_EXT = \".meta\"\nENC_EXT = \".ahe\"\nPQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\nSTORAGE_DIR = \"secure_storage\"\nENTROPY_WARN_LOW = 3.5\nENTROPY_WARN_HIGH = 4.75\nos.makedirs(STORAGE_DIR, exist_ok=True)\n# === UTILITIES ===\ndef calculate_entropy(data: bytes) -> float:\n    if not data:",
        "detail": "AHE_SDK_V6.core.core",
        "documentation": {}
    },
    {
        "label": "ENC_EXT",
        "kind": 5,
        "importPath": "AHE_SDK_V6.core.core",
        "description": "AHE_SDK_V6.core.core",
        "peekOfCode": "ENC_EXT = \".ahe\"\nPQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\nSTORAGE_DIR = \"secure_storage\"\nENTROPY_WARN_LOW = 3.5\nENTROPY_WARN_HIGH = 4.75\nos.makedirs(STORAGE_DIR, exist_ok=True)\n# === UTILITIES ===\ndef calculate_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0",
        "detail": "AHE_SDK_V6.core.core",
        "documentation": {}
    },
    {
        "label": "PQC_KEMS",
        "kind": 5,
        "importPath": "AHE_SDK_V6.core.core",
        "description": "AHE_SDK_V6.core.core",
        "peekOfCode": "PQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\nSTORAGE_DIR = \"secure_storage\"\nENTROPY_WARN_LOW = 3.5\nENTROPY_WARN_HIGH = 4.75\nos.makedirs(STORAGE_DIR, exist_ok=True)\n# === UTILITIES ===\ndef calculate_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}",
        "detail": "AHE_SDK_V6.core.core",
        "documentation": {}
    },
    {
        "label": "STORAGE_DIR",
        "kind": 5,
        "importPath": "AHE_SDK_V6.core.core",
        "description": "AHE_SDK_V6.core.core",
        "peekOfCode": "STORAGE_DIR = \"secure_storage\"\nENTROPY_WARN_LOW = 3.5\nENTROPY_WARN_HIGH = 4.75\nos.makedirs(STORAGE_DIR, exist_ok=True)\n# === UTILITIES ===\ndef calculate_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())",
        "detail": "AHE_SDK_V6.core.core",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_LOW",
        "kind": 5,
        "importPath": "AHE_SDK_V6.core.core",
        "description": "AHE_SDK_V6.core.core",
        "peekOfCode": "ENTROPY_WARN_LOW = 3.5\nENTROPY_WARN_HIGH = 4.75\nos.makedirs(STORAGE_DIR, exist_ok=True)\n# === UTILITIES ===\ndef calculate_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef detect_anomaly(entropy_score: float, message: str):",
        "detail": "AHE_SDK_V6.core.core",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_HIGH",
        "kind": 5,
        "importPath": "AHE_SDK_V6.core.core",
        "description": "AHE_SDK_V6.core.core",
        "peekOfCode": "ENTROPY_WARN_HIGH = 4.75\nos.makedirs(STORAGE_DIR, exist_ok=True)\n# === UTILITIES ===\ndef calculate_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef detect_anomaly(entropy_score: float, message: str):\n    reasons = []",
        "detail": "AHE_SDK_V6.core.core",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "AHE_SDK_V6.crypto.crypto",
        "description": "AHE_SDK_V6.crypto.crypto",
        "peekOfCode": "def aes_encrypt(message, key: bytes) -> tuple:\n    \"\"\"\n    Encrypts message using AES-GCM.\n    Accepts str or bytes.\n    Returns (ciphertext, nonce, tag) as raw bytes.\n    \"\"\"\n    logger.info(\"Starting AES encryption process\")\n    try:\n        if isinstance(message, str):\n            message = message.encode()",
        "detail": "AHE_SDK_V6.crypto.crypto",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "AHE_SDK_V6.crypto.crypto",
        "description": "AHE_SDK_V6.crypto.crypto",
        "peekOfCode": "def aes_decrypt(ciphertext: bytes, key: bytes, nonce: bytes, tag: bytes) -> bytes:\n    \"\"\"\n    Decrypts AES-GCM encrypted data.\n    Returns plaintext as bytes.\n    \"\"\"\n    logger.info(\"Starting AES decryption process\")\n    try:\n        cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n        plaintext = cipher.decrypt_and_verify(ciphertext, tag)\n        logger.info(\"AES decryption completed successfully\")",
        "detail": "AHE_SDK_V6.crypto.crypto",
        "documentation": {}
    },
    {
        "label": "derive_key_argon2",
        "kind": 2,
        "importPath": "AHE_SDK_V6.kdf.kdf",
        "description": "AHE_SDK_V6.kdf.kdf",
        "peekOfCode": "def derive_key_argon2(password: bytes, salt: bytes) -> bytes:\n    logger.info(\"Starting Argon2id key derivation\")\n    try:\n        key = hash_secret_raw(\n            secret=password,\n            salt=salt,\n            time_cost=4,\n            memory_cost=102400,\n            parallelism=8,\n            hash_len=AES_KEY_SIZE,",
        "detail": "AHE_SDK_V6.kdf.kdf",
        "documentation": {}
    },
    {
        "label": "derive_key_shake",
        "kind": 2,
        "importPath": "AHE_SDK_V6.kdf.kdf",
        "description": "AHE_SDK_V6.kdf.kdf",
        "peekOfCode": "def derive_key_shake(password: bytes, salt: bytes, bits: int=256) -> bytes:\n    logger.info(f\"Starting SHAKE-{bits} key derivation\")\n    try:\n        shake = hashlib.shake_128() if bits == 128 else hashlib.shake_256()\n        shake.update(password + salt)\n        key = shake.digest(AES_KEY_SIZE)\n        logger.info(f\"SHAKE-{bits} key derivation completed\")\n        return key\n    except Exception as e:\n        logger.error(f\"SHAKE-{bits} derivation failed: {e}\", exc_info=True)",
        "detail": "AHE_SDK_V6.kdf.kdf",
        "documentation": {}
    },
    {
        "label": "hkdf_extract",
        "kind": 2,
        "importPath": "AHE_SDK_V6.kdf.kdf",
        "description": "AHE_SDK_V6.kdf.kdf",
        "peekOfCode": "def hkdf_extract(salt: bytes, input_key_material: bytes, hash_algo=hashlib.sha256) -> bytes:\n    return hmac.new(salt, input_key_material, hash_algo).digest()\ndef hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:\n    hash_len = hash_algo().digest_size\n    blocks_needed = (length + hash_len - 1) // hash_len\n    okm = b\"\"\n    output_block = b\"\"\n    for counter in range(1, blocks_needed + 1):\n        output_block = hmac.new(prk, output_block + info + bytes([counter]), hash_algo).digest()\n        okm += output_block",
        "detail": "AHE_SDK_V6.kdf.kdf",
        "documentation": {}
    },
    {
        "label": "hkdf_expand",
        "kind": 2,
        "importPath": "AHE_SDK_V6.kdf.kdf",
        "description": "AHE_SDK_V6.kdf.kdf",
        "peekOfCode": "def hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:\n    hash_len = hash_algo().digest_size\n    blocks_needed = (length + hash_len - 1) // hash_len\n    okm = b\"\"\n    output_block = b\"\"\n    for counter in range(1, blocks_needed + 1):\n        output_block = hmac.new(prk, output_block + info + bytes([counter]), hash_algo).digest()\n        okm += output_block\n    return okm[:length]\ndef derive_key_hkdf(password: bytes, salt: bytes) -> bytes:",
        "detail": "AHE_SDK_V6.kdf.kdf",
        "documentation": {}
    },
    {
        "label": "derive_key_hkdf",
        "kind": 2,
        "importPath": "AHE_SDK_V6.kdf.kdf",
        "description": "AHE_SDK_V6.kdf.kdf",
        "peekOfCode": "def derive_key_hkdf(password: bytes, salt: bytes) -> bytes:\n    logger.info(\"Starting HKDF key derivation\")\n    try:\n        prk = hkdf_extract(salt, password)\n        key = hkdf_expand(prk, b\"AHE-HKDF\", AES_KEY_SIZE)\n        logger.info(\"HKDF key derivation completed\")\n        return key\n    except Exception as e:\n        logger.error(f\"HKDF derivation failed: {e}\", exc_info=True)\n        raise",
        "detail": "AHE_SDK_V6.kdf.kdf",
        "documentation": {}
    },
    {
        "label": "derive_key_hybrid_with_pqc",
        "kind": 2,
        "importPath": "AHE_SDK_V6.kdf.kdf",
        "description": "AHE_SDK_V6.kdf.kdf",
        "peekOfCode": "def derive_key_hybrid_with_pqc(password: bytes, salt: bytes, anomaly: bool) -> tuple:\n    PQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\n    PQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\n    if anomaly:\n        pqc_candidates = PQC_STRONG_KEMS.copy()\n    else:\n        pqc_candidates = PQC_FAST_KEMS.copy()\n    random.shuffle(pqc_candidates)\n    try:\n        if anomaly:",
        "detail": "AHE_SDK_V6.kdf.kdf",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "AHE_SDK_V6.kdf.kdf",
        "description": "AHE_SDK_V6.kdf.kdf",
        "peekOfCode": "AES_KEY_SIZE = 32\n# === Key Derivation Functions ===\ndef derive_key_argon2(password: bytes, salt: bytes) -> bytes:\n    logger.info(\"Starting Argon2id key derivation\")\n    try:\n        key = hash_secret_raw(\n            secret=password,\n            salt=salt,\n            time_cost=4,\n            memory_cost=102400,",
        "detail": "AHE_SDK_V6.kdf.kdf",
        "documentation": {}
    },
    {
        "label": "pqc_keypair",
        "kind": 2,
        "importPath": "AHE_SDK_V6.pqc.pqc",
        "description": "AHE_SDK_V6.pqc.pqc",
        "peekOfCode": "def pqc_keypair(kem_name: str):\n    logger.info(f\"Generating keypair for PQC KEM: {kem_name}\")\n    kem = oqs.KeyEncapsulation(kem_name)\n    public_key = kem.generate_keypair()\n    logger.info(f\"Keypair generated for PQC KEM: {kem_name}\")\n    return kem, public_key\ndef pqc_encapsulate(kem, public_key: bytes):\n    logger.info(\"Starting PQC encapsulation\")\n    ct, ss = kem.encap_secret(public_key)\n    logger.info(\"PQC encapsulation completed\")",
        "detail": "AHE_SDK_V6.pqc.pqc",
        "documentation": {}
    },
    {
        "label": "pqc_encapsulate",
        "kind": 2,
        "importPath": "AHE_SDK_V6.pqc.pqc",
        "description": "AHE_SDK_V6.pqc.pqc",
        "peekOfCode": "def pqc_encapsulate(kem, public_key: bytes):\n    logger.info(\"Starting PQC encapsulation\")\n    ct, ss = kem.encap_secret(public_key)\n    logger.info(\"PQC encapsulation completed\")\n    return ct, ss\ndef pqc_decapsulate(kem, ciphertext: bytes):\n    logger.info(\"Starting PQC decapsulation\")\n    ss = kem.decap_secret(ciphertext)\n    logger.info(\"PQC decapsulation completed\")\n    return ss",
        "detail": "AHE_SDK_V6.pqc.pqc",
        "documentation": {}
    },
    {
        "label": "pqc_decapsulate",
        "kind": 2,
        "importPath": "AHE_SDK_V6.pqc.pqc",
        "description": "AHE_SDK_V6.pqc.pqc",
        "peekOfCode": "def pqc_decapsulate(kem, ciphertext: bytes):\n    logger.info(\"Starting PQC decapsulation\")\n    ss = kem.decap_secret(ciphertext)\n    logger.info(\"PQC decapsulation completed\")\n    return ss\ndef pqc_select_and_run(anomaly: bool):\n    pqc_candidates = PQC_STRONG_KEMS.copy() if anomaly else PQC_FAST_KEMS.copy()\n    random.shuffle(pqc_candidates)\n    for kem_name in pqc_candidates:\n        try:",
        "detail": "AHE_SDK_V6.pqc.pqc",
        "documentation": {}
    },
    {
        "label": "pqc_select_and_run",
        "kind": 2,
        "importPath": "AHE_SDK_V6.pqc.pqc",
        "description": "AHE_SDK_V6.pqc.pqc",
        "peekOfCode": "def pqc_select_and_run(anomaly: bool):\n    pqc_candidates = PQC_STRONG_KEMS.copy() if anomaly else PQC_FAST_KEMS.copy()\n    random.shuffle(pqc_candidates)\n    for kem_name in pqc_candidates:\n        try:\n            logger.info(f\"Trying PQC KEM: {kem_name}\")\n            start = time.time()\n            kem, public_key = pqc_keypair(kem_name)\n            ciphertext, shared_secret = pqc_encapsulate(kem, public_key)\n            shared_secret_check = pqc_decapsulate(kem, ciphertext)",
        "detail": "AHE_SDK_V6.pqc.pqc",
        "documentation": {}
    },
    {
        "label": "PQC_FAST_KEMS",
        "kind": 5,
        "importPath": "AHE_SDK_V6.pqc.pqc",
        "description": "AHE_SDK_V6.pqc.pqc",
        "peekOfCode": "PQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\nPQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\ndef pqc_keypair(kem_name: str):\n    logger.info(f\"Generating keypair for PQC KEM: {kem_name}\")\n    kem = oqs.KeyEncapsulation(kem_name)\n    public_key = kem.generate_keypair()\n    logger.info(f\"Keypair generated for PQC KEM: {kem_name}\")\n    return kem, public_key\ndef pqc_encapsulate(kem, public_key: bytes):\n    logger.info(\"Starting PQC encapsulation\")",
        "detail": "AHE_SDK_V6.pqc.pqc",
        "documentation": {}
    },
    {
        "label": "PQC_STRONG_KEMS",
        "kind": 5,
        "importPath": "AHE_SDK_V6.pqc.pqc",
        "description": "AHE_SDK_V6.pqc.pqc",
        "peekOfCode": "PQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\ndef pqc_keypair(kem_name: str):\n    logger.info(f\"Generating keypair for PQC KEM: {kem_name}\")\n    kem = oqs.KeyEncapsulation(kem_name)\n    public_key = kem.generate_keypair()\n    logger.info(f\"Keypair generated for PQC KEM: {kem_name}\")\n    return kem, public_key\ndef pqc_encapsulate(kem, public_key: bytes):\n    logger.info(\"Starting PQC encapsulation\")\n    ct, ss = kem.encap_secret(public_key)",
        "detail": "AHE_SDK_V6.pqc.pqc",
        "documentation": {}
    },
    {
        "label": "test_aes_encrypt_and_decrypt",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_aes",
        "description": "AHE_SDK_V6.tests.test_aes",
        "peekOfCode": "def test_aes_encrypt_and_decrypt():\n    key = os.urandom(32)  # AES-256 key\n    plaintext = \"Adaptive Hashing Encryption - AES Test\"\n    # Encrypt\n    bundle = aes_encrypt(plaintext, key)\n    assert \"ciphertext\" in bundle\n    assert \"nonce\" in bundle\n    assert \"tag\" in bundle\n    # Decrypt\n    decrypted = aes_decrypt(bundle, key)",
        "detail": "AHE_SDK_V6.tests.test_aes",
        "documentation": {}
    },
    {
        "label": "test_aes_encrypt_decrypt_empty_data",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_aes",
        "description": "AHE_SDK_V6.tests.test_aes",
        "peekOfCode": "def test_aes_encrypt_decrypt_empty_data():\n    key = os.urandom(32)\n    plaintext = \"\"\n    bundle = aes_encrypt(plaintext, key)\n    decrypted = aes_decrypt(bundle, key)\n    assert decrypted == plaintext\ndef test_aes_encrypt_decrypt_large_data():\n    key = os.urandom(32)\n    plaintext = \"A\" * (1024 * 1024)  # 1 MB string\n    bundle = aes_encrypt(plaintext, key)",
        "detail": "AHE_SDK_V6.tests.test_aes",
        "documentation": {}
    },
    {
        "label": "test_aes_encrypt_decrypt_large_data",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_aes",
        "description": "AHE_SDK_V6.tests.test_aes",
        "peekOfCode": "def test_aes_encrypt_decrypt_large_data():\n    key = os.urandom(32)\n    plaintext = \"A\" * (1024 * 1024)  # 1 MB string\n    bundle = aes_encrypt(plaintext, key)\n    decrypted = aes_decrypt(bundle, key)\n    assert decrypted == plaintext\ndef test_aes_decrypt_with_wrong_key():\n    key = os.urandom(32)\n    wrong_key = os.urandom(32)\n    plaintext = \"Testing wrong key behavior\"",
        "detail": "AHE_SDK_V6.tests.test_aes",
        "documentation": {}
    },
    {
        "label": "test_aes_decrypt_with_wrong_key",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_aes",
        "description": "AHE_SDK_V6.tests.test_aes",
        "peekOfCode": "def test_aes_decrypt_with_wrong_key():\n    key = os.urandom(32)\n    wrong_key = os.urandom(32)\n    plaintext = \"Testing wrong key behavior\"\n    bundle = aes_encrypt(plaintext, key)\n    with pytest.raises(Exception):\n        aes_decrypt(bundle, wrong_key)",
        "detail": "AHE_SDK_V6.tests.test_aes",
        "documentation": {}
    },
    {
        "label": "test_entropy_calculation",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_ahe",
        "description": "AHE_SDK_V6.tests.test_ahe",
        "peekOfCode": "def test_entropy_calculation():\n    data = b\"abcdef\"\n    entropy = calculate_entropy(data)\n    assert entropy > 0, \"Entropy should be positive for non-empty data\"\ndef test_key_derivation():\n    key = derive_key(b\"pass\", b\"pubkey\", b\"cipher\")\n    assert len(key) == AES_KEY_SIZE, \"Derived key length mismatch\"\ndef test_metadata_encrypt_decrypt():\n    metadata = {\"nonce\": \"123\", \"tag\": \"abc\", \"kem\": \"Kyber\"}\n    encrypted = encrypt_metadata(metadata, TEST_PASSWORD)",
        "detail": "AHE_SDK_V6.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "test_key_derivation",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_ahe",
        "description": "AHE_SDK_V6.tests.test_ahe",
        "peekOfCode": "def test_key_derivation():\n    key = derive_key(b\"pass\", b\"pubkey\", b\"cipher\")\n    assert len(key) == AES_KEY_SIZE, \"Derived key length mismatch\"\ndef test_metadata_encrypt_decrypt():\n    metadata = {\"nonce\": \"123\", \"tag\": \"abc\", \"kem\": \"Kyber\"}\n    encrypted = encrypt_metadata(metadata, TEST_PASSWORD)\n    decrypted = decrypt_metadata(encrypted, TEST_PASSWORD)\n    assert decrypted == metadata, \"Metadata encryption/decryption failed\"\n# === Integration Tests ===\ndef test_full_encryption_decryption_flow():",
        "detail": "AHE_SDK_V6.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "test_metadata_encrypt_decrypt",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_ahe",
        "description": "AHE_SDK_V6.tests.test_ahe",
        "peekOfCode": "def test_metadata_encrypt_decrypt():\n    metadata = {\"nonce\": \"123\", \"tag\": \"abc\", \"kem\": \"Kyber\"}\n    encrypted = encrypt_metadata(metadata, TEST_PASSWORD)\n    decrypted = decrypt_metadata(encrypted, TEST_PASSWORD)\n    assert decrypted == metadata, \"Metadata encryption/decryption failed\"\n# === Integration Tests ===\ndef test_full_encryption_decryption_flow():\n    # Clean storage\n    for f in os.listdir(STORAGE_DIR):\n        os.remove(os.path.join(STORAGE_DIR, f))",
        "detail": "AHE_SDK_V6.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "test_full_encryption_decryption_flow",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_ahe",
        "description": "AHE_SDK_V6.tests.test_ahe",
        "peekOfCode": "def test_full_encryption_decryption_flow():\n    # Clean storage\n    for f in os.listdir(STORAGE_DIR):\n        os.remove(os.path.join(STORAGE_DIR, f))\n    # Encrypt\n    encrypt_message(TEST_MESSAGE, TEST_PASSWORD)\n    # Verify files exist\n    files = [f for f in os.listdir(STORAGE_DIR) if f.endswith(ENC_EXT)]\n    metas = [f for f in os.listdir(STORAGE_DIR) if f.endswith(META_EXT)]\n    assert files and metas, \"Ciphertext and metadata files not created\"",
        "detail": "AHE_SDK_V6.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "test_decrypt_with_wrong_password",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_ahe",
        "description": "AHE_SDK_V6.tests.test_ahe",
        "peekOfCode": "def test_decrypt_with_wrong_password():\n    # Should raise exception or fail integrity\n    with pytest.raises(Exception):\n        decrypt_latest(WRONG_PASSWORD)\ndef test_metadata_tampering_detection():\n    metas = sorted([f for f in os.listdir(STORAGE_DIR) if f.endswith(META_EXT)])\n    meta_path = os.path.join(STORAGE_DIR, metas[-1])\n    with open(meta_path, \"r+\") as f:\n        content = json.load(f)\n        content[\"nonce\"] = base64.b64encode(b\"fake_nonce\").decode()",
        "detail": "AHE_SDK_V6.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "test_metadata_tampering_detection",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_ahe",
        "description": "AHE_SDK_V6.tests.test_ahe",
        "peekOfCode": "def test_metadata_tampering_detection():\n    metas = sorted([f for f in os.listdir(STORAGE_DIR) if f.endswith(META_EXT)])\n    meta_path = os.path.join(STORAGE_DIR, metas[-1])\n    with open(meta_path, \"r+\") as f:\n        content = json.load(f)\n        content[\"nonce\"] = base64.b64encode(b\"fake_nonce\").decode()\n        f.seek(0)\n        json.dump(content, f)\n        f.truncate()\n    with pytest.raises(Exception):",
        "detail": "AHE_SDK_V6.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "test_ciphertext_tampering_detection",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_ahe",
        "description": "AHE_SDK_V6.tests.test_ahe",
        "peekOfCode": "def test_ciphertext_tampering_detection():\n    files = sorted([f for f in os.listdir(STORAGE_DIR) if f.endswith(ENC_EXT)])\n    enc_path = os.path.join(STORAGE_DIR, files[-1])\n    with open(enc_path, \"r+b\") as f:\n        f.seek(0)\n        f.write(b\"corrupt\")\n    with pytest.raises(Exception):\n        decrypt_latest(TEST_PASSWORD)\ndef test_performance_benchmark():\n    import time",
        "detail": "AHE_SDK_V6.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "test_performance_benchmark",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_ahe",
        "description": "AHE_SDK_V6.tests.test_ahe",
        "peekOfCode": "def test_performance_benchmark():\n    import time\n    start = time.time()\n    encrypt_message(\"Performance test message\", TEST_PASSWORD)\n    elapsed = time.time() - start\n    assert elapsed < 10, \"Encryption took too long (>10s)\"\n# === Anomaly & Security Checks ===\ndef test_entropy_and_anomaly_reporting(caplog):\n    encrypt_message(\"1234567890////\", TEST_PASSWORD)\n    logs = caplog.text",
        "detail": "AHE_SDK_V6.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "test_entropy_and_anomaly_reporting",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_ahe",
        "description": "AHE_SDK_V6.tests.test_ahe",
        "peekOfCode": "def test_entropy_and_anomaly_reporting(caplog):\n    encrypt_message(\"1234567890////\", TEST_PASSWORD)\n    logs = caplog.text\n    assert \"Entropy\" in logs or \"Anomaly\" in logs, \"Anomaly detection log missing\"",
        "detail": "AHE_SDK_V6.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "TEST_MESSAGE",
        "kind": 5,
        "importPath": "AHE_SDK_V6.tests.test_ahe",
        "description": "AHE_SDK_V6.tests.test_ahe",
        "peekOfCode": "TEST_MESSAGE = \"This is a secret test message for AHE.\"\nTEST_PASSWORD = \"StrongPassword123\"\nWRONG_PASSWORD = \"WrongPass\"\nMETA_EXT = \".meta\"\nENC_EXT = \".ahe\"\n# === Utility Tests ===\ndef test_entropy_calculation():\n    data = b\"abcdef\"\n    entropy = calculate_entropy(data)\n    assert entropy > 0, \"Entropy should be positive for non-empty data\"",
        "detail": "AHE_SDK_V6.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "TEST_PASSWORD",
        "kind": 5,
        "importPath": "AHE_SDK_V6.tests.test_ahe",
        "description": "AHE_SDK_V6.tests.test_ahe",
        "peekOfCode": "TEST_PASSWORD = \"StrongPassword123\"\nWRONG_PASSWORD = \"WrongPass\"\nMETA_EXT = \".meta\"\nENC_EXT = \".ahe\"\n# === Utility Tests ===\ndef test_entropy_calculation():\n    data = b\"abcdef\"\n    entropy = calculate_entropy(data)\n    assert entropy > 0, \"Entropy should be positive for non-empty data\"\ndef test_key_derivation():",
        "detail": "AHE_SDK_V6.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "WRONG_PASSWORD",
        "kind": 5,
        "importPath": "AHE_SDK_V6.tests.test_ahe",
        "description": "AHE_SDK_V6.tests.test_ahe",
        "peekOfCode": "WRONG_PASSWORD = \"WrongPass\"\nMETA_EXT = \".meta\"\nENC_EXT = \".ahe\"\n# === Utility Tests ===\ndef test_entropy_calculation():\n    data = b\"abcdef\"\n    entropy = calculate_entropy(data)\n    assert entropy > 0, \"Entropy should be positive for non-empty data\"\ndef test_key_derivation():\n    key = derive_key(b\"pass\", b\"pubkey\", b\"cipher\")",
        "detail": "AHE_SDK_V6.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "META_EXT",
        "kind": 5,
        "importPath": "AHE_SDK_V6.tests.test_ahe",
        "description": "AHE_SDK_V6.tests.test_ahe",
        "peekOfCode": "META_EXT = \".meta\"\nENC_EXT = \".ahe\"\n# === Utility Tests ===\ndef test_entropy_calculation():\n    data = b\"abcdef\"\n    entropy = calculate_entropy(data)\n    assert entropy > 0, \"Entropy should be positive for non-empty data\"\ndef test_key_derivation():\n    key = derive_key(b\"pass\", b\"pubkey\", b\"cipher\")\n    assert len(key) == AES_KEY_SIZE, \"Derived key length mismatch\"",
        "detail": "AHE_SDK_V6.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "ENC_EXT",
        "kind": 5,
        "importPath": "AHE_SDK_V6.tests.test_ahe",
        "description": "AHE_SDK_V6.tests.test_ahe",
        "peekOfCode": "ENC_EXT = \".ahe\"\n# === Utility Tests ===\ndef test_entropy_calculation():\n    data = b\"abcdef\"\n    entropy = calculate_entropy(data)\n    assert entropy > 0, \"Entropy should be positive for non-empty data\"\ndef test_key_derivation():\n    key = derive_key(b\"pass\", b\"pubkey\", b\"cipher\")\n    assert len(key) == AES_KEY_SIZE, \"Derived key length mismatch\"\ndef test_metadata_encrypt_decrypt():",
        "detail": "AHE_SDK_V6.tests.test_ahe",
        "documentation": {}
    },
    {
        "label": "TestAnomalyDetection",
        "kind": 6,
        "importPath": "AHE_SDK_V6.tests.test_anomaly",
        "description": "AHE_SDK_V6.tests.test_anomaly",
        "peekOfCode": "class TestAnomalyDetection(unittest.TestCase):\n    def test_no_anomaly_normal_entropy(self):\n        # No suspicious chars, entropy in normal range\n        input_str = \"HelloWorld\"\n        entropy = (ENTROPY_WARN_THRESHOLD_LOW + ENTROPY_WARN_THRESHOLD_HIGH) / 2\n        anomaly, reasons = detect_anomaly(input_str, entropy)\n        self.assertFalse(anomaly)\n        self.assertEqual(reasons, [])\n    def test_suspicious_characters_only(self):\n        # Suspicious chars present, entropy normal",
        "detail": "AHE_SDK_V6.tests.test_anomaly",
        "documentation": {}
    },
    {
        "label": "test_ahe_encrypt_basic",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_core",
        "description": "AHE_SDK_V6.tests.test_core",
        "peekOfCode": "def test_ahe_encrypt_basic():\n    message = \"Test encryption message\"\n    encrypted = ahe_encrypt_v9_5(message)\n    # Check the structure of returned dictionary\n    assert \"aes_encrypted\" in encrypted\n    assert \"pqc\" in encrypted\n    assert \"timing\" in encrypted\n    aes_bundle = encrypted[\"aes_encrypted\"]\n    assert \"ciphertext\" in aes_bundle\n    assert \"nonce\" in aes_bundle",
        "detail": "AHE_SDK_V6.tests.test_core",
        "documentation": {}
    },
    {
        "label": "test_ahe_encrypt_decrypt_cycle",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_core",
        "description": "AHE_SDK_V6.tests.test_core",
        "peekOfCode": "def test_ahe_encrypt_decrypt_cycle():\n    message = \"Another test message\"\n    encrypted = ahe_encrypt_v9_5(message)\n    # You will need the AES key for decryption  \n    # In current core.py, the AES key is derived internally in the encryption function.\n    # For test purpose, you might want to adjust core.py to return the AES key for this test,\n    # or mock derive_key_hybrid_with_pqc to expose the key.\n    # For demonstration, let's say you modify ahe_encrypt_v9_5 to also return AES key:\n    # encrypted, aes_key = ahe_encrypt_v9_5(message)\n    # Then do:",
        "detail": "AHE_SDK_V6.tests.test_core",
        "documentation": {}
    },
    {
        "label": "test_ahe_decrypt",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_core",
        "description": "AHE_SDK_V6.tests.test_core",
        "peekOfCode": "def test_ahe_decrypt():\n    # This test will be added later after we refactor key management\n    pass",
        "detail": "AHE_SDK_V6.tests.test_core",
        "documentation": {}
    },
    {
        "label": "test_aes_encrypt_and_decrypt",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_crypto",
        "description": "AHE_SDK_V6.tests.test_crypto",
        "peekOfCode": "def test_aes_encrypt_and_decrypt():\n    key = os.urandom(32)  # AES-256 key\n    plaintext = b\"Adaptive Hashing Encryption - AES Test\"\n    ciphertext, nonce, tag = aes_encrypt(plaintext, key)\n    decrypted = aes_decrypt(ciphertext, key, nonce, tag)\n    assert decrypted == plaintext\n# Test 2: Empty Message\ndef test_aes_encrypt_decrypt_empty_message():\n    key = os.urandom(32)\n    plaintext = b\"\"",
        "detail": "AHE_SDK_V6.tests.test_crypto",
        "documentation": {}
    },
    {
        "label": "test_aes_encrypt_decrypt_empty_message",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_crypto",
        "description": "AHE_SDK_V6.tests.test_crypto",
        "peekOfCode": "def test_aes_encrypt_decrypt_empty_message():\n    key = os.urandom(32)\n    plaintext = b\"\"\n    ciphertext, nonce, tag = aes_encrypt(plaintext, key)\n    decrypted = aes_decrypt(ciphertext, key, nonce, tag)\n    assert decrypted == plaintext\n# Test 3: Large Data (1 MB)\ndef test_aes_encrypt_decrypt_large_data():\n    key = os.urandom(32)\n    plaintext = os.urandom(1024 * 1024)  # 1 MB random data",
        "detail": "AHE_SDK_V6.tests.test_crypto",
        "documentation": {}
    },
    {
        "label": "test_aes_encrypt_decrypt_large_data",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_crypto",
        "description": "AHE_SDK_V6.tests.test_crypto",
        "peekOfCode": "def test_aes_encrypt_decrypt_large_data():\n    key = os.urandom(32)\n    plaintext = os.urandom(1024 * 1024)  # 1 MB random data\n    start = time.time()\n    ciphertext, nonce, tag = aes_encrypt(plaintext, key)\n    decrypted = aes_decrypt(ciphertext, key, nonce, tag)\n    duration = time.time() - start\n    assert decrypted == plaintext\n    print(f\"\\n[PERF] 1MB AES-GCM Encrypt+Decrypt took {duration:.4f} seconds\")\n# Test 4: Wrong Key",
        "detail": "AHE_SDK_V6.tests.test_crypto",
        "documentation": {}
    },
    {
        "label": "test_aes_decrypt_with_wrong_key",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_crypto",
        "description": "AHE_SDK_V6.tests.test_crypto",
        "peekOfCode": "def test_aes_decrypt_with_wrong_key():\n    key = os.urandom(32)\n    wrong_key = os.urandom(32)\n    plaintext = b\"Testing wrong key behavior\"\n    ciphertext, nonce, tag = aes_encrypt(plaintext, key)\n    with pytest.raises(ValueError):\n        aes_decrypt(ciphertext, wrong_key, nonce, tag)\n# Test 5: Tampered Ciphertext\ndef test_aes_decrypt_with_tampered_ciphertext():\n    key = os.urandom(32)",
        "detail": "AHE_SDK_V6.tests.test_crypto",
        "documentation": {}
    },
    {
        "label": "test_aes_decrypt_with_tampered_ciphertext",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_crypto",
        "description": "AHE_SDK_V6.tests.test_crypto",
        "peekOfCode": "def test_aes_decrypt_with_tampered_ciphertext():\n    key = os.urandom(32)\n    plaintext = b\"Testing tampered ciphertext\"\n    ciphertext, nonce, tag = aes_encrypt(plaintext, key)\n    # Modify ciphertext\n    tampered_ciphertext = bytearray(ciphertext)\n    tampered_ciphertext[0] ^= 0x01  # Flip a bit\n    with pytest.raises(ValueError):\n        aes_decrypt(bytes(tampered_ciphertext), key, nonce, tag)",
        "detail": "AHE_SDK_V6.tests.test_crypto",
        "documentation": {}
    },
    {
        "label": "TestDisplayUtils",
        "kind": 6,
        "importPath": "AHE_SDK_V6.tests.test_display",
        "description": "AHE_SDK_V6.tests.test_display",
        "peekOfCode": "class TestDisplayUtils(unittest.TestCase):\n    def test_full_display_when_length_is_small(self):\n        data = b\"\\x01\\x02\\x03\"\n        result = shorten_bytes_for_display(data, length=10)\n        self.assertEqual(result, data.hex())\n    def test_truncated_display_when_length_is_large(self):\n        data = b\"\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\x09\\x0A\\x0B\\x0C\"\n        result = shorten_bytes_for_display(data, length=5)\n        expected_prefix = data[:5].hex() + \"...\"\n        self.assertEqual(result, expected_prefix)",
        "detail": "AHE_SDK_V6.tests.test_display",
        "documentation": {}
    },
    {
        "label": "TestEntropyFunctions",
        "kind": 6,
        "importPath": "AHE_SDK_V6.tests.test_entropy",
        "description": "AHE_SDK_V6.tests.test_entropy",
        "peekOfCode": "class TestEntropyFunctions(unittest.TestCase):\n    def test_calculate_shannon_entropy_normal(self):\n        data = b\"aaaabbbbccccdddd\"\n        entropy_val = entropy.calculate_shannon_entropy(data)\n        self.assertGreater(entropy_val, 0)\n        self.assertLessEqual(entropy_val, 4)\n    def test_calculate_shannon_entropy_empty(self):\n        data = b\"\"\n        entropy_val = entropy.calculate_shannon_entropy(data)\n        self.assertEqual(entropy_val, 0)",
        "detail": "AHE_SDK_V6.tests.test_entropy",
        "documentation": {}
    },
    {
        "label": "TestHashingFunctions",
        "kind": 6,
        "importPath": "AHE_SDK_V6.tests.test_hashing",
        "description": "AHE_SDK_V6.tests.test_hashing",
        "peekOfCode": "class TestHashingFunctions(unittest.TestCase):\n    def test_hash_stage_sha256(self):\n        data = b\"test\"\n        result = hash_stage(data, \"sha256\")\n        self.assertEqual(len(result), hashlib.sha256().digest_size)\n        self.assertIsInstance(result, bytes)\n    def test_hash_stage_sha512(self):\n        data = b\"test\"\n        result = hash_stage(data, \"sha512\")\n        self.assertEqual(len(result), hashlib.sha512().digest_size)",
        "detail": "AHE_SDK_V6.tests.test_hashing",
        "documentation": {}
    },
    {
        "label": "TestAHEPipeline",
        "kind": 6,
        "importPath": "AHE_SDK_V6.tests.test_intergrated",
        "description": "AHE_SDK_V6.tests.test_intergrated",
        "peekOfCode": "class TestAHEPipeline(unittest.TestCase):\n    def test_encryption_pipeline(self):\n        message = \"Hello Adaptive Hashing Encryption!\"  # Test input\n        result = ahe_encrypt_v9_5(message)\n        # Validate result structure\n        self.assertIn(\"aes_encrypted\", result)\n        self.assertIn(\"pqc\", result)\n        self.assertIn(\"timing\", result)\n        # Check AES structure\n        aes_bundle = result[\"aes_encrypted\"]",
        "detail": "AHE_SDK_V6.tests.test_intergrated",
        "documentation": {}
    },
    {
        "label": "TestIntegratedEC",
        "kind": 6,
        "importPath": "AHE_SDK_V6.tests.test_intergrated_EC",
        "description": "AHE_SDK_V6.tests.test_intergrated_EC",
        "peekOfCode": "class TestIntegratedEC(unittest.TestCase):\n    \"\"\"Integration Test: Full AHE Encryption Pipeline Only\"\"\"\n    def test_full_encryption_pipeline(self):\n        message = \"The future of cryptography is adaptive and quantum-secure.\"\n        print(\"\\n=== Running AHE v9.5 Encryption Pipeline Test ===\")\n        print(f\" Input Message: {message}\")\n        start_time = time.time()\n        result = ahe_encrypt_v9_5(message)\n        elapsed_time = time.time() - start_time\n        #  Basic Structure Checks",
        "detail": "AHE_SDK_V6.tests.test_intergrated_EC",
        "documentation": {}
    },
    {
        "label": "test_derive_key_argon2",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_kdf",
        "description": "AHE_SDK_V6.tests.test_kdf",
        "peekOfCode": "def test_derive_key_argon2():\n    password = b\"password123\"\n    salt = os.urandom(16)\n    key = derive_key_argon2(password, salt)\n    assert isinstance(key, bytes)\n    assert len(key) == 32\ndef test_derive_key_shake():\n    password = b\"password123\"\n    salt = os.urandom(16)\n    key_128 = derive_key_shake(password, salt, 128)",
        "detail": "AHE_SDK_V6.tests.test_kdf",
        "documentation": {}
    },
    {
        "label": "test_derive_key_shake",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_kdf",
        "description": "AHE_SDK_V6.tests.test_kdf",
        "peekOfCode": "def test_derive_key_shake():\n    password = b\"password123\"\n    salt = os.urandom(16)\n    key_128 = derive_key_shake(password, salt, 128)\n    key_256 = derive_key_shake(password, salt, 256)\n    assert isinstance(key_128, bytes)\n    assert len(key_128) == 32\n    assert isinstance(key_256, bytes)\n    assert len(key_256) == 32\ndef test_derive_key_hkdf():",
        "detail": "AHE_SDK_V6.tests.test_kdf",
        "documentation": {}
    },
    {
        "label": "test_derive_key_hkdf",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_kdf",
        "description": "AHE_SDK_V6.tests.test_kdf",
        "peekOfCode": "def test_derive_key_hkdf():\n    password = b\"password123\"\n    salt = os.urandom(16)\n    key = derive_key_hkdf(password, salt)\n    assert isinstance(key, bytes)\n    assert len(key) == 32\n@pytest.mark.parametrize(\"anomaly\", [True, False])\ndef test_derive_key_hybrid_with_pqc(anomaly):\n    password = b\"password123\"\n    salt = os.urandom(16)",
        "detail": "AHE_SDK_V6.tests.test_kdf",
        "documentation": {}
    },
    {
        "label": "test_derive_key_hybrid_with_pqc",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_kdf",
        "description": "AHE_SDK_V6.tests.test_kdf",
        "peekOfCode": "def test_derive_key_hybrid_with_pqc(anomaly):\n    password = b\"password123\"\n    salt = os.urandom(16)\n    # Run the full hybrid KDF with real oqs.KeyEncapsulation calls\n    result = derive_key_hybrid_with_pqc(password, salt, anomaly)\n    # Unpack results\n    final_key, shake_time, kem_time, kem_name, public_key, ciphertext, shared_secret = result\n    # Basic assertions on outputs\n    assert isinstance(final_key, bytes)\n    assert len(final_key) == 32",
        "detail": "AHE_SDK_V6.tests.test_kdf",
        "documentation": {}
    },
    {
        "label": "test_pqc_keypair_generation",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_pqc",
        "description": "AHE_SDK_V6.tests.test_pqc",
        "peekOfCode": "def test_pqc_keypair_generation(kem_name):\n    \"\"\"\n    Test that all supported PQC KEMs generate valid keypairs.\n    EXPECTED:\n    - kem: Valid KeyEncapsulation object\n    - public_key: Non-empty bytes\n    \"\"\"\n    kem, public_key = pqc_keypair(kem_name)\n    assert kem is not None, f\"KEM object is None for {kem_name}\"\n    assert isinstance(public_key, bytes), f\"Public key is not bytes for {kem_name}\"",
        "detail": "AHE_SDK_V6.tests.test_pqc",
        "documentation": {}
    },
    {
        "label": "test_pqc_encapsulate_and_decapsulate",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_pqc",
        "description": "AHE_SDK_V6.tests.test_pqc",
        "peekOfCode": "def test_pqc_encapsulate_and_decapsulate(kem_name):\n    \"\"\"\n    Test correctness: Encapsulation followed by decapsulation\n    MUST result in the same shared secret.\n    \"\"\"\n    kem, public_key = pqc_keypair(kem_name)\n    ciphertext, shared_secret = pqc_encapsulate(kem, public_key)\n    assert isinstance(ciphertext, bytes), \"Ciphertext is not bytes\"\n    assert isinstance(shared_secret, bytes), \"Shared secret is not bytes\"\n    # Decapsulate and compare secrets",
        "detail": "AHE_SDK_V6.tests.test_pqc",
        "documentation": {}
    },
    {
        "label": "test_pqc_wrong_key_decapsulation",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_pqc",
        "description": "AHE_SDK_V6.tests.test_pqc",
        "peekOfCode": "def test_pqc_wrong_key_decapsulation():\n    \"\"\"\n    WRONG KEY TEST:\n    - Encapsulate with kem1, decapsulate with kem2.\n    EXPECTED:\n    - No error thrown\n    - Derived shared secret is DIFFERENT (by design for IND-CCA2 security).\n    \"\"\"\n    kem1, pk1 = pqc_keypair(\"Kyber512\")\n    kem2, pk2 = pqc_keypair(\"Kyber512\")",
        "detail": "AHE_SDK_V6.tests.test_pqc",
        "documentation": {}
    },
    {
        "label": "test_pqc_select_and_run",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_pqc",
        "description": "AHE_SDK_V6.tests.test_pqc",
        "peekOfCode": "def test_pqc_select_and_run(anomaly):\n    \"\"\"\n    Test adaptive PQC selection:\n    - anomaly=True  Strong KEMs (e.g., Kyber1024)\n    - anomaly=False  Fast KEMs (e.g., Kyber512)\n    EXPECTED:\n    - Successfully completes without exception.\n    \"\"\"\n    kem_name, pk, ct, ss = pqc_select_and_run(anomaly)\n    assert kem_name in (PQC_FAST_KEMS + PQC_STRONG_KEMS), \"Returned KEM not in supported list\"",
        "detail": "AHE_SDK_V6.tests.test_pqc",
        "documentation": {}
    },
    {
        "label": "test_pqc_performance",
        "kind": 2,
        "importPath": "AHE_SDK_V6.tests.test_pqc",
        "description": "AHE_SDK_V6.tests.test_pqc",
        "peekOfCode": "def test_pqc_performance():\n    \"\"\"\n    Performance Benchmark:\n    Ensure that PQC encapsulation + decapsulation completes under PERFORMANCE_THRESHOLD.\n    \"\"\"\n    kem, pk = pqc_keypair(\"Kyber512\")\n    start = time.time()\n    ct, ss = pqc_encapsulate(kem, pk)\n    pqc_decapsulate(kem, ct)\n    elapsed = time.time() - start",
        "detail": "AHE_SDK_V6.tests.test_pqc",
        "documentation": {}
    },
    {
        "label": "PERFORMANCE_THRESHOLD",
        "kind": 5,
        "importPath": "AHE_SDK_V6.tests.test_pqc",
        "description": "AHE_SDK_V6.tests.test_pqc",
        "peekOfCode": "PERFORMANCE_THRESHOLD = 0.5\n@pytest.mark.parametrize(\"kem_name\", PQC_FAST_KEMS + PQC_STRONG_KEMS)\ndef test_pqc_keypair_generation(kem_name):\n    \"\"\"\n    Test that all supported PQC KEMs generate valid keypairs.\n    EXPECTED:\n    - kem: Valid KeyEncapsulation object\n    - public_key: Non-empty bytes\n    \"\"\"\n    kem, public_key = pqc_keypair(kem_name)",
        "detail": "AHE_SDK_V6.tests.test_pqc",
        "documentation": {}
    },
    {
        "label": "pytestmark",
        "kind": 5,
        "importPath": "AHE_SDK_V6.tests.test_pqc",
        "description": "AHE_SDK_V6.tests.test_pqc",
        "peekOfCode": "pytestmark = pytest.mark.functional",
        "detail": "AHE_SDK_V6.tests.test_pqc",
        "documentation": {}
    },
    {
        "label": "detect_anomaly",
        "kind": 2,
        "importPath": "AHE_SDK_V6.utils.anomaly",
        "description": "AHE_SDK_V6.utils.anomaly",
        "peekOfCode": "def detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    try:\n        suspicious_chars = \"0123456789+/=\\n\"\n        reasons = []\n        if any(c in input_data for c in suspicious_chars):\n            reasons.append(\"Suspicious characters detected\")\n            logger.info(\"Anomaly check: Suspicious characters detected.\")\n        if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:\n            reasons.append(\"Entropy out of range\")\n            logger.info(f\"Anomaly check: Entropy score {entropy_score} out of range.\")",
        "detail": "AHE_SDK_V6.utils.anomaly",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_LOW",
        "kind": 5,
        "importPath": "AHE_SDK_V6.utils.anomaly",
        "description": "AHE_SDK_V6.utils.anomaly",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_LOW = 3.5\nENTROPY_WARN_THRESHOLD_HIGH = 4.75\ndef detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    try:\n        suspicious_chars = \"0123456789+/=\\n\"\n        reasons = []\n        if any(c in input_data for c in suspicious_chars):\n            reasons.append(\"Suspicious characters detected\")\n            logger.info(\"Anomaly check: Suspicious characters detected.\")\n        if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:",
        "detail": "AHE_SDK_V6.utils.anomaly",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_HIGH",
        "kind": 5,
        "importPath": "AHE_SDK_V6.utils.anomaly",
        "description": "AHE_SDK_V6.utils.anomaly",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_HIGH = 4.75\ndef detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    try:\n        suspicious_chars = \"0123456789+/=\\n\"\n        reasons = []\n        if any(c in input_data for c in suspicious_chars):\n            reasons.append(\"Suspicious characters detected\")\n            logger.info(\"Anomaly check: Suspicious characters detected.\")\n        if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:\n            reasons.append(\"Entropy out of range\")",
        "detail": "AHE_SDK_V6.utils.anomaly",
        "documentation": {}
    },
    {
        "label": "shorten_bytes_for_display",
        "kind": 2,
        "importPath": "AHE_SDK_V6.utils.display",
        "description": "AHE_SDK_V6.utils.display",
        "peekOfCode": "def shorten_bytes_for_display(data: bytes, length=10):\n    try:\n        if len(data) <= length:\n            result = data.hex()\n            logger.info(f\"Shortened bytes for display (full): {result}\")\n            return result\n        result = data[:length].hex() + \"...\"\n        logger.info(f\"Shortened bytes for display (truncated): {result}\")\n        return result\n    except Exception as e:",
        "detail": "AHE_SDK_V6.utils.display",
        "documentation": {}
    },
    {
        "label": "calculate_shannon_entropy",
        "kind": 2,
        "importPath": "AHE_SDK_V6.utils.entropy",
        "description": "AHE_SDK_V6.utils.entropy",
        "peekOfCode": "def calculate_shannon_entropy(data: bytes) -> float:\n    try:\n        if not data:\n            logger.warning(\"Empty data passed to calculate_shannon_entropy\")\n            return 0.0\n        freq = {b: data.count(b)/len(data) for b in set(data)}\n        entropy = -sum(p * math.log2(p) for p in freq.values())\n        logger.info(f\"Calculated Shannon entropy: {entropy:.4f}\")\n        return entropy\n    except Exception as e:",
        "detail": "AHE_SDK_V6.utils.entropy",
        "documentation": {}
    },
    {
        "label": "get_environment_entropy",
        "kind": 2,
        "importPath": "AHE_SDK_V6.utils.entropy",
        "description": "AHE_SDK_V6.utils.entropy",
        "peekOfCode": "def get_environment_entropy() -> bytes:\n    try:\n        raw = (\n            str(uuid.getnode()) +\n            str(platform.system()) +\n            str(platform.release()) +\n            str(os.cpu_count()) +\n            str(os.getpid()) +\n            str(time.time()) +\n            str(socket.gethostname())",
        "detail": "AHE_SDK_V6.utils.entropy",
        "documentation": {}
    },
    {
        "label": "hash_stage",
        "kind": 2,
        "importPath": "AHE_SDK_V6.utils.hashing",
        "description": "AHE_SDK_V6.utils.hashing",
        "peekOfCode": "def hash_stage(data: bytes, algo: str) -> bytes:\n    try:\n        h = hashlib.new(algo)\n        h.update(data)\n        logger.info(f\"Hashed data using {algo}\")\n        return h.digest()\n    except Exception as e:\n        logger.error(f\"Error hashing data with {algo}: {e}\", exc_info=True)\n        return b\"\"\ndef multi_stage_hash(data: bytes, extra_entropy: bytes) -> bytes:",
        "detail": "AHE_SDK_V6.utils.hashing",
        "documentation": {}
    },
    {
        "label": "multi_stage_hash",
        "kind": 2,
        "importPath": "AHE_SDK_V6.utils.hashing",
        "description": "AHE_SDK_V6.utils.hashing",
        "peekOfCode": "def multi_stage_hash(data: bytes, extra_entropy: bytes) -> bytes:\n    try:\n        output = data\n        shuffled_algos = random.sample(HASH_ALGORITHMS, len(HASH_ALGORITHMS))\n        logger.info(f\"Hash algorithms order: {shuffled_algos}\")\n        for algo in shuffled_algos:\n            output = hash_stage(output + extra_entropy, algo)\n        logger.info(\"Completed multi-stage hashing\")\n        return output\n    except Exception as e:",
        "detail": "AHE_SDK_V6.utils.hashing",
        "documentation": {}
    },
    {
        "label": "HASH_ALGORITHMS",
        "kind": 5,
        "importPath": "AHE_SDK_V6.utils.hashing",
        "description": "AHE_SDK_V6.utils.hashing",
        "peekOfCode": "HASH_ALGORITHMS = [\n    \"sha256\",\n    \"sha512\",\n    \"sha3_256\",\n    \"sha3_512\"\n]\ndef hash_stage(data: bytes, algo: str) -> bytes:\n    try:\n        h = hashlib.new(algo)\n        h.update(data)",
        "detail": "AHE_SDK_V6.utils.hashing",
        "documentation": {}
    },
    {
        "label": "AHEClient",
        "kind": 6,
        "importPath": "AHE_SDK_V6.ahe_sdk",
        "description": "AHE_SDK_V6.ahe_sdk",
        "peekOfCode": "class AHEClient:\n    def _init_(self, storage_dir=\"secure_storage\"):\n        self.storage_dir = storage_dir\n        if not os.path.exists(self.storage_dir):\n            os.makedirs(self.storage_dir)\n        logger.info(\"[INIT] AHEClient initialized with storage directory\")\n    def encrypt(self, message: str, password: str) -> dict:\n        \"\"\"\n        Encrypt a message using AHE and return metadata info.\n        \"\"\"",
        "detail": "AHE_SDK_V6.ahe_sdk",
        "documentation": {}
    },
    {
        "label": "custom_openapi",
        "kind": 2,
        "importPath": "AHE_SDK_V6.api",
        "description": "AHE_SDK_V6.api",
        "peekOfCode": "def custom_openapi():\n    if app.openapi_schema:\n        return app.openapi_schema\n    openapi_schema = original_openapi()\n    for path in openapi_schema.get(\"paths\", {}).values():\n        for method in path.values():\n            responses = method.get(\"responses\", {})\n            responses.pop(\"422\", None)\n            responses.pop(\"500\", None)\n    app.openapi_schema = openapi_schema",
        "detail": "AHE_SDK_V6.api",
        "documentation": {}
    },
    {
        "label": "app",
        "kind": 5,
        "importPath": "AHE_SDK_V6.api",
        "description": "AHE_SDK_V6.api",
        "peekOfCode": "app = FastAPI(\n    title=\"Adaptive Hashing Encryption API\",\n    description=\"Elite Quantum-Safe Encryption API\",\n    version=\"1.0.0\"\n)\n# Remove 422 & 500 from docs\noriginal_openapi = app.openapi\ndef custom_openapi():\n    if app.openapi_schema:\n        return app.openapi_schema",
        "detail": "AHE_SDK_V6.api",
        "documentation": {}
    },
    {
        "label": "original_openapi",
        "kind": 5,
        "importPath": "AHE_SDK_V6.api",
        "description": "AHE_SDK_V6.api",
        "peekOfCode": "original_openapi = app.openapi\ndef custom_openapi():\n    if app.openapi_schema:\n        return app.openapi_schema\n    openapi_schema = original_openapi()\n    for path in openapi_schema.get(\"paths\", {}).values():\n        for method in path.values():\n            responses = method.get(\"responses\", {})\n            responses.pop(\"422\", None)\n            responses.pop(\"500\", None)",
        "detail": "AHE_SDK_V6.api",
        "documentation": {}
    },
    {
        "label": "app.openapi",
        "kind": 5,
        "importPath": "AHE_SDK_V6.api",
        "description": "AHE_SDK_V6.api",
        "peekOfCode": "app.openapi = custom_openapi\n@app.get(\"/health\", response_model=HealthResponse)\nasync def health_check():\n    return {\"status\": \"healthy\"}\n@app.post(\"/encrypt\", response_model=EncryptResponse)\nasync def encrypt(req: EncryptRequest):\n    try:\n        logger.info(\"[ENCRYPT] Processing request...\")\n        data = encrypt_message(req.message, req.password)\n        return {",
        "detail": "AHE_SDK_V6.api",
        "documentation": {}
    },
    {
        "label": "ColorFormatter",
        "kind": 6,
        "importPath": "AHE_SDK_V6.logger",
        "description": "AHE_SDK_V6.logger",
        "peekOfCode": "class ColorFormatter(logging.Formatter):\n    COLORS = {\n        'DEBUG': Fore.CYAN,\n        'INFO': Fore.GREEN,\n        'WARNING': Fore.YELLOW,\n        'ERROR': Fore.RED,\n        'CRITICAL': Fore.RED + Style.BRIGHT,\n    }\n    # Custom keywords to color-code messages\n    KEYWORD_COLORS = {",
        "detail": "AHE_SDK_V6.logger",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "AHE_SDK_V6.logger",
        "description": "AHE_SDK_V6.logger",
        "peekOfCode": "logger = logging.getLogger(\"AHE_SDK\")\nlogger.setLevel(logging.DEBUG)  # Capture all levels\nfile_handler = logging.FileHandler(\"logs/ahe_sdk.log\")\nfile_handler.setLevel(logging.DEBUG)\nfile_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler.setFormatter(file_formatter)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.DEBUG)\nconsole_formatter = ColorFormatter('%(asctime)s - %(levelname)s - %(message)s')\nconsole_handler.setFormatter(console_formatter)",
        "detail": "AHE_SDK_V6.logger",
        "documentation": {}
    },
    {
        "label": "file_handler",
        "kind": 5,
        "importPath": "AHE_SDK_V6.logger",
        "description": "AHE_SDK_V6.logger",
        "peekOfCode": "file_handler = logging.FileHandler(\"logs/ahe_sdk.log\")\nfile_handler.setLevel(logging.DEBUG)\nfile_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler.setFormatter(file_formatter)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.DEBUG)\nconsole_formatter = ColorFormatter('%(asctime)s - %(levelname)s - %(message)s')\nconsole_handler.setFormatter(console_formatter)\nlogger.addHandler(file_handler)\nlogger.addHandler(console_handler)",
        "detail": "AHE_SDK_V6.logger",
        "documentation": {}
    },
    {
        "label": "file_formatter",
        "kind": 5,
        "importPath": "AHE_SDK_V6.logger",
        "description": "AHE_SDK_V6.logger",
        "peekOfCode": "file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\nfile_handler.setFormatter(file_formatter)\nconsole_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.DEBUG)\nconsole_formatter = ColorFormatter('%(asctime)s - %(levelname)s - %(message)s')\nconsole_handler.setFormatter(console_formatter)\nlogger.addHandler(file_handler)\nlogger.addHandler(console_handler)",
        "detail": "AHE_SDK_V6.logger",
        "documentation": {}
    },
    {
        "label": "console_handler",
        "kind": 5,
        "importPath": "AHE_SDK_V6.logger",
        "description": "AHE_SDK_V6.logger",
        "peekOfCode": "console_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.DEBUG)\nconsole_formatter = ColorFormatter('%(asctime)s - %(levelname)s - %(message)s')\nconsole_handler.setFormatter(console_formatter)\nlogger.addHandler(file_handler)\nlogger.addHandler(console_handler)",
        "detail": "AHE_SDK_V6.logger",
        "documentation": {}
    },
    {
        "label": "console_formatter",
        "kind": 5,
        "importPath": "AHE_SDK_V6.logger",
        "description": "AHE_SDK_V6.logger",
        "peekOfCode": "console_formatter = ColorFormatter('%(asctime)s - %(levelname)s - %(message)s')\nconsole_handler.setFormatter(console_formatter)\nlogger.addHandler(file_handler)\nlogger.addHandler(console_handler)",
        "detail": "AHE_SDK_V6.logger",
        "documentation": {}
    },
    {
        "label": "interactive_menu",
        "kind": 2,
        "importPath": "AHE_SDK_V6.main",
        "description": "AHE_SDK_V6.main",
        "peekOfCode": "def interactive_menu():\n    print(\"=== Adaptive Hashing Encryption SDK ===\")\n    while True:\n        print(\"\\nOptions:\")\n        print(\"1. Encrypt a message\")\n        print(\"2. Decrypt the latest message\")\n        print(\"3. Exit\")\n        choice = input(\"Choice: \").strip()\n        if choice == \"1\":\n            message = input(\"Enter message to encrypt: \").strip()",
        "detail": "AHE_SDK_V6.main",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "AHE_SDK_V6.main",
        "description": "AHE_SDK_V6.main",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser(description=\"Adaptive Hashing Encryption (AHE) CLI Tool\")\n    parser.add_argument(\"--encrypt\", type=str, help=\"Message to encrypt\")\n    parser.add_argument(\"--decrypt\", action=\"store_true\", help=\"Decrypt the latest message\")\n    parser.add_argument(\"--password\", type=str, help=\"Password for encryption/decryption\")\n    args = parser.parse_args()\n    if args.encrypt and args.password:\n        encrypt_message(args.encrypt, args.password)\n    elif args.decrypt and args.password:\n        try:",
        "detail": "AHE_SDK_V6.main",
        "documentation": {}
    },
    {
        "label": "EncryptRequest",
        "kind": 6,
        "importPath": "AHE_SDK_V6.schemas",
        "description": "AHE_SDK_V6.schemas",
        "peekOfCode": "class EncryptRequest(BaseModel):\n    message: str\n    password: str\nclass EncryptResponse(BaseModel):\n    status: str\n    ciphertext_path: Optional[str]\n    metadata_path: Optional[str]\n    pqc_profile: Optional[str]\n    entropy_score: Optional[float]\n    anomaly_detected: Optional[bool]",
        "detail": "AHE_SDK_V6.schemas",
        "documentation": {}
    },
    {
        "label": "EncryptResponse",
        "kind": 6,
        "importPath": "AHE_SDK_V6.schemas",
        "description": "AHE_SDK_V6.schemas",
        "peekOfCode": "class EncryptResponse(BaseModel):\n    status: str\n    ciphertext_path: Optional[str]\n    metadata_path: Optional[str]\n    pqc_profile: Optional[str]\n    entropy_score: Optional[float]\n    anomaly_detected: Optional[bool]\nclass DecryptRequest(BaseModel):\n    password: str\nclass DecryptResponse(BaseModel):",
        "detail": "AHE_SDK_V6.schemas",
        "documentation": {}
    },
    {
        "label": "DecryptRequest",
        "kind": 6,
        "importPath": "AHE_SDK_V6.schemas",
        "description": "AHE_SDK_V6.schemas",
        "peekOfCode": "class DecryptRequest(BaseModel):\n    password: str\nclass DecryptResponse(BaseModel):\n    status: str\n    decrypted_message: Optional[str]\n    pqc_profile: Optional[str]\n    entropy_score: Optional[float]\n    anomaly_detected: Optional[bool]\nclass HealthResponse(BaseModel):\n    status: str",
        "detail": "AHE_SDK_V6.schemas",
        "documentation": {}
    },
    {
        "label": "DecryptResponse",
        "kind": 6,
        "importPath": "AHE_SDK_V6.schemas",
        "description": "AHE_SDK_V6.schemas",
        "peekOfCode": "class DecryptResponse(BaseModel):\n    status: str\n    decrypted_message: Optional[str]\n    pqc_profile: Optional[str]\n    entropy_score: Optional[float]\n    anomaly_detected: Optional[bool]\nclass HealthResponse(BaseModel):\n    status: str",
        "detail": "AHE_SDK_V6.schemas",
        "documentation": {}
    },
    {
        "label": "HealthResponse",
        "kind": 6,
        "importPath": "AHE_SDK_V6.schemas",
        "description": "AHE_SDK_V6.schemas",
        "peekOfCode": "class HealthResponse(BaseModel):\n    status: str",
        "detail": "AHE_SDK_V6.schemas",
        "documentation": {}
    },
    {
        "label": "count_non_upstream_kems",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "def count_non_upstream_kems(alglist):\n    counted=0\n    docs_dir = os.path.join(os.environ['LIBOQS_DIR'], 'docs', 'algorithms', 'kem')\n    for alg in alglist:\n       with open(os.path.join(docs_dir, alg+\".yml\"), mode='r', encoding='utf-8') as f:\n           algyml = yaml.safe_load(f.read())\n           counted = counted + len(algyml['parameter-sets'])\n    return counted\ndef file_get_contents(filename, encoding=None):\n    with open(filename, mode='r', encoding=encoding) as fh:",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "file_get_contents",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "def file_get_contents(filename, encoding=None):\n    with open(filename, mode='r', encoding=encoding) as fh:\n        return fh.read()\ndef file_put_contents(filename, s, encoding=None):\n    with open(filename, mode='w', encoding=encoding) as fh:\n        fh.write(s)\ndef shell(command, expect=0):\n    subprocess_stdout = None if DEBUG > 0 else subprocess.DEVNULL\n    ret = subprocess.run(command, stdout=subprocess_stdout, stderr=subprocess_stdout)\n    if ret.returncode != expect:",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "file_put_contents",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "def file_put_contents(filename, s, encoding=None):\n    with open(filename, mode='w', encoding=encoding) as fh:\n        fh.write(s)\ndef shell(command, expect=0):\n    subprocess_stdout = None if DEBUG > 0 else subprocess.DEVNULL\n    ret = subprocess.run(command, stdout=subprocess_stdout, stderr=subprocess_stdout)\n    if ret.returncode != expect:\n        raise Exception(\"'{}' failed with error {}. Expected {}.\".format(\" \".join(command), ret, expect))\n# Generate template from specified scheme to replace old file in 'copy' mode\n# but preserves additions made to file in prior runs of 'libjade' mode ",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "shell",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "def shell(command, expect=0):\n    subprocess_stdout = None if DEBUG > 0 else subprocess.DEVNULL\n    ret = subprocess.run(command, stdout=subprocess_stdout, stderr=subprocess_stdout)\n    if ret.returncode != expect:\n        raise Exception(\"'{}' failed with error {}. Expected {}.\".format(\" \".join(command), ret, expect))\n# Generate template from specified scheme to replace old file in 'copy' mode\n# but preserves additions made to file in prior runs of 'libjade' mode \ndef generator(destination_file_path, template_filename, delimiter, family, scheme_desired):\n    template = file_get_contents(\n        os.path.join(os.environ['LIBOQS_DIR'], 'scripts', 'copy_from_upstream', template_filename))",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "generator",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "def generator(destination_file_path, template_filename, delimiter, family, scheme_desired):\n    template = file_get_contents(\n        os.path.join(os.environ['LIBOQS_DIR'], 'scripts', 'copy_from_upstream', template_filename))\n    f = copy.deepcopy(family)\n    contents = file_get_contents(os.path.join(os.environ['LIBOQS_DIR'], destination_file_path))\n    if scheme_desired != None:\n        f['schemes'] = [x for x in f['schemes'] if x == scheme_desired]\n    identifier = '{} OQS_COPY_FROM_{}_FRAGMENT_{}'.format(delimiter, 'LIBJADE', os.path.splitext(os.path.basename(template_filename))[0].upper())\n    if identifier in contents:\n        identifier_start, identifier_end = identifier + '_START', identifier + '_END'",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "generator_all",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "def generator_all(filename, instructions):\n    template = file_get_contents(os.path.join(os.environ['LIBOQS_DIR'], 'scripts', 'copy_from_upstream', filename))\n    contents = jinja2.Template(template).render({'instructions': instructions})\n    file_put_contents(filename, contents)\ndef replacer(filename, instructions, delimiter, libjade=False):\n    fragments = glob.glob(\n        os.path.join(os.environ['LIBOQS_DIR'], 'scripts', 'copy_from_upstream', filename, '*.{}'.format('libjade' if libjade else 'fragment')))\n    contents = file_get_contents(os.path.join(os.environ['LIBOQS_DIR'], filename))\n    for fragment in fragments:\n        template = file_get_contents(fragment)",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "replacer",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "def replacer(filename, instructions, delimiter, libjade=False):\n    fragments = glob.glob(\n        os.path.join(os.environ['LIBOQS_DIR'], 'scripts', 'copy_from_upstream', filename, '*.{}'.format('libjade' if libjade else 'fragment')))\n    contents = file_get_contents(os.path.join(os.environ['LIBOQS_DIR'], filename))\n    for fragment in fragments:\n        template = file_get_contents(fragment)\n        identifier = os.path.splitext(os.path.basename(fragment))[0]\n        identifier_start = '{} OQS_COPY_FROM_{}_FRAGMENT_{}_START'.format(delimiter, 'LIBJADE' if libjade else 'UPSTREAM', identifier.upper())\n        identifier_end = '{} OQS_COPY_FROM_{}_FRAGMENT_{}_END'.format(delimiter, 'LIBJADE' if libjade else 'UPSTREAM', identifier.upper())\n        preamble = contents[:contents.find(identifier_start)]",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "replacer_contextual",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "def replacer_contextual(destination_file_path, template_file_path, delimiter, family, scheme_desired, libjade=False):\n    contents = file_get_contents(destination_file_path)\n    template = file_get_contents(template_file_path)\n    identifier = os.path.basename(template_file_path).split(os.extsep)[0]\n    identifier_start = '{} OQS_COPY_FROM_{}_FRAGMENT_{}_START'.format(delimiter, 'LIBJADE' if libjade else 'UPSTREAM', identifier.upper())\n    identifier_end = '{} OQS_COPY_FROM_{}_FRAGMENT_{}_END'.format(delimiter, 'LIBJADE' if libjade else 'UPSTREAM', identifier.upper())\n    f = copy.deepcopy(family)\n    if scheme_desired != None:\n        f['schemes'] = [x for x in f['schemes'] if x == scheme_desired]\n    preamble = contents[:contents.find(identifier_start)]",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "load_instructions",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "def load_instructions(file='copy_from_upstream.yml'):\n    instructions = file_get_contents(\n        os.path.join(os.environ['LIBOQS_DIR'], 'scripts', 'copy_from_upstream', file),\n        encoding='utf-8')\n    instructions = yaml.safe_load(instructions)\n    upstreams = {}\n    for upstream in instructions['upstreams']:\n        upstream_name = upstream['name']\n        upstream_git_url = upstream['git_url']\n        upstream_git_commit = upstream['git_commit']",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "handle_common_deps",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "def handle_common_deps(common_dep, family, dst_basedir):\n    # Obtain current implementation array in i\n    if DEBUG > 2:\n        print(\"CDEP = %s\" % (common_dep))\n    # if 'upstream_location' in scheme and os.environ.get(scheme['upstream_location']):\n    if DEBUG > 3:\n        print(\"Obtain files for common dependency %s\" % (common_dep))\n        print(\"Obtain files for %s\" % (scheme))\n    cdep_folder_name = '{}_{}'.format(family['upstream_location'], common_dep['name'])\n    shutil.rmtree(os.path.join(dst_basedir, 'src', family['type'], family['name'],",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "handle_implementation",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "def handle_implementation(impl, family, scheme, dst_basedir):\n    # Obtain current implementation array in i\n    for imp in scheme['metadata']['implementations']:\n        if imp['name'] == impl:\n            i = imp\n    if DEBUG > 2:\n        print(\"IMP = %s\" % (i))\n    # if 'upstream_location' in scheme and os.environ.get(scheme['upstream_location']):\n    if DEBUG > 3:\n        print(\"Obtain files for implementation %s\" % (impl))",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "process_families",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "def process_families(instructions, basedir, with_kat, with_generator, with_libjade=False):\n    for family in instructions['kems'] + instructions['sigs']:\n        try:\n            os.makedirs(os.path.join(basedir, 'src', family['type'], family['name']))\n        except:\n            if delete:\n                # clear out all subdirectories\n                with os.scandir(os.path.join(basedir, 'src', family['type'], family['name'])) as ls:\n                    for entry in ls:\n                        if entry.is_dir(follow_symlinks=False):",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "copy_from_upstream",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "def copy_from_upstream():\n    for t in [\"kem\", \"sig\"]:\n        with open(os.path.join(os.environ['LIBOQS_DIR'], 'tests', 'KATs', t, 'kats.json'), 'r') as fp:\n            kats[t] = json.load(fp)\n    instructions = load_instructions('copy_from_upstream.yml')\n    process_families(instructions, os.environ['LIBOQS_DIR'], True, True)\n    replacer('.CMake/alg_support.cmake', instructions, '#####')\n    replacer('CMakeLists.txt', instructions, '#####')\n    replacer('src/oqsconfig.h.cmake', instructions, '/////')\n    replacer('src/CMakeLists.txt', instructions, '#####')",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "copy_from_libjade",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "def copy_from_libjade():\n    for t in [\"kem\", \"sig\"]:\n        with open(os.path.join(os.environ['LIBOQS_DIR'], 'tests', 'KATs', t, 'kats.json'), 'r') as fp:\n            kats[t] = json.load(fp)\n    instructions = load_instructions('copy_from_libjade.yml')\n    process_families(instructions, os.environ['LIBOQS_DIR'], True, False, True)\n    replacer('.CMake/alg_support.cmake', instructions, '#####', libjade=True)\n    replacer('src/oqsconfig.h.cmake', instructions, '/////', libjade=True)\n    for t in [\"kem\", \"sig\"]:\n        with open(os.path.join(os.environ['LIBOQS_DIR'], 'tests', 'KATs', t, 'kats.json'), \"w\") as f:",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "verify_from_upstream",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "def verify_from_upstream():\n    instructions = load_instructions()\n    basedir = \"verify_from_upstream\"\n    process_families(instructions, basedir, False, False)\n    validated = 0\n    differ = 0\n    dinfo = []\n    for family in instructions['kems'] + instructions['sigs']:\n        for scheme in family['schemes']:\n            if 'implementation' in scheme:",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "kats",
        "kind": 5,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "kats = {}\nnon_upstream_kems = 0\nparser = argparse.ArgumentParser()\nparser.add_argument(\"-v\", \"--verbosity\", type=int)\nparser.add_argument(\"-k\", \"--keep_data\", action='store_true', help='Keep upstream code in the \"repos\" folder')\nparser.add_argument(\"-d\", \"--delete\", action='store_true', help='Delete untracked files from implementation directories')\nparser.add_argument(\"operation\", choices=[\"copy\", \"verify\", \"libjade\"])\nargs = parser.parse_args()\nif args.verbosity:\n    DEBUG = args.verbosity",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "non_upstream_kems",
        "kind": 5,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "non_upstream_kems = 0\nparser = argparse.ArgumentParser()\nparser.add_argument(\"-v\", \"--verbosity\", type=int)\nparser.add_argument(\"-k\", \"--keep_data\", action='store_true', help='Keep upstream code in the \"repos\" folder')\nparser.add_argument(\"-d\", \"--delete\", action='store_true', help='Delete untracked files from implementation directories')\nparser.add_argument(\"operation\", choices=[\"copy\", \"verify\", \"libjade\"])\nargs = parser.parse_args()\nif args.verbosity:\n    DEBUG = args.verbosity\nelse:",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "parser = argparse.ArgumentParser()\nparser.add_argument(\"-v\", \"--verbosity\", type=int)\nparser.add_argument(\"-k\", \"--keep_data\", action='store_true', help='Keep upstream code in the \"repos\" folder')\nparser.add_argument(\"-d\", \"--delete\", action='store_true', help='Delete untracked files from implementation directories')\nparser.add_argument(\"operation\", choices=[\"copy\", \"verify\", \"libjade\"])\nargs = parser.parse_args()\nif args.verbosity:\n    DEBUG = args.verbosity\nelse:\n    DEBUG = 0",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "args = parser.parse_args()\nif args.verbosity:\n    DEBUG = args.verbosity\nelse:\n    DEBUG = 0\nkeepdata = True if args.keep_data else False\ndelete = True if args.delete else False\nif 'LIBOQS_DIR' not in os.environ:\n    print(\"Must set environment variable LIBOQS_DIR\")\n    exit(1)",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "keepdata",
        "kind": 5,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "keepdata = True if args.keep_data else False\ndelete = True if args.delete else False\nif 'LIBOQS_DIR' not in os.environ:\n    print(\"Must set environment variable LIBOQS_DIR\")\n    exit(1)\n# scours the documentation for non-upstream KEMs\n# returns the number of documented ones\ndef count_non_upstream_kems(alglist):\n    counted=0\n    docs_dir = os.path.join(os.environ['LIBOQS_DIR'], 'docs', 'algorithms', 'kem')",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "delete",
        "kind": 5,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "delete = True if args.delete else False\nif 'LIBOQS_DIR' not in os.environ:\n    print(\"Must set environment variable LIBOQS_DIR\")\n    exit(1)\n# scours the documentation for non-upstream KEMs\n# returns the number of documented ones\ndef count_non_upstream_kems(alglist):\n    counted=0\n    docs_dir = os.path.join(os.environ['LIBOQS_DIR'], 'docs', 'algorithms', 'kem')\n    for alg in alglist:",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "non_upstream_kems",
        "kind": 5,
        "importPath": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "description": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "peekOfCode": "non_upstream_kems = count_non_upstream_kems(['bike', 'frodokem', 'ntruprime'])\nif args.operation == \"copy\":\n    copy_from_upstream()\nelif args.operation == \"libjade\":\n    copy_from_libjade()\nelif args.operation == \"verify\":\n    verify_from_upstream()",
        "detail": "liboqs.scripts.copy_from_upstream.copy_from_upstream",
        "documentation": {}
    },
    {
        "label": "shell",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "description": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "peekOfCode": "def shell(command, expect=0):\n    subprocess_stdout = None if DEBUG > 0 else subprocess.DEVNULL\n    ret = subprocess.run(command, stdout=subprocess_stdout, stderr=subprocess_stdout)\n    if ret.returncode != expect:\n        raise Exception(\"'{}' failed with error {}. Expected {}.\".format(\" \".join(command), ret, expect))\ndef load_yaml(filename, encoding='utf-8'):\n    with open(filename, mode='r', encoding=encoding) as fh:\n        return yaml.safe_load(fh.read())\ndef store_yaml(filename, contents, encoding='utf-8'):\n    with open(filename, mode='w', encoding=encoding) as fh:",
        "detail": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "documentation": {}
    },
    {
        "label": "load_yaml",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "description": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "peekOfCode": "def load_yaml(filename, encoding='utf-8'):\n    with open(filename, mode='r', encoding=encoding) as fh:\n        return yaml.safe_load(fh.read())\ndef store_yaml(filename, contents, encoding='utf-8'):\n    with open(filename, mode='w', encoding=encoding) as fh:\n        yaml.dump(contents, fh, sort_keys=False, allow_unicode=True)\ndef fetch_upstream(liboqs_root, upstream_info):\n    work_dir_root = os.path.join(liboqs_root, 'scripts', 'copy_from_upstream', 'repos')\n    os.makedirs(work_dir_root, exist_ok=True)\n    work_dir = os.path.join(work_dir_root, upstream_info['name'])",
        "detail": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "documentation": {}
    },
    {
        "label": "store_yaml",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "description": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "peekOfCode": "def store_yaml(filename, contents, encoding='utf-8'):\n    with open(filename, mode='w', encoding=encoding) as fh:\n        yaml.dump(contents, fh, sort_keys=False, allow_unicode=True)\ndef fetch_upstream(liboqs_root, upstream_info):\n    work_dir_root = os.path.join(liboqs_root, 'scripts', 'copy_from_upstream', 'repos')\n    os.makedirs(work_dir_root, exist_ok=True)\n    work_dir = os.path.join(work_dir_root, upstream_info['name'])\n    work_dotgit = os.path.join(work_dir, '.git')\n    if not os.path.exists(work_dotgit):\n        shell(['git', 'init', work_dir])",
        "detail": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "documentation": {}
    },
    {
        "label": "fetch_upstream",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "description": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "peekOfCode": "def fetch_upstream(liboqs_root, upstream_info):\n    work_dir_root = os.path.join(liboqs_root, 'scripts', 'copy_from_upstream', 'repos')\n    os.makedirs(work_dir_root, exist_ok=True)\n    work_dir = os.path.join(work_dir_root, upstream_info['name'])\n    work_dotgit = os.path.join(work_dir, '.git')\n    if not os.path.exists(work_dotgit):\n        shell(['git', 'init', work_dir])\n        shell(['git', '--git-dir', work_dotgit, 'remote', 'add', 'origin', upstream_info['git_url']])\n        shell(['git', '--git-dir', work_dotgit, '--work-tree', work_dir, 'remote', 'set-url', 'origin', upstream_info['git_url']])\n        shell(['git', '--git-dir', work_dotgit, '--work-tree', work_dir, 'fetch', '--depth=1', 'origin', upstream_info['git_commit']])",
        "detail": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "documentation": {}
    },
    {
        "label": "rhs_if_not_equal",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "description": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "peekOfCode": "def rhs_if_not_equal(lhs, rhs, not_equal_msg):\n    if lhs != rhs:\n        if DEBUG > 0:\n            caller = inspect.getframeinfo(inspect.stack()[1][0])\n            print(\"Line {}: Discrepancy in {}: lhs: {}, rhs: {}\".format(caller.lineno, not_equal_msg, lhs, rhs))\n            if DEBUG > 1:\n               exit(1)\n        return rhs\n    return lhs\ndef get_upstream_info(upstream_list, location):",
        "detail": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "documentation": {}
    },
    {
        "label": "get_upstream_info",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "description": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "peekOfCode": "def get_upstream_info(upstream_list, location):\n    for i in upstream_list:\n       if i['name'] == location:\n           return i\n    print(\"Error: Cannot find location %s in upstream list\" % (location))\n    print(upstream_list)\n    exit(1)\ndef get_oqs_yaml(param_list, name):\n    ctr=0\n    for i in param_list:",
        "detail": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "documentation": {}
    },
    {
        "label": "get_oqs_yaml",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "description": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "peekOfCode": "def get_oqs_yaml(param_list, name):\n    ctr=0\n    for i in param_list:\n       if i['name'] == name:\n           return ctr, i\n       ctr=ctr+1\n    print(\"Error: Cannot find name %s in param list\" % (name))\n    print(param_list)\n    exit(1)\n# Merge documentation contained in liboqs_root/docs/algorithms/kem/kem['name'].yml with upstream information:",
        "detail": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "documentation": {}
    },
    {
        "label": "update_upstream_kem_alg_docs",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "description": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "peekOfCode": "def update_upstream_kem_alg_docs(liboqs_root, kems, upstream_info, write_changes=False):\n    for kem in kems:\n        ui = get_upstream_info(upstream_info, kem['upstream_location'])\n        ouis = dict()\n        if 'arch_specific_upstream_locations' in kem:\n            for arch_specific_ul in kem['arch_specific_upstream_locations']:\n                name = kem['arch_specific_upstream_locations'][arch_specific_ul] + '-' + str(arch_specific_ul)\n                ouis[name] = get_upstream_info(upstream_info, kem['arch_specific_upstream_locations'][arch_specific_ul])\n        patches_done=\"\"\n        if 'patches' in ui:",
        "detail": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "documentation": {}
    },
    {
        "label": "update_libjade_kem_alg_docs",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "description": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "peekOfCode": "def update_libjade_kem_alg_docs(liboqs_root, kems, upstream_info, write_changes=False):\n    for kem in kems:\n        ui = get_upstream_info(upstream_info, kem['upstream_location'])\n        upstream_root = ui['upstream_root']\n        meta_yaml_path_template = ui['kem_meta_path']\n        oqs_yaml_path = os.path.join(liboqs_root, 'docs', 'algorithms', 'kem', '{}.yml'.format(kem['name']))\n        oqs_yaml = load_yaml(oqs_yaml_path)\n        # We cannot assume that the ordering of \"parameter-sets\"\n        # in the OQS YAML files matches that of copy_from_upstream.yml\n        # hence use helper function get_oqs_yaml(alg_name)",
        "detail": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "documentation": {}
    },
    {
        "label": "update_upstream_sig_alg_docs",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "description": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "peekOfCode": "def update_upstream_sig_alg_docs(liboqs_root, sigs, upstream_info, write_changes=False):\n    for sig in sigs:\n        ui = get_upstream_info(upstream_info, sig['upstream_location'])\n        ouis = dict()\n        if 'arch_specific_upstream_locations' in sig:\n            for arch_specific_ul in sig['arch_specific_upstream_locations']:\n                name = sig['arch_specific_upstream_locations'][arch_specific_ul] + '-' + str(arch_specific_ul)\n                ouis[name] = get_upstream_info(upstream_info, sig['arch_specific_upstream_locations'][arch_specific_ul])\n        patches_done=\"\"\n        if 'patches' in ui:",
        "detail": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "documentation": {}
    },
    {
        "label": "do_it",
        "kind": 2,
        "importPath": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "description": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "peekOfCode": "def do_it(liboqs_root, upstream_location='upstream'):\n   global DEBUG\n   if liboqs_root == None:\n      parser = argparse.ArgumentParser()\n      parser.add_argument(\"--liboqs-root\", default=os.path.join(\"..\", \"..\"))\n      parser.add_argument(\"-w\", \"--write-changes\", dest=\"write_changes\", action='store_true')\n      parser.add_argument(\"-v\", \"--verbosity\", type=int)\n      args = parser.parse_args()\n      if args.verbosity:\n          DEBUG = args.verbosity",
        "detail": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "documentation": {}
    },
    {
        "label": "DEBUG",
        "kind": 5,
        "importPath": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "description": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "peekOfCode": "DEBUG = 0\ndef shell(command, expect=0):\n    subprocess_stdout = None if DEBUG > 0 else subprocess.DEVNULL\n    ret = subprocess.run(command, stdout=subprocess_stdout, stderr=subprocess_stdout)\n    if ret.returncode != expect:\n        raise Exception(\"'{}' failed with error {}. Expected {}.\".format(\" \".join(command), ret, expect))\ndef load_yaml(filename, encoding='utf-8'):\n    with open(filename, mode='r', encoding=encoding) as fh:\n        return yaml.safe_load(fh.read())\ndef store_yaml(filename, contents, encoding='utf-8'):",
        "detail": "liboqs.scripts.copy_from_upstream.update_upstream_alg_docs",
        "documentation": {}
    },
    {
        "label": "anchorstring",
        "kind": 2,
        "importPath": "liboqs.scripts.doxyfy",
        "description": "liboqs.scripts.doxyfy",
        "peekOfCode": "def anchorstring(str):\n    doxyref=str.replace(\"/\", \"\")\n    # can't simply use lower() as github-markdown retains non-leading uppercase characters\n    # so lowercase only every char after a space:\n    drwords = doxyref.split(\" \")\n    doxyref = \"\"\n    i = 0\n    while i < len(drwords):\n        if len(drwords[i]) != 0:\n            doxyref = doxyref+drwords[i][0].lower() + drwords[i][1:]",
        "detail": "liboqs.scripts.doxyfy",
        "documentation": {}
    },
    {
        "label": "reformat_anchors",
        "kind": 2,
        "importPath": "liboqs.scripts.doxyfy",
        "description": "liboqs.scripts.doxyfy",
        "peekOfCode": "def reformat_anchors(s):\n   if \"](#\" in s:\n      i = s.index(\"](#\") + 3\n      j = s[i:].index(\")\") + i\n      return s[0:i] + anchorstring(s[i:j]) + s[j:]\n   else: \n      return s\nif len(sys.argv) != 3 or not Path(sys.argv[1]).is_file():\n   print(\"Expecting original and new file location. Exiting.\")\n   exit(1)",
        "detail": "liboqs.scripts.doxyfy",
        "documentation": {}
    },
    {
        "label": "infile",
        "kind": 5,
        "importPath": "liboqs.scripts.doxyfy",
        "description": "liboqs.scripts.doxyfy",
        "peekOfCode": "infile = open(sys.argv[1], 'r')\nlines = infile.readlines()\nwith open(sys.argv[2], \"w\") as outfile:\n    # ll is last line: can only be written when anchor property is known\n    # and that propery can be set with subsequent line of \"===\"\n    ll = None\n    possibleanchor = None\n    for line in lines:\n        nl = line\n        if line.startswith(\"#\"): # anchor for sure",
        "detail": "liboqs.scripts.doxyfy",
        "documentation": {}
    },
    {
        "label": "lines",
        "kind": 5,
        "importPath": "liboqs.scripts.doxyfy",
        "description": "liboqs.scripts.doxyfy",
        "peekOfCode": "lines = infile.readlines()\nwith open(sys.argv[2], \"w\") as outfile:\n    # ll is last line: can only be written when anchor property is known\n    # and that propery can be set with subsequent line of \"===\"\n    ll = None\n    possibleanchor = None\n    for line in lines:\n        nl = line\n        if line.startswith(\"#\"): # anchor for sure\n            # space must exist",
        "detail": "liboqs.scripts.doxyfy",
        "documentation": {}
    },
    {
        "label": "load_yaml",
        "kind": 2,
        "importPath": "liboqs.scripts.format_docs_yaml",
        "description": "liboqs.scripts.format_docs_yaml",
        "peekOfCode": "def load_yaml(filename, encoding='utf-8'):\n    with open(filename, mode='r', encoding=encoding) as fh:\n        return yaml.safe_load(fh.read())\ndef store_yaml(filename, contents, encoding='utf-8'):\n    with open(filename, mode='w', encoding=encoding) as fh:\n        yaml.dump(contents, fh, sort_keys=False, allow_unicode=True)\nfor kem_yaml_path in glob.glob(os.path.join(args.liboqs_root, 'docs', 'algorithms', 'kem', '*.yml')):\n    print('Formatting {}.'.format(os.path.basename(kem_yaml_path)))\n    kem_yaml = load_yaml(kem_yaml_path)\n    store_yaml(kem_yaml_path, kem_yaml)",
        "detail": "liboqs.scripts.format_docs_yaml",
        "documentation": {}
    },
    {
        "label": "store_yaml",
        "kind": 2,
        "importPath": "liboqs.scripts.format_docs_yaml",
        "description": "liboqs.scripts.format_docs_yaml",
        "peekOfCode": "def store_yaml(filename, contents, encoding='utf-8'):\n    with open(filename, mode='w', encoding=encoding) as fh:\n        yaml.dump(contents, fh, sort_keys=False, allow_unicode=True)\nfor kem_yaml_path in glob.glob(os.path.join(args.liboqs_root, 'docs', 'algorithms', 'kem', '*.yml')):\n    print('Formatting {}.'.format(os.path.basename(kem_yaml_path)))\n    kem_yaml = load_yaml(kem_yaml_path)\n    store_yaml(kem_yaml_path, kem_yaml)\nfor sig_yaml_path in glob.glob(os.path.join(args.liboqs_root, 'docs', 'algorithms', 'sig', '*.yml')):\n    print('Formatting {}.'.format(os.path.basename(sig_yaml_path)))\n    sig_yaml = load_yaml(sig_yaml_path)",
        "detail": "liboqs.scripts.format_docs_yaml",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "liboqs.scripts.format_docs_yaml",
        "description": "liboqs.scripts.format_docs_yaml",
        "peekOfCode": "parser = argparse.ArgumentParser()\nparser.add_argument(\"--liboqs-root\", default=\".\")\nargs = parser.parse_args()\ndef load_yaml(filename, encoding='utf-8'):\n    with open(filename, mode='r', encoding=encoding) as fh:\n        return yaml.safe_load(fh.read())\ndef store_yaml(filename, contents, encoding='utf-8'):\n    with open(filename, mode='w', encoding=encoding) as fh:\n        yaml.dump(contents, fh, sort_keys=False, allow_unicode=True)\nfor kem_yaml_path in glob.glob(os.path.join(args.liboqs_root, 'docs', 'algorithms', 'kem', '*.yml')):",
        "detail": "liboqs.scripts.format_docs_yaml",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "liboqs.scripts.format_docs_yaml",
        "description": "liboqs.scripts.format_docs_yaml",
        "peekOfCode": "args = parser.parse_args()\ndef load_yaml(filename, encoding='utf-8'):\n    with open(filename, mode='r', encoding=encoding) as fh:\n        return yaml.safe_load(fh.read())\ndef store_yaml(filename, contents, encoding='utf-8'):\n    with open(filename, mode='w', encoding=encoding) as fh:\n        yaml.dump(contents, fh, sort_keys=False, allow_unicode=True)\nfor kem_yaml_path in glob.glob(os.path.join(args.liboqs_root, 'docs', 'algorithms', 'kem', '*.yml')):\n    print('Formatting {}.'.format(os.path.basename(kem_yaml_path)))\n    kem_yaml = load_yaml(kem_yaml_path)",
        "detail": "liboqs.scripts.format_docs_yaml",
        "documentation": {}
    },
    {
        "label": "KATSHA",
        "kind": 5,
        "importPath": "liboqs.scripts.genkatdict",
        "description": "liboqs.scripts.genkatdict",
        "peekOfCode": "KATSHA = \".kat.sha256\"\nd = {}\nfor filename in os.listdir(\".\"):\n    if filename.endswith(KATSHA): \n        alg = filename[:-len(KATSHA)]\n        with open(filename, \"r\") as f:\n           d[alg] = f.read()\n        print(\"added %s with KATSHA %s\" % (alg, d[alg]))\nwith open(\"kats.json\", \"w\") as f:\n   json.dumps(d, f, indent=2, sort_keys=True)",
        "detail": "liboqs.scripts.genkatdict",
        "documentation": {}
    },
    {
        "label": "d",
        "kind": 5,
        "importPath": "liboqs.scripts.genkatdict",
        "description": "liboqs.scripts.genkatdict",
        "peekOfCode": "d = {}\nfor filename in os.listdir(\".\"):\n    if filename.endswith(KATSHA): \n        alg = filename[:-len(KATSHA)]\n        with open(filename, \"r\") as f:\n           d[alg] = f.read()\n        print(\"added %s with KATSHA %s\" % (alg, d[alg]))\nwith open(\"kats.json\", \"w\") as f:\n   json.dumps(d, f, indent=2, sort_keys=True)",
        "detail": "liboqs.scripts.genkatdict",
        "documentation": {}
    },
    {
        "label": "cutoffpercent",
        "kind": 5,
        "importPath": "liboqs.scripts.noregress",
        "description": "liboqs.scripts.noregress",
        "peekOfCode": "cutoffpercent = 15\nwith open(sys.argv[1], 'r') as json_file:\n   d1 = json.load(json_file)\nwith open(sys.argv[2], 'r') as json_file:\n   d2 = json.load(json_file)\nfor k in d1.keys(): # algs\n      if k != \"config\" and k != \"cpuinfo\":\n          if k in d2.keys():\n            for op in d1[k]:\n              diff = 100.0*(float(d1[k][op]) - float(d2[k][op]))/float(d1[k][op])",
        "detail": "liboqs.scripts.noregress",
        "documentation": {}
    },
    {
        "label": "State",
        "kind": 6,
        "importPath": "liboqs.scripts.parse_liboqs_speed",
        "description": "liboqs.scripts.parse_liboqs_speed",
        "peekOfCode": "class State(Enum):\n   starting=0\n   config=1\n   parsing=2\ndata=[]\n# Parse command-line arguments\nparser = argparse.ArgumentParser(description=\"Parse speed_kem output and extract cycles.\")\nparser.add_argument(\"logfile\", help=\"Log file to parse\")\nparser.add_argument(\"--algorithm\", help=\"Algorithm name (e.g., BIKE-L1)\", required=True)\nargs = parser.parse_args()",
        "detail": "liboqs.scripts.parse_liboqs_speed",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "liboqs.scripts.parse_liboqs_speed",
        "description": "liboqs.scripts.parse_liboqs_speed",
        "peekOfCode": "parser = argparse.ArgumentParser(description=\"Parse speed_kem output and extract cycles.\")\nparser.add_argument(\"logfile\", help=\"Log file to parse\")\nparser.add_argument(\"--algorithm\", help=\"Algorithm name (e.g., BIKE-L1)\", required=True)\nargs = parser.parse_args()\nfn = args.logfile\nalg = args.algorithm\nstate = State.starting\nconfig = ''\nwith open(fn) as fp: \n   while True:",
        "detail": "liboqs.scripts.parse_liboqs_speed",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "liboqs.scripts.parse_liboqs_speed",
        "description": "liboqs.scripts.parse_liboqs_speed",
        "peekOfCode": "args = parser.parse_args()\nfn = args.logfile\nalg = args.algorithm\nstate = State.starting\nconfig = ''\nwith open(fn) as fp: \n   while True:\n      line = fp.readline() \n      if not line: \n         break ",
        "detail": "liboqs.scripts.parse_liboqs_speed",
        "documentation": {}
    },
    {
        "label": "fn",
        "kind": 5,
        "importPath": "liboqs.scripts.parse_liboqs_speed",
        "description": "liboqs.scripts.parse_liboqs_speed",
        "peekOfCode": "fn = args.logfile\nalg = args.algorithm\nstate = State.starting\nconfig = ''\nwith open(fn) as fp: \n   while True:\n      line = fp.readline() \n      if not line: \n         break \n      # Remove newlines",
        "detail": "liboqs.scripts.parse_liboqs_speed",
        "documentation": {}
    },
    {
        "label": "alg",
        "kind": 5,
        "importPath": "liboqs.scripts.parse_liboqs_speed",
        "description": "liboqs.scripts.parse_liboqs_speed",
        "peekOfCode": "alg = args.algorithm\nstate = State.starting\nconfig = ''\nwith open(fn) as fp: \n   while True:\n      line = fp.readline() \n      if not line: \n         break \n      # Remove newlines\n      line = line.rstrip()",
        "detail": "liboqs.scripts.parse_liboqs_speed",
        "documentation": {}
    },
    {
        "label": "state",
        "kind": 5,
        "importPath": "liboqs.scripts.parse_liboqs_speed",
        "description": "liboqs.scripts.parse_liboqs_speed",
        "peekOfCode": "state = State.starting\nconfig = ''\nwith open(fn) as fp: \n   while True:\n      line = fp.readline() \n      if not line: \n         break \n      # Remove newlines\n      line = line.rstrip()\n      if state==State.starting:",
        "detail": "liboqs.scripts.parse_liboqs_speed",
        "documentation": {}
    },
    {
        "label": "config",
        "kind": 5,
        "importPath": "liboqs.scripts.parse_liboqs_speed",
        "description": "liboqs.scripts.parse_liboqs_speed",
        "peekOfCode": "config = ''\nwith open(fn) as fp: \n   while True:\n      line = fp.readline() \n      if not line: \n         break \n      # Remove newlines\n      line = line.rstrip()\n      if state==State.starting:\n         if line.startswith(\"Configuration info\"):",
        "detail": "liboqs.scripts.parse_liboqs_speed",
        "documentation": {}
    },
    {
        "label": "output_file",
        "kind": 5,
        "importPath": "liboqs.scripts.parse_liboqs_speed",
        "description": "liboqs.scripts.parse_liboqs_speed",
        "peekOfCode": "output_file = f\"{alg}_formatted.json\"\nwith open(output_file, 'w') as outfile:\n    json.dump(data, outfile)",
        "detail": "liboqs.scripts.parse_liboqs_speed",
        "documentation": {}
    },
    {
        "label": "load_yaml",
        "kind": 2,
        "importPath": "liboqs.scripts.update_cbom",
        "description": "liboqs.scripts.update_cbom",
        "peekOfCode": "def load_yaml(filename, encoding='utf-8'):\n    with open(filename, mode='r', encoding=encoding) as fh:\n        return yaml.safe_load(fh.read())\ndef file_get_contents(filename, encoding=None):\n    with open(filename, mode='r', encoding=encoding) as fh:\n        return fh.read()\ndef out_write(out, str):\n    out.write(str)\nkem_yamls = []\nsig_yamls = []",
        "detail": "liboqs.scripts.update_cbom",
        "documentation": {}
    },
    {
        "label": "file_get_contents",
        "kind": 2,
        "importPath": "liboqs.scripts.update_cbom",
        "description": "liboqs.scripts.update_cbom",
        "peekOfCode": "def file_get_contents(filename, encoding=None):\n    with open(filename, mode='r', encoding=encoding) as fh:\n        return fh.read()\ndef out_write(out, str):\n    out.write(str)\nkem_yamls = []\nsig_yamls = []\ncbom_components = []\nbom_algs_bomrefs = []\nbom_algs_use_dependencies = {}",
        "detail": "liboqs.scripts.update_cbom",
        "documentation": {}
    },
    {
        "label": "out_write",
        "kind": 2,
        "importPath": "liboqs.scripts.update_cbom",
        "description": "liboqs.scripts.update_cbom",
        "peekOfCode": "def out_write(out, str):\n    out.write(str)\nkem_yamls = []\nsig_yamls = []\ncbom_components = []\nbom_algs_bomrefs = []\nbom_algs_use_dependencies = {}\n## Common crypto components: aes, sha3\ncommon_crypto_component_aes = {\n      \"type\": \"cryptographic-asset\",",
        "detail": "liboqs.scripts.update_cbom",
        "documentation": {}
    },
    {
        "label": "add_cbom_component",
        "kind": 2,
        "importPath": "liboqs.scripts.update_cbom",
        "description": "liboqs.scripts.update_cbom",
        "peekOfCode": "def add_cbom_component(out, kem_yaml, parameter_set):\n    primitive = kem_yaml['type']\n    component = {}\n    component['type'] = \"cryptographic-asset\"\n    component['bom-ref'] = \"alg:\" + parameter_set['name']\n    component['name'] = kem_yaml['name']\n    algorithmProperties = {}\n    algorithmProperties['parameterSetIdentifier'] = parameter_set['name']\n    algorithmProperties['primitive'] = primitive\n    algorithmProperties['executionEnvironment'] = \"software-plain-ram\"",
        "detail": "liboqs.scripts.update_cbom",
        "documentation": {}
    },
    {
        "label": "build_cbom",
        "kind": 2,
        "importPath": "liboqs.scripts.update_cbom",
        "description": "liboqs.scripts.update_cbom",
        "peekOfCode": "def build_cbom(liboqs_root, liboqs_version):\n    ## Add KEM components\n    for kem_yaml_path in sorted(glob.glob(os.path.join(liboqs_root, 'docs', 'algorithms', 'kem', '*.yml'))):\n        kem_yaml = load_yaml(kem_yaml_path)\n        kem_yamls.append(kem_yaml)\n        kem_name = os.path.splitext(os.path.basename(kem_yaml_path))[0]\n        name = kem_yaml['name']\n        for parameter_set in kem_yaml['parameter-sets']:\n            add_cbom_component(None, kem_yaml, parameter_set)\n    ## Add Sig components",
        "detail": "liboqs.scripts.update_cbom",
        "documentation": {}
    },
    {
        "label": "algorithms_changed",
        "kind": 2,
        "importPath": "liboqs.scripts.update_cbom",
        "description": "liboqs.scripts.update_cbom",
        "peekOfCode": "def algorithms_changed(cbom, cbom_path):\n    if os.path.isfile(cbom_path):\n        with open(cbom_path, mode='r', encoding='utf-8') as c:\n            existing_cbom = json.load(c)\n            existing_cbom['serialNumber'] = cbom['serialNumber']\n            existing_cbom['metadata']['timestamp'] = cbom['metadata']['timestamp']\n            existing_cbom['metadata']['component']['bom-ref'] = cbom['metadata']['component']['bom-ref']\n            existing_cbom['metadata']['component']['version'] = cbom['metadata']['component']['version']\n            existing_cbom['components'][0]['bom-ref'] = cbom['components'][0]['bom-ref']\n            existing_cbom['components'][0]['version'] = cbom['components'][0]['version']",
        "detail": "liboqs.scripts.update_cbom",
        "documentation": {}
    },
    {
        "label": "update_cbom_if_algs_not_changed",
        "kind": 2,
        "importPath": "liboqs.scripts.update_cbom",
        "description": "liboqs.scripts.update_cbom",
        "peekOfCode": "def update_cbom_if_algs_not_changed(liboqs_root, liboqs_version):\n    cbom_path = os.path.join(liboqs_root, 'docs', cbom_json_file)\n    cbom = build_cbom(liboqs_root, liboqs_version)\n    if algorithms_changed(cbom, cbom_path):\n        with open(cbom_path, mode='w', encoding='utf-8') as out_md:\n            out_md.write(json.dumps(cbom, indent=2))\n            out_md.close()\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--liboqs-root\", default=\".\")",
        "detail": "liboqs.scripts.update_cbom",
        "documentation": {}
    },
    {
        "label": "cbom_json_file",
        "kind": 5,
        "importPath": "liboqs.scripts.update_cbom",
        "description": "liboqs.scripts.update_cbom",
        "peekOfCode": "cbom_json_file = \"cbom.json\"\ndef load_yaml(filename, encoding='utf-8'):\n    with open(filename, mode='r', encoding=encoding) as fh:\n        return yaml.safe_load(fh.read())\ndef file_get_contents(filename, encoding=None):\n    with open(filename, mode='r', encoding=encoding) as fh:\n        return fh.read()\ndef out_write(out, str):\n    out.write(str)\nkem_yamls = []",
        "detail": "liboqs.scripts.update_cbom",
        "documentation": {}
    },
    {
        "label": "kem_yamls",
        "kind": 5,
        "importPath": "liboqs.scripts.update_cbom",
        "description": "liboqs.scripts.update_cbom",
        "peekOfCode": "kem_yamls = []\nsig_yamls = []\ncbom_components = []\nbom_algs_bomrefs = []\nbom_algs_use_dependencies = {}\n## Common crypto components: aes, sha3\ncommon_crypto_component_aes = {\n      \"type\": \"cryptographic-asset\",\n      \"bom-ref\": \"alg:aes\",\n      \"name\": \"aes\",",
        "detail": "liboqs.scripts.update_cbom",
        "documentation": {}
    },
    {
        "label": "sig_yamls",
        "kind": 5,
        "importPath": "liboqs.scripts.update_cbom",
        "description": "liboqs.scripts.update_cbom",
        "peekOfCode": "sig_yamls = []\ncbom_components = []\nbom_algs_bomrefs = []\nbom_algs_use_dependencies = {}\n## Common crypto components: aes, sha3\ncommon_crypto_component_aes = {\n      \"type\": \"cryptographic-asset\",\n      \"bom-ref\": \"alg:aes\",\n      \"name\": \"aes\",\n      \"cryptoProperties\": {",
        "detail": "liboqs.scripts.update_cbom",
        "documentation": {}
    },
    {
        "label": "cbom_components",
        "kind": 5,
        "importPath": "liboqs.scripts.update_cbom",
        "description": "liboqs.scripts.update_cbom",
        "peekOfCode": "cbom_components = []\nbom_algs_bomrefs = []\nbom_algs_use_dependencies = {}\n## Common crypto components: aes, sha3\ncommon_crypto_component_aes = {\n      \"type\": \"cryptographic-asset\",\n      \"bom-ref\": \"alg:aes\",\n      \"name\": \"aes\",\n      \"cryptoProperties\": {\n        \"assetType\": \"algorithm\",",
        "detail": "liboqs.scripts.update_cbom",
        "documentation": {}
    },
    {
        "label": "bom_algs_bomrefs",
        "kind": 5,
        "importPath": "liboqs.scripts.update_cbom",
        "description": "liboqs.scripts.update_cbom",
        "peekOfCode": "bom_algs_bomrefs = []\nbom_algs_use_dependencies = {}\n## Common crypto components: aes, sha3\ncommon_crypto_component_aes = {\n      \"type\": \"cryptographic-asset\",\n      \"bom-ref\": \"alg:aes\",\n      \"name\": \"aes\",\n      \"cryptoProperties\": {\n        \"assetType\": \"algorithm\",\n        \"algorithmProperties\": {",
        "detail": "liboqs.scripts.update_cbom",
        "documentation": {}
    },
    {
        "label": "bom_algs_use_dependencies",
        "kind": 5,
        "importPath": "liboqs.scripts.update_cbom",
        "description": "liboqs.scripts.update_cbom",
        "peekOfCode": "bom_algs_use_dependencies = {}\n## Common crypto components: aes, sha3\ncommon_crypto_component_aes = {\n      \"type\": \"cryptographic-asset\",\n      \"bom-ref\": \"alg:aes\",\n      \"name\": \"aes\",\n      \"cryptoProperties\": {\n        \"assetType\": \"algorithm\",\n        \"algorithmProperties\": {\n          \"primitive\": \"block-cipher\",",
        "detail": "liboqs.scripts.update_cbom",
        "documentation": {}
    },
    {
        "label": "common_crypto_component_aes",
        "kind": 5,
        "importPath": "liboqs.scripts.update_cbom",
        "description": "liboqs.scripts.update_cbom",
        "peekOfCode": "common_crypto_component_aes = {\n      \"type\": \"cryptographic-asset\",\n      \"bom-ref\": \"alg:aes\",\n      \"name\": \"aes\",\n      \"cryptoProperties\": {\n        \"assetType\": \"algorithm\",\n        \"algorithmProperties\": {\n          \"primitive\": \"block-cipher\",\n          \"executionEnvironment\": \"software-plain-ram\"\n        }",
        "detail": "liboqs.scripts.update_cbom",
        "documentation": {}
    },
    {
        "label": "common_crypto_component_sha3",
        "kind": 5,
        "importPath": "liboqs.scripts.update_cbom",
        "description": "liboqs.scripts.update_cbom",
        "peekOfCode": "common_crypto_component_sha3 = {\n      \"type\": \"cryptographic-asset\",\n      \"bom-ref\": \"alg:sha3\",\n      \"name\": \"sha3\",\n      \"cryptoProperties\": {\n        \"assetType\": \"algorithm\",\n        \"algorithmProperties\": {\n          \"primitive\": \"hash\",\n          \"executionEnvironment\": \"software-plain-ram\"\n        }",
        "detail": "liboqs.scripts.update_cbom",
        "documentation": {}
    },
    {
        "label": "load_yaml",
        "kind": 2,
        "importPath": "liboqs.scripts.update_docs_from_yaml",
        "description": "liboqs.scripts.update_docs_from_yaml",
        "peekOfCode": "def load_yaml(filename, encoding='utf-8'):\n    with open(filename, mode='r', encoding=encoding) as fh:\n        return yaml.safe_load(fh.read())\ndef file_get_contents(filename, encoding=None):\n    with open(filename, mode='r', encoding=encoding) as fh:\n        return fh.read()\nkem_yamls = []\nsig_yamls = []\nsig_stfl_yamls = []\n########################################",
        "detail": "liboqs.scripts.update_docs_from_yaml",
        "documentation": {}
    },
    {
        "label": "file_get_contents",
        "kind": 2,
        "importPath": "liboqs.scripts.update_docs_from_yaml",
        "description": "liboqs.scripts.update_docs_from_yaml",
        "peekOfCode": "def file_get_contents(filename, encoding=None):\n    with open(filename, mode='r', encoding=encoding) as fh:\n        return fh.read()\nkem_yamls = []\nsig_yamls = []\nsig_stfl_yamls = []\n########################################\n# Update the KEM markdown documentation.\n########################################\ndef do_it(liboqs_root):",
        "detail": "liboqs.scripts.update_docs_from_yaml",
        "documentation": {}
    },
    {
        "label": "do_it",
        "kind": 2,
        "importPath": "liboqs.scripts.update_docs_from_yaml",
        "description": "liboqs.scripts.update_docs_from_yaml",
        "peekOfCode": "def do_it(liboqs_root):\n    for kem_yaml_path in sorted(glob.glob(os.path.join(liboqs_root, 'docs', 'algorithms', 'kem', '*.yml'))):\n        kem_yaml = load_yaml(kem_yaml_path)\n        kem_yamls.append(kem_yaml)\n        kem_name = os.path.splitext(os.path.basename(kem_yaml_path))[0]\n        print('Updating {}/{}.md'.format(os.path.dirname(kem_yaml_path), kem_name))\n        with open(os.path.join(liboqs_root, 'docs', 'algorithms', 'kem', '{}.md'.format(kem_name)), mode='w', encoding='utf-8') as out_md:\n            out_md.write('# {}\\n\\n'.format(kem_yaml['name']))\n            out_md.write('- **Algorithm type**: Key encapsulation mechanism.\\n')\n            out_md.write('- **Main cryptographic assumption**: {}.\\n'.format(kem_yaml['crypto-assumption']))",
        "detail": "liboqs.scripts.update_docs_from_yaml",
        "documentation": {}
    },
    {
        "label": "kem_yamls",
        "kind": 5,
        "importPath": "liboqs.scripts.update_docs_from_yaml",
        "description": "liboqs.scripts.update_docs_from_yaml",
        "peekOfCode": "kem_yamls = []\nsig_yamls = []\nsig_stfl_yamls = []\n########################################\n# Update the KEM markdown documentation.\n########################################\ndef do_it(liboqs_root):\n    for kem_yaml_path in sorted(glob.glob(os.path.join(liboqs_root, 'docs', 'algorithms', 'kem', '*.yml'))):\n        kem_yaml = load_yaml(kem_yaml_path)\n        kem_yamls.append(kem_yaml)",
        "detail": "liboqs.scripts.update_docs_from_yaml",
        "documentation": {}
    },
    {
        "label": "sig_yamls",
        "kind": 5,
        "importPath": "liboqs.scripts.update_docs_from_yaml",
        "description": "liboqs.scripts.update_docs_from_yaml",
        "peekOfCode": "sig_yamls = []\nsig_stfl_yamls = []\n########################################\n# Update the KEM markdown documentation.\n########################################\ndef do_it(liboqs_root):\n    for kem_yaml_path in sorted(glob.glob(os.path.join(liboqs_root, 'docs', 'algorithms', 'kem', '*.yml'))):\n        kem_yaml = load_yaml(kem_yaml_path)\n        kem_yamls.append(kem_yaml)\n        kem_name = os.path.splitext(os.path.basename(kem_yaml_path))[0]",
        "detail": "liboqs.scripts.update_docs_from_yaml",
        "documentation": {}
    },
    {
        "label": "sig_stfl_yamls",
        "kind": 5,
        "importPath": "liboqs.scripts.update_docs_from_yaml",
        "description": "liboqs.scripts.update_docs_from_yaml",
        "peekOfCode": "sig_stfl_yamls = []\n########################################\n# Update the KEM markdown documentation.\n########################################\ndef do_it(liboqs_root):\n    for kem_yaml_path in sorted(glob.glob(os.path.join(liboqs_root, 'docs', 'algorithms', 'kem', '*.yml'))):\n        kem_yaml = load_yaml(kem_yaml_path)\n        kem_yamls.append(kem_yaml)\n        kem_name = os.path.splitext(os.path.basename(kem_yaml_path))[0]\n        print('Updating {}/{}.md'.format(os.path.dirname(kem_yaml_path), kem_name))",
        "detail": "liboqs.scripts.update_docs_from_yaml",
        "documentation": {}
    },
    {
        "label": "run_subprocess",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def run_subprocess(command, working_dir='.', env=None, expected_returncode=0, input=None, ignore_returncode=False):\n    \"\"\"\n    Helper function to run a shell command and report success/failure\n    depending on the exit status of the shell command.\n    \"\"\"\n    env_ = os.environ.copy()\n    if env is not None:\n        env_.update(env)\n    env = env_\n    # Note we need to capture stdout/stderr from the subprocess,",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "available_kems_by_name",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def available_kems_by_name():\n    available_names = []\n    with open(os.path.join('src', 'kem', 'kem.h')) as fh:\n        for line in fh:\n            if line.startswith(\"#define OQS_KEM_alg_\"):\n                kem_name = line.split(' ')[2]\n                kem_name = kem_name[1:-2]\n                available_names.append(kem_name)\n    return available_names\ndef is_kem_enabled_by_name(name):",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "is_kem_enabled_by_name",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def is_kem_enabled_by_name(name):\n    symbol = None\n    with open(os.path.join('src', 'kem', 'kem.h')) as fh:\n        for line in fh:\n            if line.startswith(\"#define OQS_KEM_alg_\"):\n                kem_symbol = line.split(' ')[1]\n                kem_symbol = kem_symbol[len(\"OQS_KEM_alg_\"):]\n                kem_name = line.split(' ')[2]\n                kem_name = kem_name[1:-2]\n                if kem_name == name:",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "available_sigs_by_name",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def available_sigs_by_name():\n    available_names = []\n    with open(os.path.join('src', 'sig', 'sig.h')) as fh:\n        for line in fh:\n            if line.startswith(\"#define OQS_SIG_alg_\"):\n                sig_name = line.split(' ')[2]\n                sig_name = sig_name[1:-2]\n                available_names.append(sig_name)\n    return available_names\ndef is_sig_enabled_by_name(name):",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "is_sig_enabled_by_name",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def is_sig_enabled_by_name(name):\n    symbol = None\n    with open(os.path.join('src', 'sig', 'sig.h')) as fh:\n        for line in fh:\n            if line.startswith(\"#define OQS_SIG_alg_\"):\n                sig_symbol = line.split(' ')[1]\n                sig_symbol = sig_symbol[len(\"OQS_SIG_alg_\"):]\n                sig_name = line.split(' ')[2]\n                sig_name = sig_name[1:-2]\n                if sig_name == name:",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "available_sig_stfls_by_name",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def available_sig_stfls_by_name():\n    available_names = []\n    with open(os.path.join('src', 'sig_stfl', 'sig_stfl.h')) as fh:\n        for line in fh:\n            if line.startswith(\"#define OQS_SIG_STFL_alg_\"):\n                sig_stfl_name = line.split(' ')[2].strip()\n                sig_stfl_name = sig_stfl_name[1:-1]\n                available_names.append(sig_stfl_name)\n    return available_names\ndef is_sig_stfl_enabled_by_name(name):",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "is_sig_stfl_enabled_by_name",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def is_sig_stfl_enabled_by_name(name):\n    symbol = None\n    with open(os.path.join('src', 'sig_stfl', 'sig_stfl.h')) as fh:\n        for line in fh:\n            if line.startswith(\"#define OQS_SIG_STFL_alg_\"):\n                sig_stfl_symbol = line.split(' ')[1]\n                sig_stfl_symbol = sig_stfl_symbol[len(\"OQS_SIG_STFL_alg_\"):]\n                sig_stfl_name = line.split(' ')[2].strip()\n                sig_stfl_name = sig_stfl_name[1:-1]\n                if sig_stfl_name == name:",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "filtered_test",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def filtered_test(func):\n    funcname = func.__name__[len(\"test_\"):]\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        if ('SKIP_ALGS' in os.environ) and len(os.environ['SKIP_ALGS'])>0:\n            for algexp in os.environ['SKIP_ALGS'].split(','):\n                for arg in args:\n                    if len(re.findall(algexp, arg))>0:\n                        pytest.skip(\"Test disabled by alg filter\")\n                for arg in kwargs:",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "get_current_build_dir_name",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def get_current_build_dir_name():\n    if 'OQS_BUILD_DIR' in os.environ:\n        return os.environ['OQS_BUILD_DIR']\n    return 'build'\ndef path_to_executable(program_name):\n    path = \".\"\n    path = os.path.join(path, get_current_build_dir_name(), \"tests\")\n    for executable in [\n        os.path.join(path, program_name),\n        os.path.join(path, program_name + \".EXE\"),",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "path_to_executable",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def path_to_executable(program_name):\n    path = \".\"\n    path = os.path.join(path, get_current_build_dir_name(), \"tests\")\n    for executable in [\n        os.path.join(path, program_name),\n        os.path.join(path, program_name + \".EXE\"),\n        os.path.join(path, program_name + \".exe\"),\n        os.path.join(path, \"Debug\", program_name + \".exe\"),]:\n            if os.path.isfile(executable):\n                return executable",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "available_use_options_by_name",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def available_use_options_by_name():\n    enabled_use_options = []\n    with open(os.path.join(get_current_build_dir_name(), 'include', 'oqs', 'oqsconfig.h')) as fh:\n        for line in fh:\n            if line.startswith(\"#define OQS_USE_\"):\n                option_name = line.split(' ')[1][len(\"OQS_USE_\"):].strip('\\n')\n                enabled_use_options.append(option_name)\n    return enabled_use_options\ndef is_use_option_enabled_by_name(name):\n    return name in available_use_options_by_name()",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "is_use_option_enabled_by_name",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def is_use_option_enabled_by_name(name):\n    return name in available_use_options_by_name()\ndef get_kats(t):\n    if kats[t] is None:\n        with open(os.path.join('tests', 'KATs', t, 'kats.json'), 'r') as fp:\n            kats[t] = json.load(fp)\n    return kats[t]\ndef get_katfile(t: str, sig_stfl_name: str) -> str:\n    algo_dir = ''\n    if \"XMSS\" in sig_stfl_name:",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "get_kats",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def get_kats(t):\n    if kats[t] is None:\n        with open(os.path.join('tests', 'KATs', t, 'kats.json'), 'r') as fp:\n            kats[t] = json.load(fp)\n    return kats[t]\ndef get_katfile(t: str, sig_stfl_name: str) -> str:\n    algo_dir = ''\n    if \"XMSS\" in sig_stfl_name:\n        algo_dir = 'xmss'\n    if \"LMS\" in sig_stfl_name:",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "get_katfile",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def get_katfile(t: str, sig_stfl_name: str) -> str:\n    algo_dir = ''\n    if \"XMSS\" in sig_stfl_name:\n        algo_dir = 'xmss'\n    if \"LMS\" in sig_stfl_name:\n        algo_dir = 'lms'\n    if algo_dir == '':\n        return ''\n    # Replace the \"/\" to \"-\" in XMSSMT parameters\n    clean_sig_stfl_name = sig_stfl_name.replace(\"/\", \"-\", 1)",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "get_valgrind_version",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def get_valgrind_version():\n    try:\n        version = run_subprocess(['valgrind', '--version'])\n        x,y,z = map(int, version.replace('valgrind-','').split('.'))\n    except:\n        x,y,z = 0,0,0\n    return x, y, z\ndef test_requires_valgrind_version_at_least(x,y,z):\n    (X,Y,Z) = get_valgrind_version()\n    return pytest.mark.skipif((X < x) or (X == x and Y < y) or (X == x and Y == y and Z < z),",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "test_requires_valgrind_version_at_least",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def test_requires_valgrind_version_at_least(x,y,z):\n    (X,Y,Z) = get_valgrind_version()\n    return pytest.mark.skipif((X < x) or (X == x and Y < y) or (X == x and Y == y and Z < z),\n                reason='Test requires Valgrind >= {}.{}.{}'.format(x,y,z))\n@functools.lru_cache()\ndef test_requires_build_options(*options):\n    enabled = {opt : False for opt in options}\n    with open(os.path.join(get_current_build_dir_name(), 'include', 'oqs', 'oqsconfig.h')) as fh:\n        for line in fh:\n            opt = line.split(' ')[1] if line.startswith('#define ') else None",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "test_requires_build_options",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def test_requires_build_options(*options):\n    enabled = {opt : False for opt in options}\n    with open(os.path.join(get_current_build_dir_name(), 'include', 'oqs', 'oqsconfig.h')) as fh:\n        for line in fh:\n            opt = line.split(' ')[1] if line.startswith('#define ') else None\n            if opt in options:\n                enabled[opt] = True\n    missing = ', '.join([opt for opt in options if not enabled[opt]])\n    return pytest.mark.skipif(not all(enabled.values()),\n                reason='Test requires missing build options {}'.format(missing))",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "test_requires_qemu",
        "kind": 2,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "def test_requires_qemu(platform, mincpu):\n    no_qemu=False\n    try:\n        run_subprocess([\"qemu-\"+platform+\"-static\", \"-cpu\", mincpu, path_to_executable('test_kem')], ignore_returncode=True)\n    except:\n        no_qemu=True\n    return pytest.mark.skipif(no_qemu,\n                reason='Test requires qemu-{}-static -cpu {}'.format(platform, mincpu))",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "kats",
        "kind": 5,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "kats = {}\nkats[\"kem\"] = None\nkats[\"sig\"] = None\nkats[\"sig_stfl\"] = None\ndef run_subprocess(command, working_dir='.', env=None, expected_returncode=0, input=None, ignore_returncode=False):\n    \"\"\"\n    Helper function to run a shell command and report success/failure\n    depending on the exit status of the shell command.\n    \"\"\"\n    env_ = os.environ.copy()",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "kats[\"kem\"]",
        "kind": 5,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "kats[\"kem\"] = None\nkats[\"sig\"] = None\nkats[\"sig_stfl\"] = None\ndef run_subprocess(command, working_dir='.', env=None, expected_returncode=0, input=None, ignore_returncode=False):\n    \"\"\"\n    Helper function to run a shell command and report success/failure\n    depending on the exit status of the shell command.\n    \"\"\"\n    env_ = os.environ.copy()\n    if env is not None:",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "kats[\"sig\"]",
        "kind": 5,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "kats[\"sig\"] = None\nkats[\"sig_stfl\"] = None\ndef run_subprocess(command, working_dir='.', env=None, expected_returncode=0, input=None, ignore_returncode=False):\n    \"\"\"\n    Helper function to run a shell command and report success/failure\n    depending on the exit status of the shell command.\n    \"\"\"\n    env_ = os.environ.copy()\n    if env is not None:\n        env_.update(env)",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "kats[\"sig_stfl\"]",
        "kind": 5,
        "importPath": "liboqs.tests.helpers",
        "description": "liboqs.tests.helpers",
        "peekOfCode": "kats[\"sig_stfl\"] = None\ndef run_subprocess(command, working_dir='.', env=None, expected_returncode=0, input=None, ignore_returncode=False):\n    \"\"\"\n    Helper function to run a shell command and report success/failure\n    depending on the exit status of the shell command.\n    \"\"\"\n    env_ = os.environ.copy()\n    if env is not None:\n        env_.update(env)\n    env = env_",
        "detail": "liboqs.tests.helpers",
        "documentation": {}
    },
    {
        "label": "test_acvp_vec_kem_keygen",
        "kind": 2,
        "importPath": "liboqs.tests.test_acvp_vectors",
        "description": "liboqs.tests.test_acvp_vectors",
        "peekOfCode": "def test_acvp_vec_kem_keygen(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    if not(kem_name in fips_kem): pytest.skip(\"Not supported\")\n    with open(os.path.join('tests', ml_kem_kg), 'r') as fp:\n        ml_kem_kg_acvp  = json.load(fp)\n        variantFound = False\n        for variant in ml_kem_kg_acvp[\"testGroups\"]:\n            if variant[\"parameterSet\"] == kem_name:\n                variantFound = True\n                for testCase in variant[\"tests\"]:",
        "detail": "liboqs.tests.test_acvp_vectors",
        "documentation": {}
    },
    {
        "label": "test_acvp_vec_kem_encdec_aft",
        "kind": 2,
        "importPath": "liboqs.tests.test_acvp_vectors",
        "description": "liboqs.tests.test_acvp_vectors",
        "peekOfCode": "def test_acvp_vec_kem_encdec_aft(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    if not(kem_name in fips_kem): pytest.skip(\"Not supported\")\n    with open(os.path.join('tests', ml_kem_encdec), 'r') as fp:\n        ml_kem_encdec_acvp  = json.load(fp)\n        variantFound = False\n        for variant in ml_kem_encdec_acvp[\"testGroups\"]:\n            if variant[\"parameterSet\"] == kem_name and variant[\"testType\"] == \"AFT\":\n                variantFound = True\n                for testCase in variant[\"tests\"]:",
        "detail": "liboqs.tests.test_acvp_vectors",
        "documentation": {}
    },
    {
        "label": "test_acvp_vec_kem_encdec_val",
        "kind": 2,
        "importPath": "liboqs.tests.test_acvp_vectors",
        "description": "liboqs.tests.test_acvp_vectors",
        "peekOfCode": "def test_acvp_vec_kem_encdec_val(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    if not(kem_name in fips_kem): pytest.skip(\"Not supported\")\n    with open(os.path.join('tests', ml_kem_encdec), 'r') as fp:\n        ml_kem_encdec_acvp  = json.load(fp)\n        variantFound = False\n        for variant in ml_kem_encdec_acvp[\"testGroups\"]:\n            if variant[\"parameterSet\"] == kem_name and variant[\"testType\"] == \"VAL\":\n                variantFound = True\n                sk = variant[\"dk\"]",
        "detail": "liboqs.tests.test_acvp_vectors",
        "documentation": {}
    },
    {
        "label": "test_acvp_vec_sig_keygen",
        "kind": 2,
        "importPath": "liboqs.tests.test_acvp_vectors",
        "description": "liboqs.tests.test_acvp_vectors",
        "peekOfCode": "def test_acvp_vec_sig_keygen(sig_name):\n    if not(helpers.is_sig_enabled_by_name(sig_name)): pytest.skip('Not enabled')\n    if not(sig_name in fips_sig): pytest.skip(\"Not supported\")\n    with open(os.path.join('tests', ml_dsa_kg), 'r') as fp:\n        ml_sig_kg_acvp  = json.load(fp)\n        variantFound = False\n        for variant in ml_sig_kg_acvp[\"testGroups\"]:\n            if variant[\"parameterSet\"] == sig_name:\n                variantFound = True\n                for testCase in variant[\"tests\"]:",
        "detail": "liboqs.tests.test_acvp_vectors",
        "documentation": {}
    },
    {
        "label": "test_acvp_vec_sig_gen",
        "kind": 2,
        "importPath": "liboqs.tests.test_acvp_vectors",
        "description": "liboqs.tests.test_acvp_vectors",
        "peekOfCode": "def test_acvp_vec_sig_gen(sig_name):\n    if not(helpers.is_sig_enabled_by_name(sig_name)): pytest.skip('Not enabled')\n    if not(sig_name in fips_sig): pytest.skip(\"Not supported\")\n    with open(os.path.join('tests', ml_dsa_sig), 'r') as fp:\n        ml_sig_sig_acvp  = json.load(fp)\n        variantFound = False\n        for variant in ml_sig_sig_acvp[\"testGroups\"]:\n            # perform only below tests ATM:\n            # 1. internal API with externalMu as false\n            # 2. external API with \"pure\" implementation",
        "detail": "liboqs.tests.test_acvp_vectors",
        "documentation": {}
    },
    {
        "label": "test_acvp_vec_sig_ver",
        "kind": 2,
        "importPath": "liboqs.tests.test_acvp_vectors",
        "description": "liboqs.tests.test_acvp_vectors",
        "peekOfCode": "def test_acvp_vec_sig_ver(sig_name):\n    if not(helpers.is_sig_enabled_by_name(sig_name)): pytest.skip('Not enabled')\n    if not(sig_name in fips_sig): pytest.skip(\"Not supported\")\n    with open(os.path.join('tests', ml_dsa_ver), 'r') as fp:\n        ml_sig_sig_acvp  = json.load(fp)\n        variantFound = False\n        for variant in ml_sig_sig_acvp[\"testGroups\"]:\n            # perform only below tests ATM:\n            # 1. internal API with externalMu as false\n            # 2. external API with \"pure\" implementation",
        "detail": "liboqs.tests.test_acvp_vectors",
        "documentation": {}
    },
    {
        "label": "fips_kem",
        "kind": 5,
        "importPath": "liboqs.tests.test_acvp_vectors",
        "description": "liboqs.tests.test_acvp_vectors",
        "peekOfCode": "fips_kem = [\"ML-KEM-512\", \"ML-KEM-768\", \"ML-KEM-1024\"]\nfips_sig = [\"ML-DSA-44\", \"ML-DSA-65\", \"ML-DSA-87\"]\nml_kem_encdec = \"ACVP_Vectors/ML-KEM-encapDecap-FIPS203/internalProjection.json\"\nml_kem_kg     = \"ACVP_Vectors/ML-KEM-keyGen-FIPS203/internalProjection.json\"\nml_dsa_kg     = \"ACVP_Vectors/ML-DSA-keyGen-FIPS204/internalProjection.json\"\nml_dsa_sig    = \"ACVP_Vectors/ML-DSA-sigGen-FIPS204/internalProjection.json\"\nml_dsa_ver    = \"ACVP_Vectors/ML-DSA-sigVer-FIPS204/internalProjection.json\"\n@helpers.filtered_test\n@pytest.mark.parametrize('kem_name', helpers.available_kems_by_name())\ndef test_acvp_vec_kem_keygen(kem_name):",
        "detail": "liboqs.tests.test_acvp_vectors",
        "documentation": {}
    },
    {
        "label": "fips_sig",
        "kind": 5,
        "importPath": "liboqs.tests.test_acvp_vectors",
        "description": "liboqs.tests.test_acvp_vectors",
        "peekOfCode": "fips_sig = [\"ML-DSA-44\", \"ML-DSA-65\", \"ML-DSA-87\"]\nml_kem_encdec = \"ACVP_Vectors/ML-KEM-encapDecap-FIPS203/internalProjection.json\"\nml_kem_kg     = \"ACVP_Vectors/ML-KEM-keyGen-FIPS203/internalProjection.json\"\nml_dsa_kg     = \"ACVP_Vectors/ML-DSA-keyGen-FIPS204/internalProjection.json\"\nml_dsa_sig    = \"ACVP_Vectors/ML-DSA-sigGen-FIPS204/internalProjection.json\"\nml_dsa_ver    = \"ACVP_Vectors/ML-DSA-sigVer-FIPS204/internalProjection.json\"\n@helpers.filtered_test\n@pytest.mark.parametrize('kem_name', helpers.available_kems_by_name())\ndef test_acvp_vec_kem_keygen(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')",
        "detail": "liboqs.tests.test_acvp_vectors",
        "documentation": {}
    },
    {
        "label": "ml_kem_encdec",
        "kind": 5,
        "importPath": "liboqs.tests.test_acvp_vectors",
        "description": "liboqs.tests.test_acvp_vectors",
        "peekOfCode": "ml_kem_encdec = \"ACVP_Vectors/ML-KEM-encapDecap-FIPS203/internalProjection.json\"\nml_kem_kg     = \"ACVP_Vectors/ML-KEM-keyGen-FIPS203/internalProjection.json\"\nml_dsa_kg     = \"ACVP_Vectors/ML-DSA-keyGen-FIPS204/internalProjection.json\"\nml_dsa_sig    = \"ACVP_Vectors/ML-DSA-sigGen-FIPS204/internalProjection.json\"\nml_dsa_ver    = \"ACVP_Vectors/ML-DSA-sigVer-FIPS204/internalProjection.json\"\n@helpers.filtered_test\n@pytest.mark.parametrize('kem_name', helpers.available_kems_by_name())\ndef test_acvp_vec_kem_keygen(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    if not(kem_name in fips_kem): pytest.skip(\"Not supported\")",
        "detail": "liboqs.tests.test_acvp_vectors",
        "documentation": {}
    },
    {
        "label": "test_alg_info_kem",
        "kind": 2,
        "importPath": "liboqs.tests.test_alg_info",
        "description": "liboqs.tests.test_alg_info",
        "peekOfCode": "def test_alg_info_kem(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    # get the algorithm info from liboqs\n    output = helpers.run_subprocess([helpers.path_to_executable('dump_alg_info')])\n    alg_info = yaml.safe_load(output)['KEMs'][kem_name]\n    assert(not(alg_info['isnull']))\n    # find and load the datasheet\n    if platform.system() == 'Windows':\n        command = f\"Select-String -Path 'docs/algorithms/kem/*' -Pattern '{kem_name}' -SimpleMatch -List | Select-Object -ExpandProperty Path\"\n        datasheet_filename = helpers.run_subprocess(['powershell', '-Command', command]).splitlines()[0]",
        "detail": "liboqs.tests.test_alg_info",
        "documentation": {}
    },
    {
        "label": "test_alg_info_sig",
        "kind": 2,
        "importPath": "liboqs.tests.test_alg_info",
        "description": "liboqs.tests.test_alg_info",
        "peekOfCode": "def test_alg_info_sig(sig_name):\n    if not(helpers.is_sig_enabled_by_name(sig_name)): pytest.skip('Not enabled')\n    # get the algorithm info from liboqs\n    output = helpers.run_subprocess([helpers.path_to_executable('dump_alg_info')])\n    alg_info = yaml.safe_load(output)['SIGs'][sig_name]\n    assert(not(alg_info['isnull']))\n    # find and load the datasheet\n    if platform.system() == 'Windows':\n        command = f\"Select-String -Path 'docs/algorithms/sig/*' -Pattern '{sig_name}' -SimpleMatch -List | Select-Object -ExpandProperty Path\"\n        datasheet_filename = helpers.run_subprocess(['powershell', '-Command', command]).splitlines()[0]",
        "detail": "liboqs.tests.test_alg_info",
        "documentation": {}
    },
    {
        "label": "test_namespace",
        "kind": 2,
        "importPath": "liboqs.tests.test_binary",
        "description": "liboqs.tests.test_binary",
        "peekOfCode": "def test_namespace():\n    liboqs = glob.glob(helpers.get_current_build_dir_name()+'/lib/liboqs.*')[0]\n    if liboqs == helpers.get_current_build_dir_name()+'/lib/liboqs.dylib':\n        out = helpers.run_subprocess(\n            ['nm', '-g', liboqs]\n        )\n    elif liboqs == helpers.get_current_build_dir_name()+'/lib/liboqs.so':\n        out = helpers.run_subprocess(\n            ['nm', '-D', liboqs]\n        )",
        "detail": "liboqs.tests.test_binary",
        "documentation": {}
    },
    {
        "label": "test_non_executable_stack",
        "kind": 2,
        "importPath": "liboqs.tests.test_binary",
        "description": "liboqs.tests.test_binary",
        "peekOfCode": "def test_non_executable_stack():\n    liboqs = helpers.get_current_build_dir_name()+'/lib/liboqs.so'\n    out = helpers.run_subprocess(\n        ['readelf', '--wide', '--segments', liboqs]\n    )\n    lines = out.strip().split(\"\\n\")\n    for line in lines:\n        if \"GNU_STACK\" in line:\n            chunks = line.strip().split()\n            flags = chunks[6]",
        "detail": "liboqs.tests.test_binary",
        "documentation": {}
    },
    {
        "label": "test_examples",
        "kind": 2,
        "importPath": "liboqs.tests.test_cmdline",
        "description": "liboqs.tests.test_cmdline",
        "peekOfCode": "def test_examples(program):\n    helpers.run_subprocess(\n        [helpers.path_to_executable(program)],\n    )\n@helpers.filtered_test\n@pytest.mark.parametrize('kem_name', helpers.available_kems_by_name())\ndef test_kem(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    helpers.run_subprocess(\n        [helpers.path_to_executable('test_kem'), kem_name],",
        "detail": "liboqs.tests.test_cmdline",
        "documentation": {}
    },
    {
        "label": "test_kem",
        "kind": 2,
        "importPath": "liboqs.tests.test_cmdline",
        "description": "liboqs.tests.test_cmdline",
        "peekOfCode": "def test_kem(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    helpers.run_subprocess(\n        [helpers.path_to_executable('test_kem'), kem_name],\n    )\n@helpers.filtered_test\n@pytest.mark.parametrize('sig_name', helpers.available_sigs_by_name())\ndef test_sig(sig_name):\n    if not(helpers.is_sig_enabled_by_name(sig_name)): pytest.skip('Not enabled')\n    helpers.run_subprocess(",
        "detail": "liboqs.tests.test_cmdline",
        "documentation": {}
    },
    {
        "label": "test_sig",
        "kind": 2,
        "importPath": "liboqs.tests.test_cmdline",
        "description": "liboqs.tests.test_cmdline",
        "peekOfCode": "def test_sig(sig_name):\n    if not(helpers.is_sig_enabled_by_name(sig_name)): pytest.skip('Not enabled')\n    helpers.run_subprocess(\n        [helpers.path_to_executable('test_sig'), sig_name],\n    )\n@helpers.filtered_test\n@pytest.mark.parametrize('sig_stfl_name', helpers.available_sig_stfls_by_name())\ndef test_sig_stfl(sig_stfl_name):\n    if not(helpers.is_sig_stfl_enabled_by_name(sig_stfl_name)): pytest.skip('Not enabled')\n    # Test with KATs apply for XMSS",
        "detail": "liboqs.tests.test_cmdline",
        "documentation": {}
    },
    {
        "label": "test_sig_stfl",
        "kind": 2,
        "importPath": "liboqs.tests.test_cmdline",
        "description": "liboqs.tests.test_cmdline",
        "peekOfCode": "def test_sig_stfl(sig_stfl_name):\n    if not(helpers.is_sig_stfl_enabled_by_name(sig_stfl_name)): pytest.skip('Not enabled')\n    # Test with KATs apply for XMSS\n    if sig_stfl_name.startswith(\"XMSS\"):\n        katfile = helpers.get_katfile(\"sig_stfl\", sig_stfl_name)\n        if not katfile: pytest.skip(\"KATs file is missing\")\n        helpers.run_subprocess(\n            [helpers.path_to_executable('test_sig_stfl'), sig_stfl_name, katfile],\n        )\n    else:",
        "detail": "liboqs.tests.test_cmdline",
        "documentation": {}
    },
    {
        "label": "test_datasheet_kem",
        "kind": 2,
        "importPath": "liboqs.tests.test_code_conventions",
        "description": "liboqs.tests.test_code_conventions",
        "peekOfCode": "def test_datasheet_kem(kem_name):\n    helpers.run_subprocess(\n        ['grep', '-r', kem_name, 'docs/algorithms']\n    )\n# Ensure every signature algorithm in the code\n# is mentioned in the documentation.\n@helpers.filtered_test\n@pytest.mark.skipif(sys.platform.startswith(\"win\"), reason=\"Not needed on Windows\")\n@pytest.mark.parametrize('sig_name', helpers.available_sigs_by_name())\ndef test_datasheet_sig(sig_name):",
        "detail": "liboqs.tests.test_code_conventions",
        "documentation": {}
    },
    {
        "label": "test_datasheet_sig",
        "kind": 2,
        "importPath": "liboqs.tests.test_code_conventions",
        "description": "liboqs.tests.test_code_conventions",
        "peekOfCode": "def test_datasheet_sig(sig_name):\n    helpers.run_subprocess(\n        ['grep', '-r', sig_name, 'docs/algorithms']\n    )\n# Ensure astyle agrees with the formatting.\n@helpers.filtered_test\n@pytest.mark.skipif(sys.platform.startswith(\"win\"), reason=\"Not needed on Windows\")\ndef test_style():\n    result = helpers.run_subprocess(\n        ['tests/run_astyle.sh']",
        "detail": "liboqs.tests.test_code_conventions",
        "documentation": {}
    },
    {
        "label": "test_style",
        "kind": 2,
        "importPath": "liboqs.tests.test_code_conventions",
        "description": "liboqs.tests.test_code_conventions",
        "peekOfCode": "def test_style():\n    result = helpers.run_subprocess(\n        ['tests/run_astyle.sh']\n    )\n    assert 'Formatted' not in result\n@helpers.filtered_test\n@pytest.mark.skipif(sys.platform.startswith(\"win\"), reason=\"Not needed on Windows\")\ndef test_spdx():\n    result = helpers.run_subprocess(\n        ['tests/test_spdx.sh']",
        "detail": "liboqs.tests.test_code_conventions",
        "documentation": {}
    },
    {
        "label": "test_spdx",
        "kind": 2,
        "importPath": "liboqs.tests.test_code_conventions",
        "description": "liboqs.tests.test_code_conventions",
        "peekOfCode": "def test_spdx():\n    result = helpers.run_subprocess(\n        ['tests/test_spdx.sh']\n    )\n    if len(result) != 0:\n        print(\"The following files do not have proper SPDX-License-Identifier headers:\")\n        print(result)\n        assert False\ndef test_memory_functions():\n    c_h_files = []",
        "detail": "liboqs.tests.test_code_conventions",
        "documentation": {}
    },
    {
        "label": "test_memory_functions",
        "kind": 2,
        "importPath": "liboqs.tests.test_code_conventions",
        "description": "liboqs.tests.test_code_conventions",
        "peekOfCode": "def test_memory_functions():\n    c_h_files = []\n    for path, _, files in os.walk('src'):\n        c_h_files += [os.path.join(path, f) for f in files if f.endswith(('.c', '.h', '.fragment'))]\n    memory_functions = ['free', 'malloc', 'calloc', 'realloc', 'strdup']\n    okay = True\n    for fn in c_h_files:\n        with open(fn) as f:\n            content = f.read()\n            lines = content.splitlines()",
        "detail": "liboqs.tests.test_code_conventions",
        "documentation": {}
    },
    {
        "label": "get_ct_passes",
        "kind": 2,
        "importPath": "liboqs.tests.test_constant_time",
        "description": "liboqs.tests.test_constant_time",
        "peekOfCode": "def get_ct_passes(t, name):\n    ct_t = os.path.join('tests', 'constant_time', t)\n    if ct_passes[t] is None:\n        with open(os.path.join(ct_t, 'passes.json'), 'r') as fp:\n            ct_passes[t] = json.load(fp)\n    passes = ct_passes[t].get(name,[])\n    return [os.path.join(ct_t, 'passes', f) for f in passes]\ndef get_ct_issues(t, name):\n    ct_t = os.path.join('tests', 'constant_time', t)\n    if ct_issues[t] is None:",
        "detail": "liboqs.tests.test_constant_time",
        "documentation": {}
    },
    {
        "label": "get_ct_issues",
        "kind": 2,
        "importPath": "liboqs.tests.test_constant_time",
        "description": "liboqs.tests.test_constant_time",
        "peekOfCode": "def get_ct_issues(t, name):\n    ct_t = os.path.join('tests', 'constant_time', t)\n    if ct_issues[t] is None:\n        with open(os.path.join(ct_t, 'issues.json'), 'r') as fp:\n            ct_issues[t] = json.load(fp)\n    issues = ct_issues[t].get(name,[])\n    return [os.path.join(ct_t, 'issues', f) for f in issues]\n@helpers.filtered_test\n@helpers.test_requires_build_options(*REQ_LIBOQS_BUILD_OPTS)\n@helpers.test_requires_valgrind_version_at_least(*MIN_VALGRIND_VERSION)",
        "detail": "liboqs.tests.test_constant_time",
        "documentation": {}
    },
    {
        "label": "test_constant_time_kem",
        "kind": 2,
        "importPath": "liboqs.tests.test_constant_time",
        "description": "liboqs.tests.test_constant_time",
        "peekOfCode": "def test_constant_time_kem(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    if ('SKIP_ALGS' in os.environ) and len(os.environ['SKIP_ALGS'])>0:\n        for algexp in os.environ['SKIP_ALGS'].split(','):\n            if len(re.findall(algexp, kem_name))>0:\n               pytest.skip(\"Test disabled by alg filter\")\n    passes = get_ct_passes('kem', kem_name)\n    issues = get_ct_issues('kem', kem_name)\n    output = helpers.run_subprocess(\n             VALGRIND + [",
        "detail": "liboqs.tests.test_constant_time",
        "documentation": {}
    },
    {
        "label": "test_constant_time_sig",
        "kind": 2,
        "importPath": "liboqs.tests.test_constant_time",
        "description": "liboqs.tests.test_constant_time",
        "peekOfCode": "def test_constant_time_sig(sig_name):\n    if not(helpers.is_sig_enabled_by_name(sig_name)): pytest.skip('Not enabled')\n    if ('SKIP_ALGS' in os.environ) and len(os.environ['SKIP_ALGS'])>0:\n        for algexp in os.environ['SKIP_ALGS'].split(','):\n            if len(re.findall(algexp, sig_name))>0:\n               pytest.skip(\"Test disabled by alg filter\")\n    passes = get_ct_passes('sig', sig_name)\n    issues = get_ct_issues('sig', sig_name)\n    output = helpers.run_subprocess(\n             VALGRIND + [",
        "detail": "liboqs.tests.test_constant_time",
        "documentation": {}
    },
    {
        "label": "REQ_LIBOQS_BUILD_OPTS",
        "kind": 5,
        "importPath": "liboqs.tests.test_constant_time",
        "description": "liboqs.tests.test_constant_time",
        "peekOfCode": "REQ_LIBOQS_BUILD_OPTS = ['OQS_ENABLE_TEST_CONSTANT_TIME',\n                         'OQS_DEBUG_BUILD']\n# Error suppression based on file and line number was introduced in\n# Valgrind 3.14.0 (9 October 2018).\n# https://www.valgrind.org/docs/manual/dist.news.html\nMIN_VALGRIND_VERSION = [3, 14, 0]\nVALGRIND = ['valgrind',\n            # '-v', # Turn on -v to see which suppression files are used\n            '--tool=memcheck',\n            '--gen-suppressions=all',",
        "detail": "liboqs.tests.test_constant_time",
        "documentation": {}
    },
    {
        "label": "MIN_VALGRIND_VERSION",
        "kind": 5,
        "importPath": "liboqs.tests.test_constant_time",
        "description": "liboqs.tests.test_constant_time",
        "peekOfCode": "MIN_VALGRIND_VERSION = [3, 14, 0]\nVALGRIND = ['valgrind',\n            # '-v', # Turn on -v to see which suppression files are used\n            '--tool=memcheck',\n            '--gen-suppressions=all',\n            '--error-exitcode=1',\n            '--max-stackframe=20480000',\n            '--num-callers=20',\n            ]\n# The following two functions read the json files",
        "detail": "liboqs.tests.test_constant_time",
        "documentation": {}
    },
    {
        "label": "VALGRIND",
        "kind": 5,
        "importPath": "liboqs.tests.test_constant_time",
        "description": "liboqs.tests.test_constant_time",
        "peekOfCode": "VALGRIND = ['valgrind',\n            # '-v', # Turn on -v to see which suppression files are used\n            '--tool=memcheck',\n            '--gen-suppressions=all',\n            '--error-exitcode=1',\n            '--max-stackframe=20480000',\n            '--num-callers=20',\n            ]\n# The following two functions read the json files\n#   liboqs/tests/constant_time/{kem,sig}/{passes,issues}.json",
        "detail": "liboqs.tests.test_constant_time",
        "documentation": {}
    },
    {
        "label": "ct_passes",
        "kind": 5,
        "importPath": "liboqs.tests.test_constant_time",
        "description": "liboqs.tests.test_constant_time",
        "peekOfCode": "ct_passes = {'kem': None, 'sig': None}\nct_issues = {'kem': None, 'sig': None}\ndef get_ct_passes(t, name):\n    ct_t = os.path.join('tests', 'constant_time', t)\n    if ct_passes[t] is None:\n        with open(os.path.join(ct_t, 'passes.json'), 'r') as fp:\n            ct_passes[t] = json.load(fp)\n    passes = ct_passes[t].get(name,[])\n    return [os.path.join(ct_t, 'passes', f) for f in passes]\ndef get_ct_issues(t, name):",
        "detail": "liboqs.tests.test_constant_time",
        "documentation": {}
    },
    {
        "label": "ct_issues",
        "kind": 5,
        "importPath": "liboqs.tests.test_constant_time",
        "description": "liboqs.tests.test_constant_time",
        "peekOfCode": "ct_issues = {'kem': None, 'sig': None}\ndef get_ct_passes(t, name):\n    ct_t = os.path.join('tests', 'constant_time', t)\n    if ct_passes[t] is None:\n        with open(os.path.join(ct_t, 'passes.json'), 'r') as fp:\n            ct_passes[t] = json.load(fp)\n    passes = ct_passes[t].get(name,[])\n    return [os.path.join(ct_t, 'passes', f) for f in passes]\ndef get_ct_issues(t, name):\n    ct_t = os.path.join('tests', 'constant_time', t)",
        "detail": "liboqs.tests.test_constant_time",
        "documentation": {}
    },
    {
        "label": "test_kem",
        "kind": 2,
        "importPath": "liboqs.tests.test_distbuild",
        "description": "liboqs.tests.test_distbuild",
        "peekOfCode": "def test_kem(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)):\n        pytest.skip('Not enabled')\n    helpers.run_subprocess([\"qemu-\"+platform.machine()+\"-static\", \"-cpu\", MINCPU,\n                            helpers.path_to_executable('test_kem'), kem_name])\n@helpers.filtered_test\n@pytest.mark.parametrize('sig_name', helpers.available_sigs_by_name())\n@helpers.test_requires_build_options(\"OQS_DIST_BUILD\")\n@helpers.test_requires_qemu(platform.machine(), MINCPU)\ndef test_sig(sig_name):",
        "detail": "liboqs.tests.test_distbuild",
        "documentation": {}
    },
    {
        "label": "test_sig",
        "kind": 2,
        "importPath": "liboqs.tests.test_distbuild",
        "description": "liboqs.tests.test_distbuild",
        "peekOfCode": "def test_sig(sig_name):\n    if not(helpers.is_sig_enabled_by_name(sig_name)):\n        pytest.skip('Not enabled')\n    helpers.run_subprocess([\"qemu-\"+platform.machine()+\"-static\", \"-cpu\", MINCPU,\n                             helpers.path_to_executable('test_sig'), sig_name])\nif __name__ == \"__main__\":\n    import sys\n    pytest.main(sys.argv)",
        "detail": "liboqs.tests.test_distbuild",
        "documentation": {}
    },
    {
        "label": "test_aes",
        "kind": 2,
        "importPath": "liboqs.tests.test_hash",
        "description": "liboqs.tests.test_hash",
        "peekOfCode": "def test_aes():\n    helpers.run_subprocess(\n        [helpers.path_to_executable('test_aes')],\n    )\n@helpers.filtered_test\n@pytest.mark.skipif(sys.platform.startswith(\"win\"), reason=\"Not supported on Windows\")\ndef test_sha3():\n    helpers.run_subprocess(\n        [helpers.path_to_executable('test_sha3')],\n    )",
        "detail": "liboqs.tests.test_hash",
        "documentation": {}
    },
    {
        "label": "test_sha3",
        "kind": 2,
        "importPath": "liboqs.tests.test_hash",
        "description": "liboqs.tests.test_hash",
        "peekOfCode": "def test_sha3():\n    helpers.run_subprocess(\n        [helpers.path_to_executable('test_sha3')],\n    )\n@helpers.filtered_test\n@pytest.mark.parametrize('algname', ['sha256', 'sha384', 'sha512', 'sha3_256', 'sha3_384', 'sha3_512'])\n@pytest.mark.skipif(sys.platform.startswith(\"win\"), reason=\"Not supported on Windows\")\ndef test_hash_sha2_random(algname):\n    # hash every size from 0 to 1024, then every 11th size after that \n    # (why 11? it's coprime with powers of 2, so we should land in a ",
        "detail": "liboqs.tests.test_hash",
        "documentation": {}
    },
    {
        "label": "test_hash_sha2_random",
        "kind": 2,
        "importPath": "liboqs.tests.test_hash",
        "description": "liboqs.tests.test_hash",
        "peekOfCode": "def test_hash_sha2_random(algname):\n    # hash every size from 0 to 1024, then every 11th size after that \n    # (why 11? it's coprime with powers of 2, so we should land in a \n    #  bunch of random-ish spots relative to block boundaries)\n    for i in list(range(0, 1024)) + list(range(1025, 20000, 11)):\n        msg = \"\".join(\"1\" for j in range(i)).encode()\n        hasher = hashlib.new(algname)\n        hasher.update(msg)\n        output = helpers.run_subprocess(\n            [helpers.path_to_executable('test_hash'), algname],",
        "detail": "liboqs.tests.test_hash",
        "documentation": {}
    },
    {
        "label": "test_kem",
        "kind": 2,
        "importPath": "liboqs.tests.test_kat",
        "description": "liboqs.tests.test_kat",
        "peekOfCode": "def test_kem(kem_name):\n    kats = helpers.get_kats(\"kem\")\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    output = helpers.run_subprocess(\n        [helpers.path_to_executable('kat_kem'), kem_name],\n    )\n    output = output.replace(\"\\r\\n\", \"\\n\")\n    h256 = sha256()\n    h256.update(output.encode())\n    assert(kats[kem_name]['single'] == h256.hexdigest())",
        "detail": "liboqs.tests.test_kat",
        "documentation": {}
    },
    {
        "label": "test_sig",
        "kind": 2,
        "importPath": "liboqs.tests.test_kat",
        "description": "liboqs.tests.test_kat",
        "peekOfCode": "def test_sig(sig_name):\n    kats = helpers.get_kats(\"sig\")\n    if not(helpers.is_sig_enabled_by_name(sig_name)): pytest.skip('Not enabled')\n    output = helpers.run_subprocess(\n        [helpers.path_to_executable('kat_sig'), sig_name],\n    )\n    output = output.replace(\"\\r\\n\", \"\\n\")\n    h256 = sha256()\n    h256.update(output.encode())\n    assert(kats[sig_name]['single'] == h256.hexdigest())",
        "detail": "liboqs.tests.test_kat",
        "documentation": {}
    },
    {
        "label": "test_sig_stfl",
        "kind": 2,
        "importPath": "liboqs.tests.test_kat",
        "description": "liboqs.tests.test_kat",
        "peekOfCode": "def test_sig_stfl(sig_stfl_name):\n    kats = helpers.get_kats(\"sig_stfl\")\n    if not(helpers.is_sig_stfl_enabled_by_name(sig_stfl_name)): pytest.skip('Not enabled')\n    katfile = helpers.get_katfile(\"sig_stfl\", sig_stfl_name)\n    if not katfile: pytest.skip(\"KATs file is missing\")\n    output = helpers.run_subprocess(\n        [helpers.path_to_executable('kat_sig_stfl'), sig_stfl_name, katfile],\n    )\n    output = output.replace(\"\\r\\n\", \"\\n\")\n    h256 = sha256()",
        "detail": "liboqs.tests.test_kat",
        "documentation": {}
    },
    {
        "label": "test_kem",
        "kind": 2,
        "importPath": "liboqs.tests.test_kat_all",
        "description": "liboqs.tests.test_kat_all",
        "peekOfCode": "def test_kem(kem_name):\n    kats = helpers.get_kats(\"kem\")\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    output = helpers.run_subprocess(\n        [helpers.path_to_executable('kat_kem'), kem_name, '--all'],\n    )\n    output = output.replace(\"\\r\\n\", \"\\n\")\n    h256 = sha256()\n    h256.update(output.encode())\n    assert(kats[kem_name]['all'] == h256.hexdigest())",
        "detail": "liboqs.tests.test_kat_all",
        "documentation": {}
    },
    {
        "label": "test_sig",
        "kind": 2,
        "importPath": "liboqs.tests.test_kat_all",
        "description": "liboqs.tests.test_kat_all",
        "peekOfCode": "def test_sig(sig_name):\n    kats = helpers.get_kats(\"sig\")\n    if not(helpers.is_sig_enabled_by_name(sig_name)): pytest.skip('Not enabled')\n    output = helpers.run_subprocess(\n        [helpers.path_to_executable('kat_sig'), sig_name, '--all'],\n    )\n    output = output.replace(\"\\r\\n\", \"\\n\")\n    h256 = sha256()\n    h256.update(output.encode())\n    assert(kats[sig_name]['all'] == h256.hexdigest())",
        "detail": "liboqs.tests.test_kat_all",
        "documentation": {}
    },
    {
        "label": "test_kem_leak",
        "kind": 2,
        "importPath": "liboqs.tests.test_leaks",
        "description": "liboqs.tests.test_leaks",
        "peekOfCode": "def test_kem_leak(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    if sys.platform != \"linux\" or os.system(\"grep ubuntu /etc/os-release\") != 0 or os.system(\"uname -a | grep x86_64\") != 0: pytest.skip('Leak testing not supported on this platform')\n    helpers.run_subprocess(\n        [\"valgrind\", \"-s\", \"--error-exitcode=1\", \"--leak-check=full\", \"--show-leak-kinds=all\", \"--vex-guest-max-insns=25\", \"--track-origins=yes\", helpers.path_to_executable('test_kem'), kem_name],\n    )\n@helpers.filtered_test\n@pytest.mark.parametrize('sig_name', helpers.available_sigs_by_name())\ndef test_sig_leak(sig_name):\n    if not(helpers.is_sig_enabled_by_name(sig_name)): pytest.skip('Not enabled')",
        "detail": "liboqs.tests.test_leaks",
        "documentation": {}
    },
    {
        "label": "test_sig_leak",
        "kind": 2,
        "importPath": "liboqs.tests.test_leaks",
        "description": "liboqs.tests.test_leaks",
        "peekOfCode": "def test_sig_leak(sig_name):\n    if not(helpers.is_sig_enabled_by_name(sig_name)): pytest.skip('Not enabled')\n    if sys.platform != \"linux\" or os.system(\"grep ubuntu /etc/os-release\") != 0 or os.system(\"uname -a | grep x86_64\") != 0: pytest.skip('Leak testing not supported on this platform')\n    helpers.run_subprocess(\n        [\"valgrind\", \"-s\", \"--error-exitcode=1\", \"--leak-check=full\", \"--show-leak-kinds=all\", helpers.path_to_executable('test_sig'), sig_name],\n    )\n@helpers.filtered_test\n@pytest.mark.parametrize('sig_stfl_name', helpers.available_sig_stfls_by_name())\ndef test_sig_stfl_leak(sig_stfl_name):\n    if not(helpers.is_sig_stfl_enabled_by_name(sig_stfl_name)): pytest.skip('Not enabled')",
        "detail": "liboqs.tests.test_leaks",
        "documentation": {}
    },
    {
        "label": "test_sig_stfl_leak",
        "kind": 2,
        "importPath": "liboqs.tests.test_leaks",
        "description": "liboqs.tests.test_leaks",
        "peekOfCode": "def test_sig_stfl_leak(sig_stfl_name):\n    if not(helpers.is_sig_stfl_enabled_by_name(sig_stfl_name)): pytest.skip('Not enabled')\n    if sys.platform != \"linux\" or os.system(\"grep ubuntu /etc/os-release\") != 0 or os.system(\"uname -a | grep x86_64\") != 0: pytest.skip('Leak testing not supported on this platform')\n    if sig_stfl_name.startswith(\"XMSS\"):\n        katfile = helpers.get_katfile(\"sig_stfl\", sig_stfl_name)\n        if not katfile: pytest.skip(\"KATs file is missing\")\n        helpers.run_subprocess(\n            [\"valgrind\", \"-s\", \"--error-exitcode=1\", \"--leak-check=full\", \"--show-leak-kinds=all\", helpers.path_to_executable('test_sig_stfl'), sig_stfl_name, katfile],\n        )\n    else:",
        "detail": "liboqs.tests.test_leaks",
        "documentation": {}
    },
    {
        "label": "test_mem_kem",
        "kind": 2,
        "importPath": "liboqs.tests.test_mem",
        "description": "liboqs.tests.test_mem",
        "peekOfCode": "def test_mem_kem(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)):\n        pytest.skip('Not enabled')\n    Path(helpers.get_current_build_dir_name()+'/mem-benchmark').mkdir(parents=True, exist_ok=True)\n    for i in range(3):\n       helpers.run_subprocess([helpers.path_to_executable('test_kem_mem'), kem_name, str(i)])\n@helpers.filtered_test\n@pytest.mark.parametrize('sig_name', helpers.available_sigs_by_name())\ndef test_mem_sig(sig_name):\n    if not(helpers.is_sig_enabled_by_name(sig_name)):",
        "detail": "liboqs.tests.test_mem",
        "documentation": {}
    },
    {
        "label": "test_mem_sig",
        "kind": 2,
        "importPath": "liboqs.tests.test_mem",
        "description": "liboqs.tests.test_mem",
        "peekOfCode": "def test_mem_sig(sig_name):\n    if not(helpers.is_sig_enabled_by_name(sig_name)):\n        pytest.skip('Not enabled')\n    Path(helpers.get_current_build_dir_name()+'/mem-benchmark').mkdir(parents=True, exist_ok=True)\n    for i in range(3):\n       helpers.run_subprocess([helpers.path_to_executable('test_sig_mem'), sig_name, str(i)])\nif __name__ == \"__main__\":\n    import sys\n    pytest.main(sys.argv)",
        "detail": "liboqs.tests.test_mem",
        "documentation": {}
    },
    {
        "label": "test_kem",
        "kind": 2,
        "importPath": "liboqs.tests.test_speed",
        "description": "liboqs.tests.test_speed",
        "peekOfCode": "def test_kem(kem_name):\n    kats = helpers.get_kats(\"kem\")\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    helpers.run_subprocess( [helpers.path_to_executable('speed_kem'), kem_name, \"-f\"] )\n@helpers.filtered_test\n@pytest.mark.parametrize('sig_name', helpers.available_sigs_by_name())\ndef test_sig(sig_name):\n    kats = helpers.get_kats(\"sig\")\n    if not(helpers.is_sig_enabled_by_name(sig_name)): pytest.skip('Not enabled')\n    helpers.run_subprocess( [helpers.path_to_executable('speed_sig'), sig_name, \"-f\"])",
        "detail": "liboqs.tests.test_speed",
        "documentation": {}
    },
    {
        "label": "test_sig",
        "kind": 2,
        "importPath": "liboqs.tests.test_speed",
        "description": "liboqs.tests.test_speed",
        "peekOfCode": "def test_sig(sig_name):\n    kats = helpers.get_kats(\"sig\")\n    if not(helpers.is_sig_enabled_by_name(sig_name)): pytest.skip('Not enabled')\n    helpers.run_subprocess( [helpers.path_to_executable('speed_sig'), sig_name, \"-f\"])\n@helpers.filtered_test\n@pytest.mark.parametrize('sig_stfl_name', helpers.available_sig_stfls_by_name())\ndef test_sig(sig_stfl_name):\n    kats = helpers.get_kats(\"sig_stfl\")\n    if not(helpers.is_sig_stfl_enabled_by_name(sig_stfl_name)):\n        pytest.skip('Not enabled')",
        "detail": "liboqs.tests.test_speed",
        "documentation": {}
    },
    {
        "label": "test_sig",
        "kind": 2,
        "importPath": "liboqs.tests.test_speed",
        "description": "liboqs.tests.test_speed",
        "peekOfCode": "def test_sig(sig_stfl_name):\n    kats = helpers.get_kats(\"sig_stfl\")\n    if not(helpers.is_sig_stfl_enabled_by_name(sig_stfl_name)):\n        pytest.skip('Not enabled')\n    elif sig_stfl_name.find(\"_10\")==-1 and sig_stfl_name.find(\"H10\")==-1:\n        pytest.skip('Test skipped')\n    else:\n        helpers.run_subprocess( [helpers.path_to_executable('speed_sig_stfl'), sig_stfl_name, \"-f\"])\nif __name__ == \"__main__\":\n    import sys",
        "detail": "liboqs.tests.test_speed",
        "documentation": {}
    },
    {
        "label": "test_wpf_strcmp_vec",
        "kind": 2,
        "importPath": "liboqs.tests.test_wycheproof_vectors",
        "description": "liboqs.tests.test_wycheproof_vectors",
        "peekOfCode": "def test_wpf_strcmp_vec(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    if not(kem_name in fips_kem): pytest.skip(\"Not supported\")\n    with open(os.path.join('tests', ml_kem_strcmp), 'r', encoding='utf-8') as fp:\n        ml_kem_kg_wpf  = json.load(fp)\n        variantFound = False\n        for variant in ml_kem_kg_wpf[\"testGroups\"]:\n            if variant[\"parameterSet\"] == kem_name and variant[\"type\"] == \"MLKEMTest\":\n                variantFound = True\n                for testCase in variant[\"tests\"]:",
        "detail": "liboqs.tests.test_wycheproof_vectors",
        "documentation": {}
    },
    {
        "label": "test_wpf_modOverflow_vec",
        "kind": 2,
        "importPath": "liboqs.tests.test_wycheproof_vectors",
        "description": "liboqs.tests.test_wycheproof_vectors",
        "peekOfCode": "def test_wpf_modOverflow_vec(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    if not(kem_name in fips_kem): pytest.skip(\"Not supported\")\n    with open(os.path.join('tests', ml_kem_modOverflow), 'r', encoding='utf-8') as fp:\n        ml_kem_kg_wpf  = json.load(fp)\n        variantFound = False\n        for variant in ml_kem_kg_wpf[\"testGroups\"]:\n            if variant[\"parameterSet\"] == kem_name and variant[\"type\"] == \"MLKEMEncapsTest\":\n                variantFound = True\n                for testCase in variant[\"tests\"]:",
        "detail": "liboqs.tests.test_wycheproof_vectors",
        "documentation": {}
    },
    {
        "label": "fips_kem",
        "kind": 5,
        "importPath": "liboqs.tests.test_wycheproof_vectors",
        "description": "liboqs.tests.test_wycheproof_vectors",
        "peekOfCode": "fips_kem = [\"ML-KEM-512\", \"ML-KEM-768\", \"ML-KEM-1024\"]\nml_kem_strcmp = \"Wycheproof_Vectors/mlkem_test/mlkem_test.json\"\nml_kem_modOverflow = \"Wycheproof_Vectors/mlkem_test/mlkem_test.json\"\n@helpers.filtered_test\n@pytest.mark.parametrize('kem_name', helpers.available_kems_by_name())\ndef test_wpf_strcmp_vec(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    if not(kem_name in fips_kem): pytest.skip(\"Not supported\")\n    with open(os.path.join('tests', ml_kem_strcmp), 'r', encoding='utf-8') as fp:\n        ml_kem_kg_wpf  = json.load(fp)",
        "detail": "liboqs.tests.test_wycheproof_vectors",
        "documentation": {}
    },
    {
        "label": "ml_kem_strcmp",
        "kind": 5,
        "importPath": "liboqs.tests.test_wycheproof_vectors",
        "description": "liboqs.tests.test_wycheproof_vectors",
        "peekOfCode": "ml_kem_strcmp = \"Wycheproof_Vectors/mlkem_test/mlkem_test.json\"\nml_kem_modOverflow = \"Wycheproof_Vectors/mlkem_test/mlkem_test.json\"\n@helpers.filtered_test\n@pytest.mark.parametrize('kem_name', helpers.available_kems_by_name())\ndef test_wpf_strcmp_vec(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    if not(kem_name in fips_kem): pytest.skip(\"Not supported\")\n    with open(os.path.join('tests', ml_kem_strcmp), 'r', encoding='utf-8') as fp:\n        ml_kem_kg_wpf  = json.load(fp)\n        variantFound = False",
        "detail": "liboqs.tests.test_wycheproof_vectors",
        "documentation": {}
    },
    {
        "label": "ml_kem_modOverflow",
        "kind": 5,
        "importPath": "liboqs.tests.test_wycheproof_vectors",
        "description": "liboqs.tests.test_wycheproof_vectors",
        "peekOfCode": "ml_kem_modOverflow = \"Wycheproof_Vectors/mlkem_test/mlkem_test.json\"\n@helpers.filtered_test\n@pytest.mark.parametrize('kem_name', helpers.available_kems_by_name())\ndef test_wpf_strcmp_vec(kem_name):\n    if not(helpers.is_kem_enabled_by_name(kem_name)): pytest.skip('Not enabled')\n    if not(kem_name in fips_kem): pytest.skip(\"Not supported\")\n    with open(os.path.join('tests', ml_kem_strcmp), 'r', encoding='utf-8') as fp:\n        ml_kem_kg_wpf  = json.load(fp)\n        variantFound = False\n        for variant in ml_kem_kg_wpf[\"testGroups\"]:",
        "detail": "liboqs.tests.test_wycheproof_vectors",
        "documentation": {}
    },
    {
        "label": "message",
        "kind": 5,
        "importPath": "liboqs-python.docker.minitest",
        "description": "liboqs-python.docker.minitest",
        "peekOfCode": "message = \"This is the message to sign\".encode()\n# create signer and verifier with sample signature mechanisms\nsigalg = \"Dilithium2\"\nwith oqs.Signature(sigalg) as signer:\n    with oqs.Signature(sigalg) as verifier:\n        signer_public_key = signer.generate_keypair()\n        signature = signer.sign(message)\n        is_valid = verifier.verify(message, signature, signer_public_key)\nif (not is_valid):\n    print(\"Failed to validate signature. Exiting.\")",
        "detail": "liboqs-python.docker.minitest",
        "documentation": {}
    },
    {
        "label": "sigalg",
        "kind": 5,
        "importPath": "liboqs-python.docker.minitest",
        "description": "liboqs-python.docker.minitest",
        "peekOfCode": "sigalg = \"Dilithium2\"\nwith oqs.Signature(sigalg) as signer:\n    with oqs.Signature(sigalg) as verifier:\n        signer_public_key = signer.generate_keypair()\n        signature = signer.sign(message)\n        is_valid = verifier.verify(message, signature, signer_public_key)\nif (not is_valid):\n    print(\"Failed to validate signature. Exiting.\")\n    exit(1)\nelse:",
        "detail": "liboqs-python.docker.minitest",
        "documentation": {}
    },
    {
        "label": "sslContext.verify_mode",
        "kind": 5,
        "importPath": "liboqs-python.docker.minitest",
        "description": "liboqs-python.docker.minitest",
        "peekOfCode": "sslContext.verify_mode = ssl.CERT_REQUIRED\n# Trust LetsEncrypt root CA:\nsslContext.load_verify_locations(cafile=\"isrgrootx1.pem\")\n# Retrieve interop test server root CA\nwith urllib.request.urlopen('https://test.openquantumsafe.org/CA.crt', context=sslContext) as response:\n    data=response.read()\n    with open(\"CA.crt\", \"w+b\") as f:\n        f.write(data)\n# Retrieve JSON structure of all alg/port combinations:\nwith urllib.request.urlopen('https://test.openquantumsafe.org/assignments.json', context=sslContext) as response:",
        "detail": "liboqs-python.docker.minitest",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "liboqs-python.examples.kem",
        "description": "liboqs-python.examples.kem",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nlogger.addHandler(logging.StreamHandler(stdout))\nlogger.info(\"liboqs version: %s\", oqs.oqs_version())\nlogger.info(\"liboqs-python version: %s\", oqs.oqs_python_version())\nlogger.info(\n    \"Enabled KEM mechanisms:\\n%s\",\n    pformat(oqs.get_enabled_kem_mechanisms(), compact=True),\n)\n# Create client and server with sample KEM mechanisms",
        "detail": "liboqs-python.examples.kem",
        "documentation": {}
    },
    {
        "label": "kemalg",
        "kind": 5,
        "importPath": "liboqs-python.examples.kem",
        "description": "liboqs-python.examples.kem",
        "peekOfCode": "kemalg = \"ML-KEM-512\"\nwith oqs.KeyEncapsulation(kemalg) as client:\n    with oqs.KeyEncapsulation(kemalg) as server:\n        logger.info(\"Key encapsulation details:\\n%s\", pformat(client.details))\n        # Client generates its keypair\n        public_key_client = client.generate_keypair()\n        # Optionally, the secret key can be obtained by calling export_secret_key()\n        # and the client can later be re-instantiated with the key pair:\n        # secret_key_client = client.export_secret_key()\n        # Store key pair, wait... (session resumption):",
        "detail": "liboqs-python.examples.kem",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "liboqs-python.examples.rand",
        "description": "liboqs-python.examples.rand",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nlogger.addHandler(logging.StreamHandler(stdout))\nlogger.info(\"liboqs version: %s\", oqs_version())\nlogger.info(\"liboqs-python version: %s\", oqs_python_version())\noqsrand.randombytes_switch_algorithm(\"system\")\nlogger.info(\n    \"System (default): %s\",\n    \" \".join(f\"{x:02X}\" for x in oqsrand.randombytes(32)),\n)",
        "detail": "liboqs-python.examples.rand",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "liboqs-python.examples.sig",
        "description": "liboqs-python.examples.sig",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nlogger.addHandler(logging.StreamHandler(stdout))\nlogger.info(\"liboqs version: %s\", oqs.oqs_version())\nlogger.info(\"liboqs-python version: %s\", oqs.oqs_python_version())\nlogger.info(\n    \"Enabled signature mechanisms:\\n%s\",\n    pformat(oqs.get_enabled_sig_mechanisms(), compact=True),\n)\nmessage = b\"This is the message to sign\"",
        "detail": "liboqs-python.examples.sig",
        "documentation": {}
    },
    {
        "label": "message",
        "kind": 5,
        "importPath": "liboqs-python.examples.sig",
        "description": "liboqs-python.examples.sig",
        "peekOfCode": "message = b\"This is the message to sign\"\n# Create signer and verifier with sample signature mechanisms\nsigalg = \"ML-DSA-44\"\nwith oqs.Signature(sigalg) as signer, oqs.Signature(sigalg) as verifier:\n    logger.info(\"Signature details:\\n%s\", pformat(signer.details))\n    # Signer generates its keypair\n    signer_public_key = signer.generate_keypair()\n    # Optionally, the secret key can be obtained by calling export_secret_key()\n    # and the signer can later be re-instantiated with the key pair:\n    # secret_key = signer.export_secret_key()",
        "detail": "liboqs-python.examples.sig",
        "documentation": {}
    },
    {
        "label": "sigalg",
        "kind": 5,
        "importPath": "liboqs-python.examples.sig",
        "description": "liboqs-python.examples.sig",
        "peekOfCode": "sigalg = \"ML-DSA-44\"\nwith oqs.Signature(sigalg) as signer, oqs.Signature(sigalg) as verifier:\n    logger.info(\"Signature details:\\n%s\", pformat(signer.details))\n    # Signer generates its keypair\n    signer_public_key = signer.generate_keypair()\n    # Optionally, the secret key can be obtained by calling export_secret_key()\n    # and the signer can later be re-instantiated with the key pair:\n    # secret_key = signer.export_secret_key()\n    # Store key pair, wait... (session resumption):\n    # signer = oqs.Signature(sigalg, secret_key)",
        "detail": "liboqs-python.examples.sig",
        "documentation": {}
    },
    {
        "label": "MechanismNotSupportedError",
        "kind": 6,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "class MechanismNotSupportedError(Exception):\n    \"\"\"Exception raised when an algorithm is not supported by OQS.\"\"\"\n    def __init__(self, alg_name: str) -> None:\n        \"\"\":param alg_name: requested algorithm name.\"\"\"\n        self.alg_name = alg_name\n        self.message = f\"{alg_name} is not supported by OQS\"\nclass MechanismNotEnabledError(MechanismNotSupportedError):\n    \"\"\"Exception raised when an algorithm is supported but not enabled by OQS.\"\"\"\n    def __init__(self, alg_name: str) -> None:\n        \"\"\":param alg_name: requested algorithm name.\"\"\"",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "MechanismNotEnabledError",
        "kind": 6,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "class MechanismNotEnabledError(MechanismNotSupportedError):\n    \"\"\"Exception raised when an algorithm is supported but not enabled by OQS.\"\"\"\n    def __init__(self, alg_name: str) -> None:\n        \"\"\":param alg_name: requested algorithm name.\"\"\"\n        self.alg_name = alg_name\n        self.message = f\"{alg_name} is supported but not enabled by OQS\"\nclass KeyEncapsulation(ct.Structure):\n    \"\"\"\n    An OQS KeyEncapsulation wraps native/C liboqs OQS_KEM structs.\n    The wrapper maps methods to the C equivalent as follows:",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "KeyEncapsulation",
        "kind": 6,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "class KeyEncapsulation(ct.Structure):\n    \"\"\"\n    An OQS KeyEncapsulation wraps native/C liboqs OQS_KEM structs.\n    The wrapper maps methods to the C equivalent as follows:\n    Python            |  C liboqs\n    -------------------------------\n    generate_keypair  |  keypair\n    encap_secret      |  encaps\n    decap_secret      |  decaps\n    free              |  OQS_KEM_free",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "Signature",
        "kind": 6,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "class Signature(ct.Structure):\n    \"\"\"\n    An OQS Signature wraps native/C liboqs OQS_SIG structs.\n    The wrapper maps methods to the C equivalent as follows:\n    Python            |  C liboqs\n    -------------------------------\n    generate_keypair  |  keypair\n    sign              |  sign\n    verify            |  verify\n    free              |  OQS_SIG_free",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "oqs_python_version",
        "kind": 2,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "def oqs_python_version() -> Union[str, None]:\n    \"\"\"liboqs-python version string.\"\"\"\n    try:\n        result = importlib.metadata.version(\"liboqs-python\")\n    except importlib.metadata.PackageNotFoundError:\n        warnings.warn(\"Please install liboqs-python using pip install\", stacklevel=2)\n        return None\n    return result\n# liboqs-python tries to automatically install and load this liboqs version in\n# case no other version is found",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "version",
        "kind": 2,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "def version(version_str: str) -> tuple[str, str, str]:\n    parts = version_str.split(\".\")\n    major = parts[0] if len(parts) > 0 else \"\"\n    minor = parts[1] if len(parts) > 1 else \"\"\n    patch = parts[2] if len(parts) > 2 else \"\"\n    return major, minor, patch\ndef _load_shared_obj(\n    name: str,\n    additional_searching_paths: Union[Sequence[Path], None] = None,\n) -> ct.CDLL:",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "native",
        "kind": 2,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "def native() -> ct.CDLL:\n    \"\"\"Handle to native liboqs handler.\"\"\"\n    return _liboqs\n# liboqs initialization\nnative().OQS_init()\ndef oqs_version() -> str:\n    \"\"\"`liboqs` version string.\"\"\"\n    native().OQS_version.restype = ct.c_char_p\n    return ct.c_char_p(native().OQS_version()).value.decode(\"UTF-8\")  # type: ignore[union-attr]\noqs_ver = oqs_version()",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "oqs_version",
        "kind": 2,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "def oqs_version() -> str:\n    \"\"\"`liboqs` version string.\"\"\"\n    native().OQS_version.restype = ct.c_char_p\n    return ct.c_char_p(native().OQS_version()).value.decode(\"UTF-8\")  # type: ignore[union-attr]\noqs_ver = oqs_version()\noqs_ver_major, oqs_ver_minor, oqs_ver_patch = version(oqs_ver)\noqs_python_ver = oqs_python_version()\nif oqs_python_ver:\n    oqs_python_ver_major, oqs_python_ver_minor, oqs_python_ver_patch = version(oqs_python_ver)\n    # Warn the user if the liboqs version differs from liboqs-python version",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "is_kem_enabled",
        "kind": 2,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "def is_kem_enabled(alg_name: str) -> bool:\n    \"\"\"\n    Return True if the KEM algorithm is enabled.\n    :param alg_name: a KEM mechanism algorithm name.\n    \"\"\"\n    return native().OQS_KEM_alg_is_enabled(ct.create_string_buffer(alg_name.encode()))\n_KEM_alg_ids = [native().OQS_KEM_alg_identifier(i) for i in range(native().OQS_KEM_alg_count())]\n_supported_KEMs: tuple[str, ...] = tuple([i.decode() for i in _KEM_alg_ids])  # noqa: N816\n_enabled_KEMs: tuple[str, ...] = tuple([i for i in _supported_KEMs if is_kem_enabled(i)])  # noqa: N816\ndef get_enabled_kem_mechanisms() -> tuple[str, ...]:",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "get_enabled_kem_mechanisms",
        "kind": 2,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "def get_enabled_kem_mechanisms() -> tuple[str, ...]:\n    \"\"\"Return the list of enabled KEM mechanisms.\"\"\"\n    return _enabled_KEMs\ndef get_supported_kem_mechanisms() -> tuple[str, ...]:\n    \"\"\"Return the list of supported KEM mechanisms.\"\"\"\n    return _supported_KEMs\nclass Signature(ct.Structure):\n    \"\"\"\n    An OQS Signature wraps native/C liboqs OQS_SIG structs.\n    The wrapper maps methods to the C equivalent as follows:",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "get_supported_kem_mechanisms",
        "kind": 2,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "def get_supported_kem_mechanisms() -> tuple[str, ...]:\n    \"\"\"Return the list of supported KEM mechanisms.\"\"\"\n    return _supported_KEMs\nclass Signature(ct.Structure):\n    \"\"\"\n    An OQS Signature wraps native/C liboqs OQS_SIG structs.\n    The wrapper maps methods to the C equivalent as follows:\n    Python            |  C liboqs\n    -------------------------------\n    generate_keypair  |  keypair",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "is_sig_enabled",
        "kind": 2,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "def is_sig_enabled(alg_name: str) -> bool:\n    \"\"\"\n    Return True if the signature algorithm is enabled.\n    :param alg_name: a signature mechanism algorithm name.\n    \"\"\"\n    return native().OQS_SIG_alg_is_enabled(ct.create_string_buffer(alg_name.encode()))\n_sig_alg_ids = [native().OQS_SIG_alg_identifier(i) for i in range(native().OQS_SIG_alg_count())]\n_supported_sigs: tuple[str, ...] = tuple([i.decode() for i in _sig_alg_ids])\n_enabled_sigs: tuple[str, ...] = tuple([i for i in _supported_sigs if is_sig_enabled(i)])\ndef get_enabled_sig_mechanisms() -> tuple[str, ...]:",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "get_enabled_sig_mechanisms",
        "kind": 2,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "def get_enabled_sig_mechanisms() -> tuple[str, ...]:\n    \"\"\"Return the list of enabled signature mechanisms.\"\"\"\n    return _enabled_sigs\ndef get_supported_sig_mechanisms() -> tuple[str, ...]:\n    \"\"\"Return the list of supported signature mechanisms.\"\"\"\n    return _supported_sigs",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "get_supported_sig_mechanisms",
        "kind": 2,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "def get_supported_sig_mechanisms() -> tuple[str, ...]:\n    \"\"\"Return the list of supported signature mechanisms.\"\"\"\n    return _supported_sigs",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "TKeyEncapsulation",
        "kind": 5,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "TKeyEncapsulation = TypeVar(\"TKeyEncapsulation\", bound=\"KeyEncapsulation\")\nTSignature = TypeVar(\"TSignature\", bound=\"Signature\")\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nlogger.addHandler(logging.StreamHandler(stdout))\n# Expected return value from native OQS functions\nOQS_SUCCESS: Final[int] = 0\nOQS_ERROR: Final[int] = -1\ndef oqs_python_version() -> Union[str, None]:\n    \"\"\"liboqs-python version string.\"\"\"",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "TSignature",
        "kind": 5,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "TSignature = TypeVar(\"TSignature\", bound=\"Signature\")\nlogger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nlogger.addHandler(logging.StreamHandler(stdout))\n# Expected return value from native OQS functions\nOQS_SUCCESS: Final[int] = 0\nOQS_ERROR: Final[int] = -1\ndef oqs_python_version() -> Union[str, None]:\n    \"\"\"liboqs-python version string.\"\"\"\n    try:",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "logger",
        "kind": 5,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "logger = logging.getLogger(__name__)\nlogger.setLevel(logging.INFO)\nlogger.addHandler(logging.StreamHandler(stdout))\n# Expected return value from native OQS functions\nOQS_SUCCESS: Final[int] = 0\nOQS_ERROR: Final[int] = -1\ndef oqs_python_version() -> Union[str, None]:\n    \"\"\"liboqs-python version string.\"\"\"\n    try:\n        result = importlib.metadata.version(\"liboqs-python\")",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "OQS_VERSION",
        "kind": 5,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "OQS_VERSION = oqs_python_version()\ndef version(version_str: str) -> tuple[str, str, str]:\n    parts = version_str.split(\".\")\n    major = parts[0] if len(parts) > 0 else \"\"\n    minor = parts[1] if len(parts) > 1 else \"\"\n    patch = parts[2] if len(parts) > 2 else \"\"\n    return major, minor, patch\ndef _load_shared_obj(\n    name: str,\n    additional_searching_paths: Union[Sequence[Path], None] = None,",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "_liboqs",
        "kind": 5,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "_liboqs = _load_liboqs()\ndef native() -> ct.CDLL:\n    \"\"\"Handle to native liboqs handler.\"\"\"\n    return _liboqs\n# liboqs initialization\nnative().OQS_init()\ndef oqs_version() -> str:\n    \"\"\"`liboqs` version string.\"\"\"\n    native().OQS_version.restype = ct.c_char_p\n    return ct.c_char_p(native().OQS_version()).value.decode(\"UTF-8\")  # type: ignore[union-attr]",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "oqs_ver",
        "kind": 5,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "oqs_ver = oqs_version()\noqs_ver_major, oqs_ver_minor, oqs_ver_patch = version(oqs_ver)\noqs_python_ver = oqs_python_version()\nif oqs_python_ver:\n    oqs_python_ver_major, oqs_python_ver_minor, oqs_python_ver_patch = version(oqs_python_ver)\n    # Warn the user if the liboqs version differs from liboqs-python version\n    if not (oqs_ver_major == oqs_python_ver_major and oqs_ver_minor == oqs_python_ver_minor):\n        warnings.warn(\n            f\"liboqs version (major, minor) {oqs_version()} differs from liboqs-python version \"\n            f\"{oqs_python_version()}\",",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "oqs_python_ver",
        "kind": 5,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "oqs_python_ver = oqs_python_version()\nif oqs_python_ver:\n    oqs_python_ver_major, oqs_python_ver_minor, oqs_python_ver_patch = version(oqs_python_ver)\n    # Warn the user if the liboqs version differs from liboqs-python version\n    if not (oqs_ver_major == oqs_python_ver_major and oqs_ver_minor == oqs_python_ver_minor):\n        warnings.warn(\n            f\"liboqs version (major, minor) {oqs_version()} differs from liboqs-python version \"\n            f\"{oqs_python_version()}\",\n            stacklevel=2,\n        )",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "native().OQS_KEM_new.restype",
        "kind": 5,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "native().OQS_KEM_new.restype = ct.POINTER(KeyEncapsulation)\nnative().OQS_KEM_alg_identifier.restype = ct.c_char_p\ndef is_kem_enabled(alg_name: str) -> bool:\n    \"\"\"\n    Return True if the KEM algorithm is enabled.\n    :param alg_name: a KEM mechanism algorithm name.\n    \"\"\"\n    return native().OQS_KEM_alg_is_enabled(ct.create_string_buffer(alg_name.encode()))\n_KEM_alg_ids = [native().OQS_KEM_alg_identifier(i) for i in range(native().OQS_KEM_alg_count())]\n_supported_KEMs: tuple[str, ...] = tuple([i.decode() for i in _KEM_alg_ids])  # noqa: N816",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "native().OQS_KEM_alg_identifier.restype",
        "kind": 5,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "native().OQS_KEM_alg_identifier.restype = ct.c_char_p\ndef is_kem_enabled(alg_name: str) -> bool:\n    \"\"\"\n    Return True if the KEM algorithm is enabled.\n    :param alg_name: a KEM mechanism algorithm name.\n    \"\"\"\n    return native().OQS_KEM_alg_is_enabled(ct.create_string_buffer(alg_name.encode()))\n_KEM_alg_ids = [native().OQS_KEM_alg_identifier(i) for i in range(native().OQS_KEM_alg_count())]\n_supported_KEMs: tuple[str, ...] = tuple([i.decode() for i in _KEM_alg_ids])  # noqa: N816\n_enabled_KEMs: tuple[str, ...] = tuple([i for i in _supported_KEMs if is_kem_enabled(i)])  # noqa: N816",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "_KEM_alg_ids",
        "kind": 5,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "_KEM_alg_ids = [native().OQS_KEM_alg_identifier(i) for i in range(native().OQS_KEM_alg_count())]\n_supported_KEMs: tuple[str, ...] = tuple([i.decode() for i in _KEM_alg_ids])  # noqa: N816\n_enabled_KEMs: tuple[str, ...] = tuple([i for i in _supported_KEMs if is_kem_enabled(i)])  # noqa: N816\ndef get_enabled_kem_mechanisms() -> tuple[str, ...]:\n    \"\"\"Return the list of enabled KEM mechanisms.\"\"\"\n    return _enabled_KEMs\ndef get_supported_kem_mechanisms() -> tuple[str, ...]:\n    \"\"\"Return the list of supported KEM mechanisms.\"\"\"\n    return _supported_KEMs\nclass Signature(ct.Structure):",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "native().OQS_SIG_new.restype",
        "kind": 5,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "native().OQS_SIG_new.restype = ct.POINTER(Signature)\nnative().OQS_SIG_alg_identifier.restype = ct.c_char_p\ndef is_sig_enabled(alg_name: str) -> bool:\n    \"\"\"\n    Return True if the signature algorithm is enabled.\n    :param alg_name: a signature mechanism algorithm name.\n    \"\"\"\n    return native().OQS_SIG_alg_is_enabled(ct.create_string_buffer(alg_name.encode()))\n_sig_alg_ids = [native().OQS_SIG_alg_identifier(i) for i in range(native().OQS_SIG_alg_count())]\n_supported_sigs: tuple[str, ...] = tuple([i.decode() for i in _sig_alg_ids])",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "native().OQS_SIG_alg_identifier.restype",
        "kind": 5,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "native().OQS_SIG_alg_identifier.restype = ct.c_char_p\ndef is_sig_enabled(alg_name: str) -> bool:\n    \"\"\"\n    Return True if the signature algorithm is enabled.\n    :param alg_name: a signature mechanism algorithm name.\n    \"\"\"\n    return native().OQS_SIG_alg_is_enabled(ct.create_string_buffer(alg_name.encode()))\n_sig_alg_ids = [native().OQS_SIG_alg_identifier(i) for i in range(native().OQS_SIG_alg_count())]\n_supported_sigs: tuple[str, ...] = tuple([i.decode() for i in _sig_alg_ids])\n_enabled_sigs: tuple[str, ...] = tuple([i for i in _supported_sigs if is_sig_enabled(i)])",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "_sig_alg_ids",
        "kind": 5,
        "importPath": "liboqs-python.oqs.oqs",
        "description": "liboqs-python.oqs.oqs",
        "peekOfCode": "_sig_alg_ids = [native().OQS_SIG_alg_identifier(i) for i in range(native().OQS_SIG_alg_count())]\n_supported_sigs: tuple[str, ...] = tuple([i.decode() for i in _sig_alg_ids])\n_enabled_sigs: tuple[str, ...] = tuple([i for i in _supported_sigs if is_sig_enabled(i)])\ndef get_enabled_sig_mechanisms() -> tuple[str, ...]:\n    \"\"\"Return the list of enabled signature mechanisms.\"\"\"\n    return _enabled_sigs\ndef get_supported_sig_mechanisms() -> tuple[str, ...]:\n    \"\"\"Return the list of supported signature mechanisms.\"\"\"\n    return _supported_sigs",
        "detail": "liboqs-python.oqs.oqs",
        "documentation": {}
    },
    {
        "label": "randombytes",
        "kind": 2,
        "importPath": "liboqs-python.oqs.rand",
        "description": "liboqs-python.oqs.rand",
        "peekOfCode": "def randombytes(bytes_to_read: int) -> bytes:\n    \"\"\"\n    Generate random bytes. This implementation uses either the default RNG algorithm (\"system\"),\n    or whichever algorithm has been selected by random_bytes_switch_algorithm().\n    :param bytes_to_read: the number of random bytes to generate.\n    :return: random bytes.\n    \"\"\"\n    result = ct.create_string_buffer(bytes_to_read)\n    oqs.native().OQS_randombytes(result, ct.c_size_t(bytes_to_read))\n    return bytes(result)",
        "detail": "liboqs-python.oqs.rand",
        "documentation": {}
    },
    {
        "label": "randombytes_switch_algorithm",
        "kind": 2,
        "importPath": "liboqs-python.oqs.rand",
        "description": "liboqs-python.oqs.rand",
        "peekOfCode": "def randombytes_switch_algorithm(alg_name: str) -> None:\n    \"\"\"\n    Switches the core OQS_randombytes to use the specified algorithm. See <oqs/rand.h> liboqs\n    headers for more details.\n    :param alg_name: algorithm name, possible values are \"system\" and \"OpenSSL\".\n    \"\"\"\n    if (\n        oqs.native().OQS_randombytes_switch_algorithm(\n            ct.create_string_buffer(alg_name.encode()),\n        )",
        "detail": "liboqs-python.oqs.rand",
        "documentation": {}
    },
    {
        "label": "test_correctness",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_kem",
        "description": "liboqs-python.tests.test_kem",
        "peekOfCode": "def test_correctness() -> tuple[None, str]:\n    for alg_name in oqs.get_enabled_kem_mechanisms():\n        if any(item in alg_name for item in disabled_KEM_patterns):\n            continue\n        yield check_correctness, alg_name\ndef check_correctness(alg_name: str) -> None:\n    with oqs.KeyEncapsulation(alg_name) as kem:\n        public_key = kem.generate_keypair()\n        ciphertext, shared_secret_server = kem.encap_secret(public_key)\n        shared_secret_client = kem.decap_secret(ciphertext)",
        "detail": "liboqs-python.tests.test_kem",
        "documentation": {}
    },
    {
        "label": "check_correctness",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_kem",
        "description": "liboqs-python.tests.test_kem",
        "peekOfCode": "def check_correctness(alg_name: str) -> None:\n    with oqs.KeyEncapsulation(alg_name) as kem:\n        public_key = kem.generate_keypair()\n        ciphertext, shared_secret_server = kem.encap_secret(public_key)\n        shared_secret_client = kem.decap_secret(ciphertext)\n        assert shared_secret_client == shared_secret_server  # noqa: S101\ndef test_wrong_ciphertext() -> tuple[None, str]:\n    for alg_name in oqs.get_enabled_kem_mechanisms():\n        if any(item in alg_name for item in disabled_KEM_patterns):\n            continue",
        "detail": "liboqs-python.tests.test_kem",
        "documentation": {}
    },
    {
        "label": "test_wrong_ciphertext",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_kem",
        "description": "liboqs-python.tests.test_kem",
        "peekOfCode": "def test_wrong_ciphertext() -> tuple[None, str]:\n    for alg_name in oqs.get_enabled_kem_mechanisms():\n        if any(item in alg_name for item in disabled_KEM_patterns):\n            continue\n        yield check_wrong_ciphertext, alg_name\ndef check_wrong_ciphertext(alg_name: str) -> None:\n    with oqs.KeyEncapsulation(alg_name) as kem:\n        public_key = kem.generate_keypair()\n        ciphertext, shared_secret_server = kem.encap_secret(public_key)\n        wrong_ciphertext = bytes(random.getrandbits(8) for _ in range(len(ciphertext)))",
        "detail": "liboqs-python.tests.test_kem",
        "documentation": {}
    },
    {
        "label": "check_wrong_ciphertext",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_kem",
        "description": "liboqs-python.tests.test_kem",
        "peekOfCode": "def check_wrong_ciphertext(alg_name: str) -> None:\n    with oqs.KeyEncapsulation(alg_name) as kem:\n        public_key = kem.generate_keypair()\n        ciphertext, shared_secret_server = kem.encap_secret(public_key)\n        wrong_ciphertext = bytes(random.getrandbits(8) for _ in range(len(ciphertext)))\n        try:\n            shared_secret_client = kem.decap_secret(wrong_ciphertext)\n            assert shared_secret_client != shared_secret_server  # noqa: S101\n        except RuntimeError:\n            pass",
        "detail": "liboqs-python.tests.test_kem",
        "documentation": {}
    },
    {
        "label": "test_not_supported",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_kem",
        "description": "liboqs-python.tests.test_kem",
        "peekOfCode": "def test_not_supported() -> None:\n    try:\n        with oqs.KeyEncapsulation(\"unsupported_sig\"):\n            pass\n    except oqs.MechanismNotSupportedError:\n        pass\n    except Exception as ex:\n        msg = f\"An unexpected exception was raised {ex}\"\n        raise AssertionError(msg) from ex\n    else:",
        "detail": "liboqs-python.tests.test_kem",
        "documentation": {}
    },
    {
        "label": "test_not_enabled",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_kem",
        "description": "liboqs-python.tests.test_kem",
        "peekOfCode": "def test_not_enabled() -> None:\n    for alg_name in oqs.get_supported_kem_mechanisms():\n        if alg_name not in oqs.get_enabled_kem_mechanisms():\n            # Found a non-enabled but supported alg\n            try:\n                with oqs.KeyEncapsulation(alg_name):\n                    pass\n            except oqs.MechanismNotEnabledError:\n                pass\n            except Exception as ex:",
        "detail": "liboqs-python.tests.test_kem",
        "documentation": {}
    },
    {
        "label": "test_python_attributes",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_kem",
        "description": "liboqs-python.tests.test_kem",
        "peekOfCode": "def test_python_attributes() -> None:\n    for alg_name in oqs.get_enabled_kem_mechanisms():\n        with oqs.KeyEncapsulation(alg_name) as kem:\n            if kem.method_name.decode() != alg_name:\n                msg = \"Incorrect oqs.KeyEncapsulation.method_name\"\n                raise AssertionError(msg)\n            if kem.alg_version is None:\n                msg = \"Undefined oqs.KeyEncapsulation.alg_version\"\n                raise AssertionError(msg)\n            if not 1 <= kem.claimed_nist_level <= 5:",
        "detail": "liboqs-python.tests.test_kem",
        "documentation": {}
    },
    {
        "label": "disabled_KEM_patterns",
        "kind": 5,
        "importPath": "liboqs-python.tests.test_kem",
        "description": "liboqs-python.tests.test_kem",
        "peekOfCode": "disabled_KEM_patterns = []  # noqa: N816\nif platform.system() == \"Windows\":\n    disabled_KEM_patterns = [\"\"]  # noqa: N816\ndef test_correctness() -> tuple[None, str]:\n    for alg_name in oqs.get_enabled_kem_mechanisms():\n        if any(item in alg_name for item in disabled_KEM_patterns):\n            continue\n        yield check_correctness, alg_name\ndef check_correctness(alg_name: str) -> None:\n    with oqs.KeyEncapsulation(alg_name) as kem:",
        "detail": "liboqs-python.tests.test_kem",
        "documentation": {}
    },
    {
        "label": "test_correctness",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_sig",
        "description": "liboqs-python.tests.test_sig",
        "peekOfCode": "def test_correctness() -> tuple[None, str]:\n    for alg_name in oqs.get_enabled_sig_mechanisms():\n        if any(item in alg_name for item in disabled_sig_patterns):\n            continue\n        yield check_correctness, alg_name\ndef test_correctness_with_ctx_str() -> tuple[None, str]:\n    for alg_name in oqs.get_enabled_sig_mechanisms():\n        if not Signature(alg_name).details[\"sig_with_ctx_support\"]:\n            continue\n        if any(item in alg_name for item in disabled_sig_patterns):",
        "detail": "liboqs-python.tests.test_sig",
        "documentation": {}
    },
    {
        "label": "test_correctness_with_ctx_str",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_sig",
        "description": "liboqs-python.tests.test_sig",
        "peekOfCode": "def test_correctness_with_ctx_str() -> tuple[None, str]:\n    for alg_name in oqs.get_enabled_sig_mechanisms():\n        if not Signature(alg_name).details[\"sig_with_ctx_support\"]:\n            continue\n        if any(item in alg_name for item in disabled_sig_patterns):\n            continue\n        yield check_correctness_with_ctx_str, alg_name\ndef check_correctness(alg_name: str) -> None:\n    with oqs.Signature(alg_name) as sig:\n        message = bytes(random.getrandbits(8) for _ in range(100))",
        "detail": "liboqs-python.tests.test_sig",
        "documentation": {}
    },
    {
        "label": "check_correctness",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_sig",
        "description": "liboqs-python.tests.test_sig",
        "peekOfCode": "def check_correctness(alg_name: str) -> None:\n    with oqs.Signature(alg_name) as sig:\n        message = bytes(random.getrandbits(8) for _ in range(100))\n        public_key = sig.generate_keypair()\n        signature = sig.sign(message)\n        assert sig.verify(message, signature, public_key)  # noqa: S101\ndef check_correctness_with_ctx_str(alg_name: str) -> None:\n    with oqs.Signature(alg_name) as sig:\n        message = bytes(random.getrandbits(8) for _ in range(100))\n        context = b\"some context\"",
        "detail": "liboqs-python.tests.test_sig",
        "documentation": {}
    },
    {
        "label": "check_correctness_with_ctx_str",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_sig",
        "description": "liboqs-python.tests.test_sig",
        "peekOfCode": "def check_correctness_with_ctx_str(alg_name: str) -> None:\n    with oqs.Signature(alg_name) as sig:\n        message = bytes(random.getrandbits(8) for _ in range(100))\n        context = b\"some context\"\n        public_key = sig.generate_keypair()\n        signature = sig.sign_with_ctx_str(message, context)\n        assert sig.verify_with_ctx_str(message, signature, context, public_key)  # noqa: S101\ndef test_wrong_message() -> tuple[None, str]:\n    for alg_name in oqs.get_enabled_sig_mechanisms():\n        if any(item in alg_name for item in disabled_sig_patterns):",
        "detail": "liboqs-python.tests.test_sig",
        "documentation": {}
    },
    {
        "label": "test_wrong_message",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_sig",
        "description": "liboqs-python.tests.test_sig",
        "peekOfCode": "def test_wrong_message() -> tuple[None, str]:\n    for alg_name in oqs.get_enabled_sig_mechanisms():\n        if any(item in alg_name for item in disabled_sig_patterns):\n            continue\n        yield check_wrong_message, alg_name\ndef check_wrong_message(alg_name: str) -> None:\n    with oqs.Signature(alg_name) as sig:\n        message = bytes(random.getrandbits(8) for _ in range(100))\n        public_key = sig.generate_keypair()\n        signature = sig.sign(message)",
        "detail": "liboqs-python.tests.test_sig",
        "documentation": {}
    },
    {
        "label": "check_wrong_message",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_sig",
        "description": "liboqs-python.tests.test_sig",
        "peekOfCode": "def check_wrong_message(alg_name: str) -> None:\n    with oqs.Signature(alg_name) as sig:\n        message = bytes(random.getrandbits(8) for _ in range(100))\n        public_key = sig.generate_keypair()\n        signature = sig.sign(message)\n        wrong_message = bytes(random.getrandbits(8) for _ in range(len(message)))\n        assert not (sig.verify(wrong_message, signature, public_key))  # noqa: S101\ndef test_wrong_signature() -> tuple[None, str]:\n    for alg_name in oqs.get_enabled_sig_mechanisms():\n        if any(item in alg_name for item in disabled_sig_patterns):",
        "detail": "liboqs-python.tests.test_sig",
        "documentation": {}
    },
    {
        "label": "test_wrong_signature",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_sig",
        "description": "liboqs-python.tests.test_sig",
        "peekOfCode": "def test_wrong_signature() -> tuple[None, str]:\n    for alg_name in oqs.get_enabled_sig_mechanisms():\n        if any(item in alg_name for item in disabled_sig_patterns):\n            continue\n        yield check_wrong_signature, alg_name\ndef check_wrong_signature(alg_name: str) -> None:\n    with oqs.Signature(alg_name) as sig:\n        message = bytes(random.getrandbits(8) for _ in range(100))\n        public_key = sig.generate_keypair()\n        signature = sig.sign(message)",
        "detail": "liboqs-python.tests.test_sig",
        "documentation": {}
    },
    {
        "label": "check_wrong_signature",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_sig",
        "description": "liboqs-python.tests.test_sig",
        "peekOfCode": "def check_wrong_signature(alg_name: str) -> None:\n    with oqs.Signature(alg_name) as sig:\n        message = bytes(random.getrandbits(8) for _ in range(100))\n        public_key = sig.generate_keypair()\n        signature = sig.sign(message)\n        wrong_signature = bytes(random.getrandbits(8) for _ in range(len(signature)))\n        assert not (sig.verify(message, wrong_signature, public_key))  # noqa: S101\ndef test_wrong_public_key() -> tuple[None, str]:\n    for alg_name in oqs.get_enabled_sig_mechanisms():\n        if any(item in alg_name for item in disabled_sig_patterns):",
        "detail": "liboqs-python.tests.test_sig",
        "documentation": {}
    },
    {
        "label": "test_wrong_public_key",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_sig",
        "description": "liboqs-python.tests.test_sig",
        "peekOfCode": "def test_wrong_public_key() -> tuple[None, str]:\n    for alg_name in oqs.get_enabled_sig_mechanisms():\n        if any(item in alg_name for item in disabled_sig_patterns):\n            continue\n        yield check_wrong_public_key, alg_name\ndef check_wrong_public_key(alg_name: str) -> None:\n    with oqs.Signature(alg_name) as sig:\n        message = bytes(random.getrandbits(8) for _ in range(100))\n        public_key = sig.generate_keypair()\n        signature = sig.sign(message)",
        "detail": "liboqs-python.tests.test_sig",
        "documentation": {}
    },
    {
        "label": "check_wrong_public_key",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_sig",
        "description": "liboqs-python.tests.test_sig",
        "peekOfCode": "def check_wrong_public_key(alg_name: str) -> None:\n    with oqs.Signature(alg_name) as sig:\n        message = bytes(random.getrandbits(8) for _ in range(100))\n        public_key = sig.generate_keypair()\n        signature = sig.sign(message)\n        wrong_public_key = bytes(random.getrandbits(8) for _ in range(len(public_key)))\n        assert not (sig.verify(message, signature, wrong_public_key))  # noqa: S101\ndef test_not_supported() -> None:\n    try:\n        with oqs.Signature(\"unsupported_sig\"):",
        "detail": "liboqs-python.tests.test_sig",
        "documentation": {}
    },
    {
        "label": "test_not_supported",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_sig",
        "description": "liboqs-python.tests.test_sig",
        "peekOfCode": "def test_not_supported() -> None:\n    try:\n        with oqs.Signature(\"unsupported_sig\"):\n            pass\n    except oqs.MechanismNotSupportedError:\n        pass\n    except Exception as ex:\n        msg = f\"An unexpected exception was raised: {ex}\"\n        raise AssertionError(msg) from ex\n    else:",
        "detail": "liboqs-python.tests.test_sig",
        "documentation": {}
    },
    {
        "label": "test_not_enabled",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_sig",
        "description": "liboqs-python.tests.test_sig",
        "peekOfCode": "def test_not_enabled() -> None:\n    for alg_name in oqs.get_supported_sig_mechanisms():\n        if alg_name not in oqs.get_enabled_sig_mechanisms():\n            # Found a non-enabled but supported alg\n            try:\n                with oqs.Signature(alg_name):\n                    pass\n            except oqs.MechanismNotEnabledError:\n                pass\n            except Exception as ex:",
        "detail": "liboqs-python.tests.test_sig",
        "documentation": {}
    },
    {
        "label": "test_python_attributes",
        "kind": 2,
        "importPath": "liboqs-python.tests.test_sig",
        "description": "liboqs-python.tests.test_sig",
        "peekOfCode": "def test_python_attributes() -> None:\n    for alg_name in oqs.get_enabled_sig_mechanisms():\n        with oqs.Signature(alg_name) as sig:\n            if sig.method_name.decode() != alg_name:\n                msg = \"Incorrect oqs.Signature.method_name\"\n                raise AssertionError(msg)\n            if sig.alg_version is None:\n                msg = \"Undefined oqs.Signature.alg_version\"\n                raise AssertionError(msg)\n            if not 1 <= sig.claimed_nist_level <= 5:",
        "detail": "liboqs-python.tests.test_sig",
        "documentation": {}
    },
    {
        "label": "disabled_sig_patterns",
        "kind": 5,
        "importPath": "liboqs-python.tests.test_sig",
        "description": "liboqs-python.tests.test_sig",
        "peekOfCode": "disabled_sig_patterns = []\nif platform.system() == \"Windows\":\n    disabled_sig_patterns = [\"\"]\ndef test_correctness() -> tuple[None, str]:\n    for alg_name in oqs.get_enabled_sig_mechanisms():\n        if any(item in alg_name for item in disabled_sig_patterns):\n            continue\n        yield check_correctness, alg_name\ndef test_correctness_with_ctx_str() -> tuple[None, str]:\n    for alg_name in oqs.get_enabled_sig_mechanisms():",
        "detail": "liboqs-python.tests.test_sig",
        "documentation": {}
    },
    {
        "label": "calculate_shannon_entropy",
        "kind": 2,
        "importPath": "ahe.version6",
        "description": "ahe.version6",
        "peekOfCode": "def calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    entropy = -sum(p * math.log2(p) for p in freq.values())\n    return entropy\ndef get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +\n        str(platform.system()) +",
        "detail": "ahe.version6",
        "documentation": {}
    },
    {
        "label": "get_environment_entropy",
        "kind": 2,
        "importPath": "ahe.version6",
        "description": "ahe.version6",
        "peekOfCode": "def get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +\n        str(platform.system()) +\n        str(platform.release()) +\n        str(os.cpu_count()) +\n        str(os.getpid()) +\n        str(time.time()) +\n        str(socket.gethostname())\n    ).encode()",
        "detail": "ahe.version6",
        "documentation": {}
    },
    {
        "label": "generate_fractal_id",
        "kind": 2,
        "importPath": "ahe.version6",
        "description": "ahe.version6",
        "peekOfCode": "def generate_fractal_id() -> str:\n    now = datetime.datetime.now(datetime.UTC)\n    entropy = secrets.token_bytes(16)\n    data = f\"{now.timestamp()}_{entropy.hex()}\".encode()\n    return hashlib.blake2b(data).hexdigest()[:16]\ndef detect_anomaly(input_data: str, entropy_score: float) -> bool:\n    # Flags anomaly if entropy is suspiciously low or high OR contains suspicious chars\n    suspicious_chars = \"0123456789+/=\\n\"\n    has_suspicious_chars = any(c in input_data for c in suspicious_chars)\n    is_entropy_out_of_range = entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH",
        "detail": "ahe.version6",
        "documentation": {}
    },
    {
        "label": "detect_anomaly",
        "kind": 2,
        "importPath": "ahe.version6",
        "description": "ahe.version6",
        "peekOfCode": "def detect_anomaly(input_data: str, entropy_score: float) -> bool:\n    # Flags anomaly if entropy is suspiciously low or high OR contains suspicious chars\n    suspicious_chars = \"0123456789+/=\\n\"\n    has_suspicious_chars = any(c in input_data for c in suspicious_chars)\n    is_entropy_out_of_range = entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH\n    return has_suspicious_chars or is_entropy_out_of_range\n# === HASHING FUNCTION ===\ndef hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)\n    h.update(data)",
        "detail": "ahe.version6",
        "documentation": {}
    },
    {
        "label": "hash_stage",
        "kind": 2,
        "importPath": "ahe.version6",
        "description": "ahe.version6",
        "peekOfCode": "def hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)\n    h.update(data)\n    return h.digest()\n# === AES ENCRYPTION UTILITIES ===\ndef aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {",
        "detail": "ahe.version6",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "ahe.version6",
        "description": "ahe.version6",
        "peekOfCode": "def aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),\n        \"nonce\": urlsafe_b64encode(nonce).decode(),\n        \"tag\": urlsafe_b64encode(tag).decode()\n    }\ndef aes_decrypt(bundle: dict, key: bytes) -> str:",
        "detail": "ahe.version6",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "ahe.version6",
        "description": "ahe.version6",
        "peekOfCode": "def aes_decrypt(bundle: dict, key: bytes) -> str:\n    nonce = urlsafe_b64decode(bundle[\"nonce\"])\n    tag = urlsafe_b64decode(bundle[\"tag\"])\n    ciphertext = urlsafe_b64decode(bundle[\"ciphertext\"])\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag).decode()\n# === EXPLANATION SUMMARY ===\ndef print_explanation_summary(result: dict, message: str):\n    print(\"\\n === Detailed Explanation Summary ===\")\n    print(f\"Message length: {len(message)} characters\")",
        "detail": "ahe.version6",
        "documentation": {}
    },
    {
        "label": "print_explanation_summary",
        "kind": 2,
        "importPath": "ahe.version6",
        "description": "ahe.version6",
        "peekOfCode": "def print_explanation_summary(result: dict, message: str):\n    print(\"\\n === Detailed Explanation Summary ===\")\n    print(f\"Message length: {len(message)} characters\")\n    print(f\"Input Entropy Score: {round(result['input_entropy'], 3)}\")\n    print(f\"Anomaly Detected: {result['anomaly']}\")\n    print(f\"System Entropy Score: {round(result['system_entropy'], 3)}\")\n    print(f\"Fractal Session ID: {result['fractal_id']}\")\n    print(\"Hashing algorithms used (in order):\", [stage['algo'] for stage in result['hash_stages']])\n    print(\"Hashing stages times (seconds):\", [stage['time'] for stage in result['hash_stages']])\n    print(f\"Total encryption time: {result['total_time']} seconds\")",
        "detail": "ahe.version6",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt",
        "kind": 2,
        "importPath": "ahe.version6",
        "description": "ahe.version6",
        "peekOfCode": "def ahe_encrypt(message: str) -> dict:\n    print(\"\\n [1] Reading User Input and Calculating Entropy...\")\n    input_bytes = message.encode()\n    input_entropy = calculate_shannon_entropy(input_bytes)\n    anomaly = detect_anomaly(message, input_entropy)\n    print(f\" Input Entropy Score: {round(input_entropy, 3)}\")\n    print(f\" Anomaly Detected: {anomaly}\")\n    print(\"\\n [2] Gathering System Entropy for Key Derivation...\")\n    system_entropy = get_environment_entropy()\n    system_entropy_score = calculate_shannon_entropy(system_entropy)",
        "detail": "ahe.version6",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ahe.version6",
        "description": "ahe.version6",
        "peekOfCode": "def main():\n    print(\"\\n Adaptive Hashing Encryption v6.0 :: Fully Verbose Execution Mode ::\")\n    while True:\n        msg = input(\"\\n Enter message to encrypt (or 'exit'): \")\n        if msg.lower() == \"exit\":\n            print(\" Goodbye.\")\n            break\n        result = ahe_encrypt(msg)\n        print(\"\\n--- END OF SESSION ---\")\nif __name__ == \"__main__\":",
        "detail": "ahe.version6",
        "documentation": {}
    },
    {
        "label": "MAX_INPUT_LENGTH",
        "kind": 5,
        "importPath": "ahe.version6",
        "description": "ahe.version6",
        "peekOfCode": "MAX_INPUT_LENGTH = 4096\nENTROPY_WARN_THRESHOLD_LOW = 3.5\nENTROPY_WARN_THRESHOLD_HIGH = 4.75\nPBKDF2_ITERATIONS = 100_000  # Reduced from 200k for speed, still strong\nAES_KEY_SIZE = 32  # 256-bit AES key\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === ENTROPY UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0",
        "detail": "ahe.version6",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_LOW",
        "kind": 5,
        "importPath": "ahe.version6",
        "description": "ahe.version6",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_LOW = 3.5\nENTROPY_WARN_THRESHOLD_HIGH = 4.75\nPBKDF2_ITERATIONS = 100_000  # Reduced from 200k for speed, still strong\nAES_KEY_SIZE = 32  # 256-bit AES key\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === ENTROPY UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}",
        "detail": "ahe.version6",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_HIGH",
        "kind": 5,
        "importPath": "ahe.version6",
        "description": "ahe.version6",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_HIGH = 4.75\nPBKDF2_ITERATIONS = 100_000  # Reduced from 200k for speed, still strong\nAES_KEY_SIZE = 32  # 256-bit AES key\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === ENTROPY UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    entropy = -sum(p * math.log2(p) for p in freq.values())",
        "detail": "ahe.version6",
        "documentation": {}
    },
    {
        "label": "PBKDF2_ITERATIONS",
        "kind": 5,
        "importPath": "ahe.version6",
        "description": "ahe.version6",
        "peekOfCode": "PBKDF2_ITERATIONS = 100_000  # Reduced from 200k for speed, still strong\nAES_KEY_SIZE = 32  # 256-bit AES key\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === ENTROPY UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    entropy = -sum(p * math.log2(p) for p in freq.values())\n    return entropy",
        "detail": "ahe.version6",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "ahe.version6",
        "description": "ahe.version6",
        "peekOfCode": "AES_KEY_SIZE = 32  # 256-bit AES key\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === ENTROPY UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    entropy = -sum(p * math.log2(p) for p in freq.values())\n    return entropy\ndef get_environment_entropy() -> bytes:",
        "detail": "ahe.version6",
        "documentation": {}
    },
    {
        "label": "HASH_ALGORITHMS",
        "kind": 5,
        "importPath": "ahe.version6",
        "description": "ahe.version6",
        "peekOfCode": "HASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === ENTROPY UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    entropy = -sum(p * math.log2(p) for p in freq.values())\n    return entropy\ndef get_environment_entropy() -> bytes:\n    raw = (",
        "detail": "ahe.version6",
        "documentation": {}
    },
    {
        "label": "calculate_shannon_entropy",
        "kind": 2,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "def calculate_shannon_entropy(data: bytes) -> float:\n    \"\"\"\n    Calculate Shannon entropy of byte data.\n    Returns entropy value in bits per byte.\n    \"\"\"\n    if not data:\n        return 0.0\n    freq = {}\n    for b in data:\n        freq[b] = freq.get(b, 0) + 1",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "get_secure_entropy_bytes",
        "kind": 2,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "def get_secure_entropy_bytes(length: int = 64) -> bytes:\n    \"\"\"\n    Get cryptographically secure random bytes from OS entropy pool.\n    \"\"\"\n    return secrets.token_bytes(length)\ndef get_system_entropy() -> bytes:\n    \"\"\"\n    Collect local system entropy from device characteristics,\n    system uptime, CPU load, memory info, MAC address, and UUID.\n    \"\"\"",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "get_system_entropy",
        "kind": 2,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "def get_system_entropy() -> bytes:\n    \"\"\"\n    Collect local system entropy from device characteristics,\n    system uptime, CPU load, memory info, MAC address, and UUID.\n    \"\"\"\n    entropy_sources = []\n    # Device hostname\n    try:\n        hostname = socket.gethostname()\n        entropy_sources.append(hostname.encode())",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "generate_fractal_id",
        "kind": 2,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "def generate_fractal_id() -> str:\n    \"\"\"\n    Generate a unique fractal session ID bound to time and local entropy.\n    Non-replayable and device-bound.\n    \"\"\"\n    now = datetime.datetime.now(datetime.timezone.utc)\n    entropy = get_system_entropy()\n    data = f\"{now.timestamp()}_{entropy.hex()}\".encode()\n    fractal_hash = hashlib.blake2b(data).hexdigest()\n    return fractal_hash[:16]",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "hash_stage",
        "kind": 2,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "def hash_stage(data: bytes, algo: str) -> bytes:\n    \"\"\"\n    Hash data using specified algorithm from HASH_ALGORITHMS.\n    \"\"\"\n    hasher = hashlib.new(algo)\n    hasher.update(data)\n    return hasher.digest()\ndef aes_encrypt(message: str, key: bytes) -> dict:\n    \"\"\"\n    AES-GCM encrypt message with given key.",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "def aes_encrypt(message: str, key: bytes) -> dict:\n    \"\"\"\n    AES-GCM encrypt message with given key.\n    \"\"\"\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),\n        \"nonce\": urlsafe_b64encode(nonce).decode(),",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "def aes_decrypt(bundle: dict, key: bytes) -> str:\n    \"\"\"\n    AES-GCM decrypt ciphertext bundle with given key.\n    \"\"\"\n    nonce = urlsafe_b64decode(bundle[\"nonce\"])\n    tag = urlsafe_b64decode(bundle[\"tag\"])\n    ciphertext = urlsafe_b64decode(bundle[\"ciphertext\"])\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    plaintext = cipher.decrypt_and_verify(ciphertext, tag)\n    return plaintext.decode()",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "is_entropy_anomalous",
        "kind": 2,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "def is_entropy_anomalous(entropy_score: float) -> bool:\n    \"\"\"\n    Detect if entropy score is suspiciously low or high.\n    \"\"\"\n    if entropy_score < ENTROPY_WARN_THRESHOLD_LOW:\n        return True\n    if entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:\n        return True\n    return False\n# === CORE AHE ENCRYPTION ===",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt",
        "kind": 2,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "def ahe_encrypt(message: str) -> dict:\n    \"\"\"\n    Adaptive Hashing Encryption:\n    - Local environment entropy injected\n    - Multi-stage shuffled hashing\n    - Passwordless local key derivation\n    - AES-GCM encryption bound to environment\n    \"\"\"\n    if len(message) > MAX_INPUT_LENGTH:\n        raise ValueError(f\"Input exceeds max length of {MAX_INPUT_LENGTH} bytes\")",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "ahe_decrypt",
        "kind": 2,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "def ahe_decrypt(bundle: dict) -> str:\n    \"\"\"\n    Decrypt ciphertext bundle using environment-bound key derivation.\n    \"\"\"\n    # Decode the ahe cipher to bytes for key derivation\n    raw_key_source = urlsafe_b64decode(bundle[\"ahe_cipher\"])[:32]\n    # Regenerate system entropy for key derivation\n    system_entropy = get_system_entropy()\n    # Derive AES key with PBKDF2\n    key = PBKDF2(",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "def main():\n    print(\"\\n Adaptive Hashing Encryption Engine v5.0  Quantum-Aware, Anomaly-Flagging, Environment-Bound\")\n    while True:\n        msg = input(\"\\n Enter message to encrypt (or type 'exit' to quit): \")\n        if msg.strip().lower() == \"exit\":\n            print(\" Exiting AHE.\")\n            break\n        try:\n            result = ahe_encrypt(msg)\n            print(\"\\n AHE Cipher (hashed):\", result[\"ahe_cipher\"][:64], \"...\")",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "MAX_INPUT_LENGTH",
        "kind": 5,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "MAX_INPUT_LENGTH = 4096\nENTROPY_WARN_THRESHOLD_LOW = 2.5\nENTROPY_WARN_THRESHOLD_HIGH = 5.0\nPBKDF2_ITERATIONS = 150_000\nAES_KEY_SIZE = 32  # 256-bit AES key\nHASH_ALGORITHMS = [\n    \"sha3_512\",\n    \"blake2b\",\n    \"sha512\",\n    \"blake2s\"",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_LOW",
        "kind": 5,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_LOW = 2.5\nENTROPY_WARN_THRESHOLD_HIGH = 5.0\nPBKDF2_ITERATIONS = 150_000\nAES_KEY_SIZE = 32  # 256-bit AES key\nHASH_ALGORITHMS = [\n    \"sha3_512\",\n    \"blake2b\",\n    \"sha512\",\n    \"blake2s\"\n]",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_HIGH",
        "kind": 5,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_HIGH = 5.0\nPBKDF2_ITERATIONS = 150_000\nAES_KEY_SIZE = 32  # 256-bit AES key\nHASH_ALGORITHMS = [\n    \"sha3_512\",\n    \"blake2b\",\n    \"sha512\",\n    \"blake2s\"\n]\n# === UTILITY FUNCTIONS ===",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "PBKDF2_ITERATIONS",
        "kind": 5,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "PBKDF2_ITERATIONS = 150_000\nAES_KEY_SIZE = 32  # 256-bit AES key\nHASH_ALGORITHMS = [\n    \"sha3_512\",\n    \"blake2b\",\n    \"sha512\",\n    \"blake2s\"\n]\n# === UTILITY FUNCTIONS ===\ndef calculate_shannon_entropy(data: bytes) -> float:",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "AES_KEY_SIZE = 32  # 256-bit AES key\nHASH_ALGORITHMS = [\n    \"sha3_512\",\n    \"blake2b\",\n    \"sha512\",\n    \"blake2s\"\n]\n# === UTILITY FUNCTIONS ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    \"\"\"",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "HASH_ALGORITHMS",
        "kind": 5,
        "importPath": "ahe5",
        "description": "ahe5",
        "peekOfCode": "HASH_ALGORITHMS = [\n    \"sha3_512\",\n    \"blake2b\",\n    \"sha512\",\n    \"blake2s\"\n]\n# === UTILITY FUNCTIONS ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    \"\"\"\n    Calculate Shannon entropy of byte data.",
        "detail": "ahe5",
        "documentation": {}
    },
    {
        "label": "calculate_shannon_entropy",
        "kind": 2,
        "importPath": "ahe7.2",
        "description": "ahe7.2",
        "peekOfCode": "def calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +\n        str(platform.system()) +\n        str(platform.release()) +",
        "detail": "ahe7.2",
        "documentation": {}
    },
    {
        "label": "get_environment_entropy",
        "kind": 2,
        "importPath": "ahe7.2",
        "description": "ahe7.2",
        "peekOfCode": "def get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +\n        str(platform.system()) +\n        str(platform.release()) +\n        str(os.cpu_count()) +\n        str(os.getpid()) +\n        str(time.time()) +\n        str(socket.gethostname())\n    ).encode()",
        "detail": "ahe7.2",
        "documentation": {}
    },
    {
        "label": "generate_fractal_id",
        "kind": 2,
        "importPath": "ahe7.2",
        "description": "ahe7.2",
        "peekOfCode": "def generate_fractal_id() -> str:\n    now = datetime.datetime.now(datetime.UTC)\n    entropy = secrets.token_bytes(16)\n    return hashlib.blake2b(f\"{now.timestamp()}_{entropy.hex()}\".encode()).hexdigest()[:128]\ndef detect_anomaly_severity(input_data: str, entropy_score: float) -> tuple:\n    severity = 0.0\n    reasons = []\n    # Suspicious characters check\n    suspicious_chars = \"0123456789+/=\\n\"\n    if any(c in input_data for c in suspicious_chars):",
        "detail": "ahe7.2",
        "documentation": {}
    },
    {
        "label": "detect_anomaly_severity",
        "kind": 2,
        "importPath": "ahe7.2",
        "description": "ahe7.2",
        "peekOfCode": "def detect_anomaly_severity(input_data: str, entropy_score: float) -> tuple:\n    severity = 0.0\n    reasons = []\n    # Suspicious characters check\n    suspicious_chars = \"0123456789+/=\\n\"\n    if any(c in input_data for c in suspicious_chars):\n        severity += 3.0\n        reasons.append(\"suspicious characters detected\")\n    # Entropy deviation\n    if entropy_score < ENTROPY_WARN_THRESHOLD_LOW:",
        "detail": "ahe7.2",
        "documentation": {}
    },
    {
        "label": "hash_stage",
        "kind": 2,
        "importPath": "ahe7.2",
        "description": "ahe7.2",
        "peekOfCode": "def hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)\n    h.update(data)\n    return h.digest()\ndef aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),",
        "detail": "ahe7.2",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "ahe7.2",
        "description": "ahe7.2",
        "peekOfCode": "def aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),\n        \"nonce\": urlsafe_b64encode(nonce).decode(),\n        \"tag\": urlsafe_b64encode(tag).decode()\n    }\ndef aes_decrypt(bundle: dict, key: bytes) -> str:",
        "detail": "ahe7.2",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "ahe7.2",
        "description": "ahe7.2",
        "peekOfCode": "def aes_decrypt(bundle: dict, key: bytes) -> str:\n    nonce = urlsafe_b64decode(bundle[\"nonce\"])\n    tag = urlsafe_b64decode(bundle[\"tag\"])\n    ciphertext = urlsafe_b64decode(bundle[\"ciphertext\"])\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag).decode()\ndef adaptive_kdf(secret: bytes, salt: bytes, severity: float) -> bytes:\n    \"\"\"\n    Adaptive key derivation function selecting KDF based on anomaly severity score.\n    \"\"\"",
        "detail": "ahe7.2",
        "documentation": {}
    },
    {
        "label": "adaptive_kdf",
        "kind": 2,
        "importPath": "ahe7.2",
        "description": "ahe7.2",
        "peekOfCode": "def adaptive_kdf(secret: bytes, salt: bytes, severity: float) -> bytes:\n    \"\"\"\n    Adaptive key derivation function selecting KDF based on anomaly severity score.\n    \"\"\"\n    if severity < 3.0:\n        # Low threat: PBKDF2 fast\n        return PBKDF2(secret, salt, dkLen=AES_KEY_SIZE, count=PBKDF2_ITERATIONS_FAST, hmac_hash_module=SHA512)\n    elif severity < 7.0:\n        # Medium threat: HKDF\n        return HKDF(secret, AES_KEY_SIZE, salt, SHA512)",
        "detail": "ahe7.2",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v7_adaptive",
        "kind": 2,
        "importPath": "ahe7.2",
        "description": "ahe7.2",
        "peekOfCode": "def ahe_encrypt_v7_adaptive(message: str) -> dict:\n    print(\"\\n AHE v7.x :: Adaptive Encryption Begins\")\n    start_time = time.time()\n    # Step 1: Input entropy\n    step_start = time.time()\n    input_bytes = message.encode()\n    input_entropy = calculate_shannon_entropy(input_bytes)\n    step_time_input_entropy = time.time() - step_start\n    print(f\"1 Input entropy calculated: {input_entropy:.4f} (took {step_time_input_entropy:.6f}s)\")\n    # Step 2: System entropy",
        "detail": "ahe7.2",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ahe7.2",
        "description": "ahe7.2",
        "peekOfCode": "def main():\n    print(\"\\n Welcome to Adaptive Hashing Encryption v7.x\\n\")\n    while True:\n        command = input(\" Enter text to encrypt, 'd' to decrypt, or 'exit': \").strip()\n        if command.lower() == \"exit\":\n            print(\" Exiting.\")\n            break\n        elif command.lower() == \"d\":\n            print(\" Decryption mode (manual input)...\")\n            try:",
        "detail": "ahe7.2",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_LOW",
        "kind": 5,
        "importPath": "ahe7.2",
        "description": "ahe7.2",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_LOW = 3.5\nENTROPY_WARN_THRESHOLD_HIGH = 4.75\nPBKDF2_ITERATIONS_FAST = 100_000\nPBKDF2_ITERATIONS_SLOW = 500_000\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0",
        "detail": "ahe7.2",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_HIGH",
        "kind": 5,
        "importPath": "ahe7.2",
        "description": "ahe7.2",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_HIGH = 4.75\nPBKDF2_ITERATIONS_FAST = 100_000\nPBKDF2_ITERATIONS_SLOW = 500_000\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}",
        "detail": "ahe7.2",
        "documentation": {}
    },
    {
        "label": "PBKDF2_ITERATIONS_FAST",
        "kind": 5,
        "importPath": "ahe7.2",
        "description": "ahe7.2",
        "peekOfCode": "PBKDF2_ITERATIONS_FAST = 100_000\nPBKDF2_ITERATIONS_SLOW = 500_000\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())",
        "detail": "ahe7.2",
        "documentation": {}
    },
    {
        "label": "PBKDF2_ITERATIONS_SLOW",
        "kind": 5,
        "importPath": "ahe7.2",
        "description": "ahe7.2",
        "peekOfCode": "PBKDF2_ITERATIONS_SLOW = 500_000\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:",
        "detail": "ahe7.2",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "ahe7.2",
        "description": "ahe7.2",
        "peekOfCode": "AES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (",
        "detail": "ahe7.2",
        "documentation": {}
    },
    {
        "label": "HASH_ALGORITHMS",
        "kind": 5,
        "importPath": "ahe7.2",
        "description": "ahe7.2",
        "peekOfCode": "HASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +",
        "detail": "ahe7.2",
        "documentation": {}
    },
    {
        "label": "calculate_shannon_entropy",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +\n        str(platform.system()) +\n        str(platform.release()) +",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "get_environment_entropy",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +\n        str(platform.system()) +\n        str(platform.release()) +\n        str(os.cpu_count()) +\n        str(os.getpid()) +\n        str(time.time()) +\n        str(socket.gethostname())\n    ).encode()",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "detect_anomaly",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    suspicious_chars = \"0123456789+/=\\n\"\n    reasons = []\n    if any(c in input_data for c in suspicious_chars):\n        reasons.append(\"suspicious characters detected\")\n    if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:\n        reasons.append(\"entropy out of range\")\n    return (len(reasons) > 0), reasons\ndef hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "hash_stage",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)\n    h.update(data)\n    return h.digest()\ndef aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),\n        \"nonce\": urlsafe_b64encode(nonce).decode(),\n        \"tag\": urlsafe_b64encode(tag).decode()\n    }\ndef aes_decrypt(bundle: dict, key: bytes) -> str:",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def aes_decrypt(bundle: dict, key: bytes) -> str:\n    nonce = urlsafe_b64decode(bundle[\"nonce\"])\n    tag = urlsafe_b64decode(bundle[\"tag\"])\n    ciphertext = urlsafe_b64decode(bundle[\"ciphertext\"])\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag).decode()\n# === Key Derivation Functions ===\ndef derive_key_argon2(password: bytes, salt: bytes) -> bytes:\n    return hash_secret_raw(\n        secret=password,",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "derive_key_argon2",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def derive_key_argon2(password: bytes, salt: bytes) -> bytes:\n    return hash_secret_raw(\n        secret=password,\n        salt=salt,\n        time_cost=4,\n        memory_cost=102400,\n        parallelism=8,\n        hash_len=AES_KEY_SIZE,\n        type=Type.ID\n    )",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "derive_key_shake",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def derive_key_shake(password: bytes, salt: bytes, bits: int=256) -> bytes:\n    shake = hashlib.shake_128() if bits == 128 else hashlib.shake_256()\n    shake.update(password + salt)\n    return shake.digest(AES_KEY_SIZE)\ndef hkdf_extract(salt: bytes, input_key_material: bytes, hash_algo=hashlib.sha256) -> bytes:\n    return hmac.new(salt, input_key_material, hash_algo).digest()\ndef hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:\n    hash_len = hash_algo().digest_size\n    blocks_needed = (length + hash_len - 1) // hash_len\n    okm = b\"\"",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "hkdf_extract",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def hkdf_extract(salt: bytes, input_key_material: bytes, hash_algo=hashlib.sha256) -> bytes:\n    return hmac.new(salt, input_key_material, hash_algo).digest()\ndef hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:\n    hash_len = hash_algo().digest_size\n    blocks_needed = (length + hash_len - 1) // hash_len\n    okm = b\"\"\n    output_block = b\"\"\n    for counter in range(1, blocks_needed + 1):\n        output_block = hmac.new(prk, output_block + info + bytes([counter]), hash_algo).digest()\n        okm += output_block",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "hkdf_expand",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:\n    hash_len = hash_algo().digest_size\n    blocks_needed = (length + hash_len - 1) // hash_len\n    okm = b\"\"\n    output_block = b\"\"\n    for counter in range(1, blocks_needed + 1):\n        output_block = hmac.new(prk, output_block + info + bytes([counter]), hash_algo).digest()\n        okm += output_block\n    return okm[:length]\ndef derive_key_hkdf(password: bytes, salt: bytes) -> bytes:",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "derive_key_hkdf",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def derive_key_hkdf(password: bytes, salt: bytes) -> bytes:\n    prk = hkdf_extract(salt, password)\n    return hkdf_expand(prk, b\"AHE-HKDF\", AES_KEY_SIZE)\n# === PQC KEM Helpers ===\ndef pqc_keypair(kem_name: str):\n    kem = oqs.KeyEncapsulation(kem_name)\n    public_key = kem.generate_keypair()\n    return kem, public_key\ndef pqc_encapsulate(kem, public_key: bytes):\n    return kem.encap_secret(public_key)",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "pqc_keypair",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def pqc_keypair(kem_name: str):\n    kem = oqs.KeyEncapsulation(kem_name)\n    public_key = kem.generate_keypair()\n    return kem, public_key\ndef pqc_encapsulate(kem, public_key: bytes):\n    return kem.encap_secret(public_key)\ndef pqc_decapsulate(kem, ciphertext: bytes):\n    return kem.decap_secret(ciphertext)\n# === Hybrid Key Derivation with SHAKE-256 finalization and PQC integration ===\ndef derive_key_hybrid_with_pqc(password: bytes, salt: bytes, anomaly: bool) -> tuple:",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "pqc_encapsulate",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def pqc_encapsulate(kem, public_key: bytes):\n    return kem.encap_secret(public_key)\ndef pqc_decapsulate(kem, ciphertext: bytes):\n    return kem.decap_secret(ciphertext)\n# === Hybrid Key Derivation with SHAKE-256 finalization and PQC integration ===\ndef derive_key_hybrid_with_pqc(password: bytes, salt: bytes, anomaly: bool) -> tuple:\n    if anomaly:\n        pqc_candidates = PQC_STRONG_KEMS.copy()\n    else:\n        pqc_candidates = PQC_FAST_KEMS.copy()",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "pqc_decapsulate",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def pqc_decapsulate(kem, ciphertext: bytes):\n    return kem.decap_secret(ciphertext)\n# === Hybrid Key Derivation with SHAKE-256 finalization and PQC integration ===\ndef derive_key_hybrid_with_pqc(password: bytes, salt: bytes, anomaly: bool) -> tuple:\n    if anomaly:\n        pqc_candidates = PQC_STRONG_KEMS.copy()\n    else:\n        pqc_candidates = PQC_FAST_KEMS.copy()\n    random.shuffle(pqc_candidates)\n    if anomaly:",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "derive_key_hybrid_with_pqc",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def derive_key_hybrid_with_pqc(password: bytes, salt: bytes, anomaly: bool) -> tuple:\n    if anomaly:\n        pqc_candidates = PQC_STRONG_KEMS.copy()\n    else:\n        pqc_candidates = PQC_FAST_KEMS.copy()\n    random.shuffle(pqc_candidates)\n    if anomaly:\n        if random.choice([True, False]):\n            print(\"Anomaly detected: Using Argon2id for initial KDF\")\n            intermediate_key = derive_key_argon2(password, salt)",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "shorten_bytes_for_display",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def shorten_bytes_for_display(data: bytes, length=10):\n    if len(data) <= length:\n        return data.hex()\n    return data[:length].hex() + \"...\"\n# === AHE Core Encryption Function with PQC ===\ndef ahe_encrypt_v9_5(message: str) -> dict:\n    print(\"\\n AHE v9.5 :: Quantum Secure Adaptive Encryption Begins\")\n    total_start = time.time()\n    step_times = {}\n    step_start = time.time()",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v9_5",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def ahe_encrypt_v9_5(message: str) -> dict:\n    print(\"\\n AHE v9.5 :: Quantum Secure Adaptive Encryption Begins\")\n    total_start = time.time()\n    step_times = {}\n    step_start = time.time()\n    input_bytes = message.encode()\n    input_entropy = calculate_shannon_entropy(input_bytes)\n    step_times[\"input_entropy_calc\"] = time.time() - step_start\n    print(f\"1 Input Entropy Score: {round(input_entropy,4)} (took {step_times['input_entropy_calc']:.6f}s)\")\n    step_start = time.time()",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "ahe_decrypt_v9_5",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def ahe_decrypt_v9_5(encrypted_data: dict, private_kem: oqs.KeyEncapsulation) -> str:\n    print(\"\\n AHE v9.5 :: Quantum Secure Adaptive Decryption Begins\")\n    # Retrieve PQC ciphertext and decrypt shared secret\n    ciphertext_b64 = encrypted_data[\"pqc\"][\"ciphertext\"]\n    # For decryption, we need full ciphertext bytes; user should have saved full ciphertext\n    # Here we assume ciphertext was saved fully, not shortened, so adjust accordingly in real use\n    # This example just outlines process, you should save full ciphertext in real system\n    # Warning: Here we must get real ciphertext bytes for decapsulation\n    # This example assumes ciphertext is stored in full in encrypted_data[\"pqc\"][\"ciphertext_full\"]\n    # Adapt as needed for your storage",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "def main():\n    print(\"=== Adaptive Hashing Encryption (AHE) v9.5 ===\")\n    while True:\n        print(\"\\nChoose an option:\")\n        print(\"1. Encrypt a message\")\n        print(\"2. Exit\")\n        choice = input(\"Enter choice (1/2): \").strip()\n        if choice == \"1\":\n            message = input(\"\\nEnter message to encrypt:\\n\")\n            encrypted = ahe_encrypt_v9_5(message)",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_LOW",
        "kind": 5,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_LOW = 3.5\nENTROPY_WARN_THRESHOLD_HIGH = 4.75\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\n    \"sha256\",\n    \"sha512\",\n    \"sha3_256\",\n    \"sha3_512\"\n]\n# PQC KEM groups for selection",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_HIGH",
        "kind": 5,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_HIGH = 4.75\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\n    \"sha256\",\n    \"sha512\",\n    \"sha3_256\",\n    \"sha3_512\"\n]\n# PQC KEM groups for selection\nPQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "AES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\n    \"sha256\",\n    \"sha512\",\n    \"sha3_256\",\n    \"sha3_512\"\n]\n# PQC KEM groups for selection\nPQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\nPQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "HASH_ALGORITHMS",
        "kind": 5,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "HASH_ALGORITHMS = [\n    \"sha256\",\n    \"sha512\",\n    \"sha3_256\",\n    \"sha3_512\"\n]\n# PQC KEM groups for selection\nPQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\nPQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\n# === UTILITIES ===",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "PQC_FAST_KEMS",
        "kind": 5,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "PQC_FAST_KEMS = [\"Kyber512\", \"Kyber768\", \"ML-KEM-512\", \"ML-KEM-768\"]\nPQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "PQC_STRONG_KEMS",
        "kind": 5,
        "importPath": "ahe95",
        "description": "ahe95",
        "peekOfCode": "PQC_STRONG_KEMS = [\"Kyber1024\", \"sntrup761\", \"ML-KEM-1024\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b)/len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +",
        "detail": "ahe95",
        "documentation": {}
    },
    {
        "label": "calculate_shannon_entropy",
        "kind": 2,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "def calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    entropy = -sum(p * math.log2(p) for p in freq.values())\n    return entropy\ndef get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +\n        str(platform.system()) +",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "get_environment_entropy",
        "kind": 2,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "def get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +\n        str(platform.system()) +\n        str(platform.release()) +\n        str(os.cpu_count()) +\n        str(os.getpid()) +\n        str(time.time()) +\n        str(socket.gethostname())\n    ).encode()",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "generate_fractal_id",
        "kind": 2,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "def generate_fractal_id() -> str:\n    now = datetime.datetime.utcnow()\n    entropy = secrets.token_bytes(16)\n    data = f\"{now.timestamp()}_{entropy.hex()}\".encode()\n    return hashlib.blake2b(data).hexdigest()[:16]\ndef l_infinity_norm(values: list) -> float:\n    return max(abs(v) for v in values)\ndef detect_anomaly(input_data: str, entropy_components: dict) -> bool:\n    l_inf = l_infinity_norm(list(entropy_components.values()))\n    suspicious_chars = \"0123456789+/=\\n\"",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "l_infinity_norm",
        "kind": 2,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "def l_infinity_norm(values: list) -> float:\n    return max(abs(v) for v in values)\ndef detect_anomaly(input_data: str, entropy_components: dict) -> bool:\n    l_inf = l_infinity_norm(list(entropy_components.values()))\n    suspicious_chars = \"0123456789+/=\\n\"\n    has_suspicious_chars = any(c in input_data for c in suspicious_chars)\n    return l_inf > L_INF_THRESHOLD or has_suspicious_chars\ndef hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)\n    h.update(data)",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "detect_anomaly",
        "kind": 2,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "def detect_anomaly(input_data: str, entropy_components: dict) -> bool:\n    l_inf = l_infinity_norm(list(entropy_components.values()))\n    suspicious_chars = \"0123456789+/=\\n\"\n    has_suspicious_chars = any(c in input_data for c in suspicious_chars)\n    return l_inf > L_INF_THRESHOLD or has_suspicious_chars\ndef hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)\n    h.update(data)\n    return h.digest()\ndef aes_encrypt(message: str, key: bytes) -> dict:",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "hash_stage",
        "kind": 2,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "def hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)\n    h.update(data)\n    return h.digest()\ndef aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "def aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),\n        \"nonce\": urlsafe_b64encode(nonce).decode(),\n        \"tag\": urlsafe_b64encode(tag).decode()\n    }\ndef aes_decrypt(bundle: dict, key: bytes) -> str:",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "def aes_decrypt(bundle: dict, key: bytes) -> str:\n    nonce = urlsafe_b64decode(bundle[\"nonce\"])\n    tag = urlsafe_b64decode(bundle[\"tag\"])\n    ciphertext = urlsafe_b64decode(bundle[\"ciphertext\"])\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag).decode()\ndef max_repeat_run_score(data: str) -> float:\n    max_run = 1\n    current_run = 1\n    for i in range(1, len(data)):",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "max_repeat_run_score",
        "kind": 2,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "def max_repeat_run_score(data: str) -> float:\n    max_run = 1\n    current_run = 1\n    for i in range(1, len(data)):\n        if data[i] == data[i-1]:\n            current_run += 1\n            max_run = max(max_run, current_run)\n        else:\n            current_run = 1\n    return float(max_run)",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt",
        "kind": 2,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "def ahe_encrypt(message: str) -> dict:\n    input_bytes = message.encode()\n    input_entropy = calculate_shannon_entropy(input_bytes)\n    system_entropy = get_environment_entropy()\n    system_entropy_score = calculate_shannon_entropy(system_entropy)\n    entropy_components = {\n        \"input_entropy\": input_entropy,\n        \"system_entropy\": system_entropy_score,\n        \"repeat_char_score\": max_repeat_run_score(message),\n        \"timing_deviation\": 0  # Placeholder for timing anomalies",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "benchmark_aes",
        "kind": 2,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "def benchmark_aes(message: str) -> float:\n    key = get_random_bytes(AES_KEY_SIZE)\n    start = time.time()\n    aes_encrypt(message, key)\n    end = time.time()\n    return end - start\ndef benchmark_sha256(message: str) -> float:\n    start = time.time()\n    hashlib.sha256(message.encode()).digest()\n    end = time.time()",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "benchmark_sha256",
        "kind": 2,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "def benchmark_sha256(message: str) -> float:\n    start = time.time()\n    hashlib.sha256(message.encode()).digest()\n    end = time.time()\n    return end - start\ndef benchmark_rsa(message: str) -> float:\n    try:\n        from Crypto.PublicKey import RSA\n        from Crypto.Cipher import PKCS1_OAEP\n    except ImportError:",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "benchmark_rsa",
        "kind": 2,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "def benchmark_rsa(message: str) -> float:\n    try:\n        from Crypto.PublicKey import RSA\n        from Crypto.Cipher import PKCS1_OAEP\n    except ImportError:\n        return -1\n    key = RSA.generate(2048)\n    cipher = PKCS1_OAEP.new(key.publickey())\n    start = time.time()\n    cipher.encrypt(message.encode())",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "benchmark_pqc_kyber",
        "kind": 2,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "def benchmark_pqc_kyber(message: str):\n    if not PQC_AVAILABLE:\n        return None\n    public_key, secret_key = generate_keypair()\n    start = time.time()\n    encrypt(message.encode(), public_key)\n    end = time.time()\n    return end - start\ndef main():\n    print(\"Adaptive Hashing Encryption v7.0 - L Anomaly Detection + Benchmarking\")",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "def main():\n    print(\"Adaptive Hashing Encryption v7.0 - L Anomaly Detection + Benchmarking\")\n    if not PQC_AVAILABLE:\n        print(\n            \"pqcrypto not installed; skipping PQC benchmarks.\\n\"\n            \"Install with 'pip install pqcrypto'\"\n        )\n    while True:\n        msg = input(\"\\nEnter message to encrypt (or 'exit'): \")\n        if msg.lower() == \"exit\":",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "MAX_INPUT_LENGTH",
        "kind": 5,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "MAX_INPUT_LENGTH = 4096\nPBKDF2_ITERATIONS = 100_000\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\nL_INF_THRESHOLD = 5.0\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    entropy = -sum(p * math.log2(p) for p in freq.values())",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "PBKDF2_ITERATIONS",
        "kind": 5,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "PBKDF2_ITERATIONS = 100_000\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\nL_INF_THRESHOLD = 5.0\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    entropy = -sum(p * math.log2(p) for p in freq.values())\n    return entropy",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "AES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\nL_INF_THRESHOLD = 5.0\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    entropy = -sum(p * math.log2(p) for p in freq.values())\n    return entropy\ndef get_environment_entropy() -> bytes:",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "HASH_ALGORITHMS",
        "kind": 5,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "HASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\nL_INF_THRESHOLD = 5.0\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    entropy = -sum(p * math.log2(p) for p in freq.values())\n    return entropy\ndef get_environment_entropy() -> bytes:\n    raw = (",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "L_INF_THRESHOLD",
        "kind": 5,
        "importPath": "AHElinfity",
        "description": "AHElinfity",
        "peekOfCode": "L_INF_THRESHOLD = 5.0\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    entropy = -sum(p * math.log2(p) for p in freq.values())\n    return entropy\ndef get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +",
        "detail": "AHElinfity",
        "documentation": {}
    },
    {
        "label": "AHE",
        "kind": 6,
        "importPath": "ahesetup",
        "description": "ahesetup",
        "peekOfCode": "class AHE:\n    def _init_(self):\n        pass\n    def encrypt(self, message: str):\n        # TODO: Integrate v9.5 encryption steps here\n        return {\"status\": \"Encryption logic placeholder\"}\n    def decrypt(self, encrypted_data: dict):\n        # TODO: Integrate v9.5 decryption steps here\n        return \"Decryption logic placeholder\"\n\"\"\"",
        "detail": "ahesetup",
        "documentation": {}
    },
    {
        "label": "create_structure",
        "kind": 2,
        "importPath": "ahesetup",
        "description": "ahesetup",
        "peekOfCode": "def create_structure(base_path, structure):\n    for key, value in structure.items():\n        path = os.path.join(base_path, key)\n        os.makedirs(path, exist_ok=True)\n        for item in value:\n            if isinstance(item, str):\n                file_path = os.path.join(path, item)\n                with open(file_path, \"w\") as f:\n                    if item == \"core.py\":\n                        f.write(core_content)",
        "detail": "ahesetup",
        "documentation": {}
    },
    {
        "label": "folders",
        "kind": 5,
        "importPath": "ahesetup",
        "description": "ahesetup",
        "peekOfCode": "folders = {\n    \"AHE_SDK\": [\n        \"_init_.py\",\n        {\n            \"argon_hkdf_shake256\": [\"pqc.py\"],\n            \"constants_algorithm_lists\": [\"exceptions.py\"],\n            \"encryption_decryption\": [\"key_derivation.py\", \"pqc.py\"],\n            \"hashing_entropy_anomaly_detection\": [\"config.py\"],\n            \"main_class\": [\"core.py\"],\n            \"post_quantum_kem_logic\": [\"utils.py\", \"_init_.py\"]",
        "detail": "ahesetup",
        "documentation": {}
    },
    {
        "label": "core_content",
        "kind": 5,
        "importPath": "ahesetup",
        "description": "ahesetup",
        "peekOfCode": "core_content = \"\"\"# core.py\nfrom .utils import calculate_shannon_entropy, get_environment_entropy, detect_anomaly, hash_stage\nfrom .key_derivation import derive_key_argon2, derive_key_hkdf, derive_key_shake\nfrom .pqc import pqc_keypair, pqc_encapsulate, pqc_decapsulate\nfrom .exceptions import AHEError\nfrom .config import HASH_ALGORITHMS, AES_KEY_SIZE\nclass AHE:\n    def _init_(self):\n        pass\n    def encrypt(self, message: str):",
        "detail": "ahesetup",
        "documentation": {}
    },
    {
        "label": "derive_key",
        "kind": 2,
        "importPath": "ahev10.5.decryption",
        "description": "ahev10.5.decryption",
        "peekOfCode": "def derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    key = hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\n    print(f\"Derived key (SHA3-512 truncated): {key.hex()}\")\n    return key\ndef aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext_bytes)\n    print(f\"AES encrypt: nonce({len(nonce)} bytes), tag({len(tag)} bytes), ciphertext({len(ciphertext)} bytes)\")",
        "detail": "ahev10.5.decryption",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "ahev10.5.decryption",
        "description": "ahev10.5.decryption",
        "peekOfCode": "def aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext_bytes)\n    print(f\"AES encrypt: nonce({len(nonce)} bytes), tag({len(tag)} bytes), ciphertext({len(ciphertext)} bytes)\")\n    return ciphertext, nonce, tag\ndef aes_decrypt(ciphertext, nonce, tag, key):\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    plaintext = cipher.decrypt_and_verify(ciphertext, tag)\n    print(f\"AES decrypt successful: plaintext length {len(plaintext)} bytes\")",
        "detail": "ahev10.5.decryption",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "ahev10.5.decryption",
        "description": "ahev10.5.decryption",
        "peekOfCode": "def aes_decrypt(ciphertext, nonce, tag, key):\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    plaintext = cipher.decrypt_and_verify(ciphertext, tag)\n    print(f\"AES decrypt successful: plaintext length {len(plaintext)} bytes\")\n    return plaintext\ndef encrypt_file(filepath, password):\n    print(f\"\\n--- Encryption start for: {filepath} ---\")\n    start_time = time.time()\n    with open(filepath, \"rb\") as f:\n        plaintext = f.read()",
        "detail": "ahev10.5.decryption",
        "documentation": {}
    },
    {
        "label": "encrypt_file",
        "kind": 2,
        "importPath": "ahev10.5.decryption",
        "description": "ahev10.5.decryption",
        "peekOfCode": "def encrypt_file(filepath, password):\n    print(f\"\\n--- Encryption start for: {filepath} ---\")\n    start_time = time.time()\n    with open(filepath, \"rb\") as f:\n        plaintext = f.read()\n    print(f\"Read plaintext: {len(plaintext)} bytes\")\n    kem_name = random.choice(PQC_KEMS)\n    print(f\"Selected PQC KEM: {kem_name}\")\n    kem = oqs.KeyEncapsulation(kem_name)\n    pubkey = kem.generate_keypair()",
        "detail": "ahev10.5.decryption",
        "documentation": {}
    },
    {
        "label": "decrypt_file",
        "kind": 2,
        "importPath": "ahev10.5.decryption",
        "description": "ahev10.5.decryption",
        "peekOfCode": "def decrypt_file(enc_path, password):\n    print(f\"\\n--- Decryption start for: {enc_path} ---\")\n    start_time = time.time()\n    meta_path = enc_path.replace(ENC_EXT, META_EXT)\n    if not os.path.exists(meta_path):\n        raise FileNotFoundError(f\"Metadata file not found: {meta_path}\")\n    print(f\"Found metadata file: {meta_path}\")\n    with open(enc_path, \"rb\") as f:\n        ciphertext = f.read()\n    print(f\"Read ciphertext: {len(ciphertext)} bytes\")",
        "detail": "ahev10.5.decryption",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ahev10.5.decryption",
        "description": "ahev10.5.decryption",
        "peekOfCode": "def main():\n    print(\"=== Adaptive Hashing Encryption v10.5 with Metrics ===\")\n    while True:\n        print(\"\\nOptions:\")\n        print(\"1. Encrypt a file\")\n        print(\"2. Decrypt a file\")\n        print(\"3. Exit\")\n        choice = input(\"Choice: \").strip()\n        if choice == \"1\":\n            path = input(\"File to encrypt: \").strip()",
        "detail": "ahev10.5.decryption",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "ahev10.5.decryption",
        "description": "ahev10.5.decryption",
        "peekOfCode": "AES_KEY_SIZE = 32\nMETA_EXT = \".meta\"\nENC_EXT = \".ahe\"\nPQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\ndef derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    key = hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\n    print(f\"Derived key (SHA3-512 truncated): {key.hex()}\")\n    return key\ndef aes_encrypt(plaintext_bytes, key):",
        "detail": "ahev10.5.decryption",
        "documentation": {}
    },
    {
        "label": "META_EXT",
        "kind": 5,
        "importPath": "ahev10.5.decryption",
        "description": "ahev10.5.decryption",
        "peekOfCode": "META_EXT = \".meta\"\nENC_EXT = \".ahe\"\nPQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\ndef derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    key = hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\n    print(f\"Derived key (SHA3-512 truncated): {key.hex()}\")\n    return key\ndef aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)",
        "detail": "ahev10.5.decryption",
        "documentation": {}
    },
    {
        "label": "ENC_EXT",
        "kind": 5,
        "importPath": "ahev10.5.decryption",
        "description": "ahev10.5.decryption",
        "peekOfCode": "ENC_EXT = \".ahe\"\nPQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\ndef derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    key = hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\n    print(f\"Derived key (SHA3-512 truncated): {key.hex()}\")\n    return key\ndef aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)",
        "detail": "ahev10.5.decryption",
        "documentation": {}
    },
    {
        "label": "PQC_KEMS",
        "kind": 5,
        "importPath": "ahev10.5.decryption",
        "description": "ahev10.5.decryption",
        "peekOfCode": "PQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\ndef derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    key = hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\n    print(f\"Derived key (SHA3-512 truncated): {key.hex()}\")\n    return key\ndef aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext_bytes)",
        "detail": "ahev10.5.decryption",
        "documentation": {}
    },
    {
        "label": "derive_key",
        "kind": 2,
        "importPath": "ahev10",
        "description": "ahev10",
        "peekOfCode": "def derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    return hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\ndef aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext_bytes)\n    return ciphertext, nonce, tag\ndef aes_decrypt(ciphertext, nonce, tag, key):\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)",
        "detail": "ahev10",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "ahev10",
        "description": "ahev10",
        "peekOfCode": "def aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext_bytes)\n    return ciphertext, nonce, tag\ndef aes_decrypt(ciphertext, nonce, tag, key):\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag)\ndef encrypt_file(filepath, password):\n    with open(filepath, \"rb\") as f:",
        "detail": "ahev10",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "ahev10",
        "description": "ahev10",
        "peekOfCode": "def aes_decrypt(ciphertext, nonce, tag, key):\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag)\ndef encrypt_file(filepath, password):\n    with open(filepath, \"rb\") as f:\n        plaintext = f.read()\n    kem_name = random.choice(PQC_KEMS)\n    kem = oqs.KeyEncapsulation(kem_name)\n    pubkey = kem.generate_keypair()\n    ciphertext_kem, shared_secret = kem.encap_secret(pubkey)",
        "detail": "ahev10",
        "documentation": {}
    },
    {
        "label": "encrypt_file",
        "kind": 2,
        "importPath": "ahev10",
        "description": "ahev10",
        "peekOfCode": "def encrypt_file(filepath, password):\n    with open(filepath, \"rb\") as f:\n        plaintext = f.read()\n    kem_name = random.choice(PQC_KEMS)\n    kem = oqs.KeyEncapsulation(kem_name)\n    pubkey = kem.generate_keypair()\n    ciphertext_kem, shared_secret = kem.encap_secret(pubkey)\n    key = derive_key(password.encode(), pubkey, ciphertext_kem)\n    ciphertext, nonce, tag = aes_encrypt(plaintext, key)\n    out_enc_path = filepath + ENC_EXT",
        "detail": "ahev10",
        "documentation": {}
    },
    {
        "label": "decrypt_file",
        "kind": 2,
        "importPath": "ahev10",
        "description": "ahev10",
        "peekOfCode": "def decrypt_file(enc_path, password):\n    meta_path = enc_path.replace(ENC_EXT, META_EXT)\n    if not os.path.exists(meta_path):\n        raise FileNotFoundError(f\"Metadata file not found: {meta_path}\")\n    with open(enc_path, \"rb\") as f:\n        ciphertext = f.read()\n    with open(meta_path, \"rb\") as f:\n        lines = f.read().splitlines()\n        nonce = urlsafe_b64decode(lines[0])\n        tag = urlsafe_b64decode(lines[1])",
        "detail": "ahev10",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ahev10",
        "description": "ahev10",
        "peekOfCode": "def main():\n    print(\"=== Adaptive Hashing Encryption v10.5 ===\")\n    while True:\n        print(\"\\nOptions:\")\n        print(\"1. Encrypt a file\")\n        print(\"2. Decrypt a file\")\n        print(\"3. Exit\")\n        choice = input(\"Choice: \").strip()\n        if choice == \"1\":\n            path = input(\"File to encrypt: \").strip()",
        "detail": "ahev10",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "ahev10",
        "description": "ahev10",
        "peekOfCode": "AES_KEY_SIZE = 32\nMETA_EXT = \".meta\"\nENC_EXT = \".ahe\"\nPQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\ndef derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    return hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\ndef aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)",
        "detail": "ahev10",
        "documentation": {}
    },
    {
        "label": "META_EXT",
        "kind": 5,
        "importPath": "ahev10",
        "description": "ahev10",
        "peekOfCode": "META_EXT = \".meta\"\nENC_EXT = \".ahe\"\nPQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\ndef derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    return hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\ndef aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext_bytes)",
        "detail": "ahev10",
        "documentation": {}
    },
    {
        "label": "ENC_EXT",
        "kind": 5,
        "importPath": "ahev10",
        "description": "ahev10",
        "peekOfCode": "ENC_EXT = \".ahe\"\nPQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\ndef derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    return hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\ndef aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext_bytes)\n    return ciphertext, nonce, tag",
        "detail": "ahev10",
        "documentation": {}
    },
    {
        "label": "PQC_KEMS",
        "kind": 5,
        "importPath": "ahev10",
        "description": "ahev10",
        "peekOfCode": "PQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\ndef derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    return hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\ndef aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext_bytes)\n    return ciphertext, nonce, tag\ndef aes_decrypt(ciphertext, nonce, tag, key):",
        "detail": "ahev10",
        "documentation": {}
    },
    {
        "label": "calculate_shannon_entropy",
        "kind": 2,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "def calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +\n        str(platform.system()) +\n        str(platform.release()) +",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "get_environment_entropy",
        "kind": 2,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "def get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +\n        str(platform.system()) +\n        str(platform.release()) +\n        str(os.cpu_count()) +\n        str(os.getpid()) +\n        str(time.time()) +\n        str(socket.gethostname())\n    ).encode()",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "generate_fractal_id",
        "kind": 2,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "def generate_fractal_id() -> str:\n    now = datetime.datetime.now(datetime.UTC)\n    entropy = secrets.token_bytes(16)\n    return hashlib.blake2b(f\"{now.timestamp()}_{entropy.hex()}\".encode()).hexdigest()[:65]\ndef detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    suspicious_chars = \"0123456789+/=\\n\"\n    reasons = []\n    if any(c in input_data for c in suspicious_chars):\n        reasons.append(\"suspicious characters detected\")\n    if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "detect_anomaly",
        "kind": 2,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "def detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    suspicious_chars = \"0123456789+/=\\n\"\n    reasons = []\n    if any(c in input_data for c in suspicious_chars):\n        reasons.append(\"suspicious characters detected\")\n    if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:\n        reasons.append(\"entropy out of range\")\n    return (len(reasons) > 0), reasons\ndef hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "hash_stage",
        "kind": 2,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "def hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)\n    h.update(data)\n    return h.digest()\ndef aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "def aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),\n        \"nonce\": urlsafe_b64encode(nonce).decode(),\n        \"tag\": urlsafe_b64encode(tag).decode()\n    }\ndef aes_decrypt(bundle: dict, key: bytes) -> str:",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "def aes_decrypt(bundle: dict, key: bytes) -> str:\n    nonce = urlsafe_b64decode(bundle[\"nonce\"])\n    tag = urlsafe_b64decode(bundle[\"tag\"])\n    ciphertext = urlsafe_b64decode(bundle[\"ciphertext\"])\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag).decode()\n# === Adaptive Key Derivation Functions ===\ndef derive_key_pbkdf2(password: bytes, salt: bytes) -> bytes:\n    return PBKDF2(password, salt, dkLen=AES_KEY_SIZE, count=PBKDF2_ITERATIONS, hmac_hash_module=SHA512)\ndef derive_key_hkdf(password: bytes, salt: bytes) -> bytes:",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "derive_key_pbkdf2",
        "kind": 2,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "def derive_key_pbkdf2(password: bytes, salt: bytes) -> bytes:\n    return PBKDF2(password, salt, dkLen=AES_KEY_SIZE, count=PBKDF2_ITERATIONS, hmac_hash_module=SHA512)\ndef derive_key_hkdf(password: bytes, salt: bytes) -> bytes:\n    return HKDF(password, AES_KEY_SIZE, salt, SHA256)\ndef derive_key_argon2(password: bytes, salt: bytes) -> bytes:\n    return hash_secret_raw(\n        secret=password,\n        salt=salt,\n        time_cost=4,\n        memory_cost=102400,",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "derive_key_hkdf",
        "kind": 2,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "def derive_key_hkdf(password: bytes, salt: bytes) -> bytes:\n    return HKDF(password, AES_KEY_SIZE, salt, SHA256)\ndef derive_key_argon2(password: bytes, salt: bytes) -> bytes:\n    return hash_secret_raw(\n        secret=password,\n        salt=salt,\n        time_cost=4,\n        memory_cost=102400,\n        parallelism=8,\n        hash_len=AES_KEY_SIZE,",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "derive_key_argon2",
        "kind": 2,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "def derive_key_argon2(password: bytes, salt: bytes) -> bytes:\n    return hash_secret_raw(\n        secret=password,\n        salt=salt,\n        time_cost=4,\n        memory_cost=102400,\n        parallelism=8,\n        hash_len=AES_KEY_SIZE,\n        type=Type.ID\n    )",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v8",
        "kind": 2,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "def ahe_encrypt_v8(message: str) -> dict:\n    print(\"\\n AHE v8 :: Adaptive Encryption Begins\")\n    start_time = time.time()\n    print(\"1 Reading user input and calculating input entropy...\")\n    t1 = time.time()\n    input_bytes = message.encode()\n    input_entropy = calculate_shannon_entropy(input_bytes)\n    t1_elapsed = time.time() - t1\n    print(f\"    Input Entropy Score: {round(input_entropy, 4)} (Calculated in {t1_elapsed:.6f}s)\")\n    print(\"2 Collecting system entropy for chrono-harmonic behavior...\")",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "def main():\n    print(\"\\n Welcome to Adaptive Hashing Encryption v8\\n\")\n    last_result = None\n    while True:\n        command = input(\" Enter text to encrypt, 'd' to decrypt last message, or 'exit': \").strip()\n        if command.lower() == \"exit\":\n            print(\" Exiting.\")\n            break\n        elif command.lower() == \"d\":\n            if not last_result:",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_LOW",
        "kind": 5,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_LOW = 3.5\nENTROPY_WARN_THRESHOLD_HIGH = 4.75\nPBKDF2_ITERATIONS = 100_000\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_HIGH",
        "kind": 5,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_HIGH = 4.75\nPBKDF2_ITERATIONS = 100_000\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "PBKDF2_ITERATIONS",
        "kind": 5,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "PBKDF2_ITERATIONS = 100_000\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "AES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "HASH_ALGORITHMS",
        "kind": 5,
        "importPath": "ahev8.1",
        "description": "ahev8.1",
        "peekOfCode": "HASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +",
        "detail": "ahev8.1",
        "documentation": {}
    },
    {
        "label": "calculate_shannon_entropy",
        "kind": 2,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "def calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +\n        str(platform.system()) +\n        str(platform.release()) +",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "get_environment_entropy",
        "kind": 2,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "def get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +\n        str(platform.system()) +\n        str(platform.release()) +\n        str(os.cpu_count()) +\n        str(os.getpid()) +\n        str(time.time()) +\n        str(socket.gethostname())\n    ).encode()",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "generate_fractal_id",
        "kind": 2,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "def generate_fractal_id() -> str:\n    now = datetime.datetime.now(datetime.UTC)\n    entropy = secrets.token_bytes(16)\n    return hashlib.blake2b(f\"{now.timestamp()}_{entropy.hex()}\".encode()).hexdigest()[:64+1]\ndef detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    suspicious_chars = \"0123456789+/=\\n\"\n    reasons = []\n    if any(c in input_data for c in suspicious_chars):\n        reasons.append(\"suspicious characters detected\")\n    if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "detect_anomaly",
        "kind": 2,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "def detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    suspicious_chars = \"0123456789+/=\\n\"\n    reasons = []\n    if any(c in input_data for c in suspicious_chars):\n        reasons.append(\"suspicious characters detected\")\n    if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:\n        reasons.append(\"entropy out of range\")\n    return (len(reasons) > 0), reasons\ndef hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "hash_stage",
        "kind": 2,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "def hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)\n    h.update(data)\n    return h.digest()\ndef aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "def aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),\n        \"nonce\": urlsafe_b64encode(nonce).decode(),\n        \"tag\": urlsafe_b64encode(tag).decode()\n    }\ndef aes_decrypt(bundle: dict, key: bytes) -> str:",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "def aes_decrypt(bundle: dict, key: bytes) -> str:\n    nonce = urlsafe_b64decode(bundle[\"nonce\"])\n    tag = urlsafe_b64decode(bundle[\"tag\"])\n    ciphertext = urlsafe_b64decode(bundle[\"ciphertext\"])\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag).decode()\n# === Adaptive Key Derivation Functions ===\ndef derive_key_pbkdf2(password: bytes, salt: bytes) -> bytes:\n    return PBKDF2(password, salt, dkLen=AES_KEY_SIZE, count=PBKDF2_ITERATIONS, hmac_hash_module=SHA512)\ndef derive_key_hkdf(password: bytes, salt: bytes) -> bytes:",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "derive_key_pbkdf2",
        "kind": 2,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "def derive_key_pbkdf2(password: bytes, salt: bytes) -> bytes:\n    return PBKDF2(password, salt, dkLen=AES_KEY_SIZE, count=PBKDF2_ITERATIONS, hmac_hash_module=SHA512)\ndef derive_key_hkdf(password: bytes, salt: bytes) -> bytes:\n    return HKDF(password, AES_KEY_SIZE, salt, SHA256)\ndef derive_key_argon2(password: bytes, salt: bytes) -> bytes:\n    # Real Argon2id key derivation - secure and memory hard\n    return hash_secret_raw(\n        secret=password,\n        salt=salt,\n        time_cost=4,         # adjustable: increase for higher security / slower performance",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "derive_key_hkdf",
        "kind": 2,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "def derive_key_hkdf(password: bytes, salt: bytes) -> bytes:\n    return HKDF(password, AES_KEY_SIZE, salt, SHA256)\ndef derive_key_argon2(password: bytes, salt: bytes) -> bytes:\n    # Real Argon2id key derivation - secure and memory hard\n    return hash_secret_raw(\n        secret=password,\n        salt=salt,\n        time_cost=4,         # adjustable: increase for higher security / slower performance\n        memory_cost=102400,  # in kibibytes (100 MiB here)\n        parallelism=8,",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "derive_key_argon2",
        "kind": 2,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "def derive_key_argon2(password: bytes, salt: bytes) -> bytes:\n    # Real Argon2id key derivation - secure and memory hard\n    return hash_secret_raw(\n        secret=password,\n        salt=salt,\n        time_cost=4,         # adjustable: increase for higher security / slower performance\n        memory_cost=102400,  # in kibibytes (100 MiB here)\n        parallelism=8,\n        hash_len=AES_KEY_SIZE,\n        type=Type.ID",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v8",
        "kind": 2,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "def ahe_encrypt_v8(message: str) -> dict:\n    print(\"\\n AHE v8 :: Adaptive Encryption Begins\")\n    start_time = time.time()\n    print(\"1 Reading user input and calculating input entropy...\")\n    t1 = time.time()\n    input_bytes = message.encode()\n    input_entropy = calculate_shannon_entropy(input_bytes)\n    t1_elapsed = time.time() - t1\n    print(f\"    Input Entropy Score: {round(input_entropy, 4)} (Calculated in {t1_elapsed:.6f}s)\")\n    print(\"2 Collecting system entropy for chrono-harmonic behavior...\")",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "def main():\n    print(\"\\n Welcome to Adaptive Hashing Encryption v8\\n\")\n    while True:\n        command = input(\" Enter text to encrypt, 'd' to decrypt, or 'exit': \").strip()\n        if command.lower() == \"exit\":\n            print(\" Exiting.\")\n            break\n        elif command.lower() == \"d\":\n            print(\" Decryption mode (manual input)...\")\n            aes_bundle = eval(input(\"    AES Bundle (as dict): \"))",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_LOW",
        "kind": 5,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_LOW = 3.5\nENTROPY_WARN_THRESHOLD_HIGH = 4.75\nPBKDF2_ITERATIONS = 100_000\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_HIGH",
        "kind": 5,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_HIGH = 4.75\nPBKDF2_ITERATIONS = 100_000\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "PBKDF2_ITERATIONS",
        "kind": 5,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "PBKDF2_ITERATIONS = 100_000\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "AES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "HASH_ALGORITHMS",
        "kind": 5,
        "importPath": "ahev8",
        "description": "ahev8",
        "peekOfCode": "HASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +",
        "detail": "ahev8",
        "documentation": {}
    },
    {
        "label": "calculate_shannon_entropy",
        "kind": 2,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "def calculate_shannon_entropy(data: bytes) -> float:  \n    if not data:  \n        return 0.0  \n    freq = {b: data.count(b) / len(data) for b in set(data)}  \n    return -sum(p * math.log2(p) for p in freq.values())  \ndef get_environment_entropy() -> bytes:  \n    raw = (  \n        str(uuid.getnode()) +  \n        str(platform.system()) +  \n        str(platform.release()) +  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "get_environment_entropy",
        "kind": 2,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "def get_environment_entropy() -> bytes:  \n    raw = (  \n        str(uuid.getnode()) +  \n        str(platform.system()) +  \n        str(platform.release()) +  \n        str(os.cpu_count()) +  \n        str(os.getpid()) +  \n        str(time.time()) +  \n        str(socket.gethostname())  \n    ).encode()  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "generate_fractal_id",
        "kind": 2,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "def generate_fractal_id() -> str:  \n    now = datetime.datetime.now(datetime.timezone.utc)  \n    entropy = secrets.token_bytes(16)  \n    return hashlib.sha3_512(f\"{now.timestamp()}_{entropy.hex()}\".encode()).hexdigest()[:65]  \ndef detect_anomaly(input_data: str, entropy_score: float) -> tuple:  \n    suspicious_chars = \"0123456789+/=\\n\"  \n    reasons = []  \n    if any(c in input_data for c in suspicious_chars):  \n        reasons.append(\"suspicious characters detected\")  \n    if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "detect_anomaly",
        "kind": 2,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "def detect_anomaly(input_data: str, entropy_score: float) -> tuple:  \n    suspicious_chars = \"0123456789+/=\\n\"  \n    reasons = []  \n    if any(c in input_data for c in suspicious_chars):  \n        reasons.append(\"suspicious characters detected\")  \n    if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:  \n        reasons.append(\"entropy out of range\")  \n    return (len(reasons) > 0), reasons  \ndef hash_stage(data: bytes, algo: str) -> bytes:  \n    h = hashlib.new(algo)  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "hash_stage",
        "kind": 2,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "def hash_stage(data: bytes, algo: str) -> bytes:  \n    h = hashlib.new(algo)  \n    h.update(data)  \n    return h.digest()  \ndef aes_encrypt(message: str, key: bytes) -> dict:  \n    nonce = get_random_bytes(12)  \n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)  \n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())  \n    return {  \n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "def aes_encrypt(message: str, key: bytes) -> dict:  \n    nonce = get_random_bytes(12)  \n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)  \n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())  \n    return {  \n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),  \n        \"nonce\": urlsafe_b64encode(nonce).decode(),  \n        \"tag\": urlsafe_b64encode(tag).decode()  \n    }  \ndef aes_decrypt(bundle: dict, key: bytes) -> str:  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "def aes_decrypt(bundle: dict, key: bytes) -> str:  \n    nonce = urlsafe_b64decode(bundle[\"nonce\"])  \n    tag = urlsafe_b64decode(bundle[\"tag\"])  \n    ciphertext = urlsafe_b64decode(bundle[\"ciphertext\"])  \n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)  \n    return cipher.decrypt_and_verify(ciphertext, tag).decode()  \n# === Key Derivation Functions ===  \ndef derive_key_argon2(password: bytes, salt: bytes) -> bytes:  \n    return hash_secret_raw(  \n        secret=password,  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "derive_key_argon2",
        "kind": 2,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "def derive_key_argon2(password: bytes, salt: bytes) -> bytes:  \n    return hash_secret_raw(  \n        secret=password,  \n        salt=salt,  \n        time_cost=4,  \n        memory_cost=102400,  \n        parallelism=8,  \n        hash_len=AES_KEY_SIZE,  \n        type=Type.ID  \n    )  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "derive_key_shake",
        "kind": 2,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "def derive_key_shake(password: bytes, salt: bytes, bits: int = 256) -> bytes:  \n    shake = hashlib.shake_128() if bits == 128 else hashlib.shake_256()  \n    shake.update(password + salt)  \n    return shake.digest(AES_KEY_SIZE)  \ndef hkdf_extract(salt: bytes, input_key_material: bytes, hash_algo=hashlib.sha256) -> bytes:  \n    return hmac.new(salt, input_key_material, hash_algo).digest()  \ndef hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:  \n    hash_len = hash_algo().digest_size  \n    blocks_needed = (length + hash_len - 1) // hash_len  \n    okm = b\"\"  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "hkdf_extract",
        "kind": 2,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "def hkdf_extract(salt: bytes, input_key_material: bytes, hash_algo=hashlib.sha256) -> bytes:  \n    return hmac.new(salt, input_key_material, hash_algo).digest()  \ndef hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:  \n    hash_len = hash_algo().digest_size  \n    blocks_needed = (length + hash_len - 1) // hash_len  \n    okm = b\"\"  \n    output_block = b\"\"  \n    for counter in range(1, blocks_needed + 1):  \n        output_block = hmac.new(prk, output_block + info + bytes([counter]), hash_algo).digest()  \n        okm += output_block  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "hkdf_expand",
        "kind": 2,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "def hkdf_expand(prk: bytes, info: bytes, length: int, hash_algo=hashlib.sha256) -> bytes:  \n    hash_len = hash_algo().digest_size  \n    blocks_needed = (length + hash_len - 1) // hash_len  \n    okm = b\"\"  \n    output_block = b\"\"  \n    for counter in range(1, blocks_needed + 1):  \n        output_block = hmac.new(prk, output_block + info + bytes([counter]), hash_algo).digest()  \n        okm += output_block  \n    return okm[:length]  \ndef derive_key_hkdf(password: bytes, salt: bytes) -> bytes:  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "derive_key_hkdf",
        "kind": 2,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "def derive_key_hkdf(password: bytes, salt: bytes) -> bytes:  \n    prk = hkdf_extract(salt, password)  \n    return hkdf_expand(prk, b\"AHE-HKDF\", AES_KEY_SIZE)  \n# === Hybrid Key Derivation with SHAKE-256 finalization and timing ===  \ndef derive_key_hybrid(password: bytes, salt: bytes, anomaly: bool) -> tuple:  \n    timings = {}  \n    if anomaly:  \n        if random.choice([True, False]):  \n            start = time.time()  \n            print(\"Anomaly detected: Using Argon2id for initial KDF\")  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "derive_key_hybrid",
        "kind": 2,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "def derive_key_hybrid(password: bytes, salt: bytes, anomaly: bool) -> tuple:  \n    timings = {}  \n    if anomaly:  \n        if random.choice([True, False]):  \n            start = time.time()  \n            print(\"Anomaly detected: Using Argon2id for initial KDF\")  \n            intermediate_key = derive_key_argon2(password, salt)  \n            timings[\"argon2id\"] = time.time() - start  \n        else:  \n            bits = random.choice([128, 256])  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v9_1",
        "kind": 2,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "def ahe_encrypt_v9_1(message: str) -> dict:  \n    print(\"\\n AHE v9.1 :: Quantum Secure Adaptive Encryption Begins\")  \n    start_time = time.time()  \n    print(\"1 Reading user input and calculating input entropy...\")  \n    t1 = time.time()  \n    input_bytes = message.encode()  \n    input_entropy = calculate_shannon_entropy(input_bytes)  \n    t1_elapsed = time.time() - t1  \n    print(f\"    Input Entropy Score: {round(input_entropy, 4)} (Calculated in {t1_elapsed:.6f}s)\")  \n    print(\"2 Collecting system entropy for chrono-harmonic behavior...\")  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "def main():  \n    print(\"\\n Welcome to Adaptive Hashing Encryption v9.1\\n\")  \n    while True:  \n        command = input(\" Enter text to encrypt, 'd' to decrypt, or 'exit': \").strip()  \n        if command.lower() == \"exit\":  \n            print(\" Exiting.\")  \n            break  \n        elif command.lower() == \"d\":  \n            print(\" Decryption mode (manual input)...\")  \n            try:  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_LOW",
        "kind": 5,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_LOW = 3.5  \nENTROPY_WARN_THRESHOLD_HIGH = 4.75  \nAES_KEY_SIZE = 32  \nHASH_ALGORITHMS = [  \n    \"sha256\",  \n    \"sha512\",  \n    \"sha3_256\",  \n    \"sha3_512\"  \n]  \n# === UTILITIES ===  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_HIGH",
        "kind": 5,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_HIGH = 4.75  \nAES_KEY_SIZE = 32  \nHASH_ALGORITHMS = [  \n    \"sha256\",  \n    \"sha512\",  \n    \"sha3_256\",  \n    \"sha3_512\"  \n]  \n# === UTILITIES ===  \ndef calculate_shannon_entropy(data: bytes) -> float:  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "AES_KEY_SIZE = 32  \nHASH_ALGORITHMS = [  \n    \"sha256\",  \n    \"sha512\",  \n    \"sha3_256\",  \n    \"sha3_512\"  \n]  \n# === UTILITIES ===  \ndef calculate_shannon_entropy(data: bytes) -> float:  \n    if not data:  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "HASH_ALGORITHMS",
        "kind": 5,
        "importPath": "ahev8benchmark",
        "description": "ahev8benchmark",
        "peekOfCode": "HASH_ALGORITHMS = [  \n    \"sha256\",  \n    \"sha512\",  \n    \"sha3_256\",  \n    \"sha3_512\"  \n]  \n# === UTILITIES ===  \ndef calculate_shannon_entropy(data: bytes) -> float:  \n    if not data:  \n        return 0.0  ",
        "detail": "ahev8benchmark",
        "documentation": {}
    },
    {
        "label": "calculate_entropy",
        "kind": 2,
        "importPath": "ahev9",
        "description": "ahev9",
        "peekOfCode": "def calculate_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef aes_encrypt(plaintext: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext.encode())\n    return {",
        "detail": "ahev9",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "ahev9",
        "description": "ahev9",
        "peekOfCode": "def aes_encrypt(plaintext: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),\n        \"nonce\": urlsafe_b64encode(nonce).decode(),\n        \"tag\": urlsafe_b64encode(tag).decode()\n    }\ndef aes_decrypt(bundle: dict, key: bytes) -> str:",
        "detail": "ahev9",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "ahev9",
        "description": "ahev9",
        "peekOfCode": "def aes_decrypt(bundle: dict, key: bytes) -> str:\n    nonce = urlsafe_b64decode(bundle[\"nonce\"])\n    tag = urlsafe_b64decode(bundle[\"tag\"])\n    ciphertext = urlsafe_b64decode(bundle[\"ciphertext\"])\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag).decode()\n# === Core AHE functions ===\ndef ahe_encrypt_v9(message: str) -> dict:\n    # 1. Entropy scoring\n    entropy_seed = os.urandom(16)",
        "detail": "ahev9",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v9",
        "kind": 2,
        "importPath": "ahev9",
        "description": "ahev9",
        "peekOfCode": "def ahe_encrypt_v9(message: str) -> dict:\n    # 1. Entropy scoring\n    entropy_seed = os.urandom(16)\n    entropy_score = calculate_entropy(entropy_seed)\n    #  Kyber512 KEM\n    kem_pk, kem_sk = kem_keypair()\n    kem_ct, kem_ss = kem_encaps(kem_pk)\n    # Derive AES key via HKDF\n    aes_key = HKDF(kem_ss, AES_KEY_SIZE, entropy_seed, SHA256)\n    aes_bundle = aes_encrypt(message, aes_key)",
        "detail": "ahev9",
        "documentation": {}
    },
    {
        "label": "ahe_decrypt_v9",
        "kind": 2,
        "importPath": "ahev9",
        "description": "ahev9",
        "peekOfCode": "def ahe_decrypt_v9(payload: dict) -> str:\n    entropy_seed = urlsafe_b64decode(payload[\"entropy_seed\"])\n    kem_ct = urlsafe_b64decode(payload[\"kem_ciphertext\"])\n    kem_sk = urlsafe_b64decode(payload[\"kem_secret_key\"])\n    kem_ss = kem_decaps(kem_ct, kem_sk)\n    aes_key = HKDF(kem_ss, AES_KEY_SIZE, entropy_seed, SHA256)\n    plaintext = aes_decrypt(payload[\"aes_bundle\"], aes_key)\n    fused = hashlib.blake2b(entropy_seed + plaintext.encode()).digest()\n    fused += bytes([sum(fused) % 127])\n    for algo in HASH_ALGOS:  # same order assumed",
        "detail": "ahev9",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ahev9",
        "description": "ahev9",
        "peekOfCode": "def main():\n    print(\"\\n Adaptive Hashing Encryption v9 with Kyber512 + Dilithium2\")\n    while True:\n        cmd = input(\"[E]ncrypt / [D]ecrypt / [Q]uit: \").strip().lower()\n        if cmd == \"e\":\n            msg = input(\"Enter message: \")\n            payload = ahe_encrypt_v9(msg)\n            print(\"\\n Payload:\")\n            print(payload)\n        elif cmd == \"d\":",
        "detail": "ahev9",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "ahev9",
        "description": "ahev9",
        "peekOfCode": "AES_KEY_SIZE = 32\nHASH_ALGOS = [\"sha3_512\", \"blake2b\", \"sha512\", \"sha3_256\"]\n# === Utility functions ===\ndef calculate_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef aes_encrypt(plaintext: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)",
        "detail": "ahev9",
        "documentation": {}
    },
    {
        "label": "HASH_ALGOS",
        "kind": 5,
        "importPath": "ahev9",
        "description": "ahev9",
        "peekOfCode": "HASH_ALGOS = [\"sha3_512\", \"blake2b\", \"sha512\", \"sha3_256\"]\n# === Utility functions ===\ndef calculate_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef aes_encrypt(plaintext: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)",
        "detail": "ahev9",
        "documentation": {}
    },
    {
        "label": "calculate_shannon_entropy",
        "kind": 2,
        "importPath": "ahe_7",
        "description": "ahe_7",
        "peekOfCode": "def calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +\n        str(platform.system()) +\n        str(platform.release()) +",
        "detail": "ahe_7",
        "documentation": {}
    },
    {
        "label": "get_environment_entropy",
        "kind": 2,
        "importPath": "ahe_7",
        "description": "ahe_7",
        "peekOfCode": "def get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +\n        str(platform.system()) +\n        str(platform.release()) +\n        str(os.cpu_count()) +\n        str(os.getpid()) +\n        str(time.time()) +\n        str(socket.gethostname())\n    ).encode()",
        "detail": "ahe_7",
        "documentation": {}
    },
    {
        "label": "generate_fractal_id",
        "kind": 2,
        "importPath": "ahe_7",
        "description": "ahe_7",
        "peekOfCode": "def generate_fractal_id() -> str:\n    now = datetime.datetime.now(datetime.UTC)\n    entropy = secrets.token_bytes(16)\n    return hashlib.blake2b(f\"{now.timestamp()}_{entropy.hex()}\".encode()).hexdigest()[:128]\ndef detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    suspicious_chars = \"0123456789+/=\\n\"\n    reasons = []\n    if any(c in input_data for c in suspicious_chars):\n        reasons.append(\"suspicious characters detected\")\n    if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:",
        "detail": "ahe_7",
        "documentation": {}
    },
    {
        "label": "detect_anomaly",
        "kind": 2,
        "importPath": "ahe_7",
        "description": "ahe_7",
        "peekOfCode": "def detect_anomaly(input_data: str, entropy_score: float) -> tuple:\n    suspicious_chars = \"0123456789+/=\\n\"\n    reasons = []\n    if any(c in input_data for c in suspicious_chars):\n        reasons.append(\"suspicious characters detected\")\n    if entropy_score < ENTROPY_WARN_THRESHOLD_LOW or entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:\n        reasons.append(\"entropy out of range\")\n    return (len(reasons) > 0), reasons\ndef hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)",
        "detail": "ahe_7",
        "documentation": {}
    },
    {
        "label": "hash_stage",
        "kind": 2,
        "importPath": "ahe_7",
        "description": "ahe_7",
        "peekOfCode": "def hash_stage(data: bytes, algo: str) -> bytes:\n    h = hashlib.new(algo)\n    h.update(data)\n    return h.digest()\ndef aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),",
        "detail": "ahe_7",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "ahe_7",
        "description": "ahe_7",
        "peekOfCode": "def aes_encrypt(message: str, key: bytes) -> dict:\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),\n        \"nonce\": urlsafe_b64encode(nonce).decode(),\n        \"tag\": urlsafe_b64encode(tag).decode()\n    }\ndef aes_decrypt(bundle: dict, key: bytes) -> str:",
        "detail": "ahe_7",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "ahe_7",
        "description": "ahe_7",
        "peekOfCode": "def aes_decrypt(bundle: dict, key: bytes) -> str:\n    nonce = urlsafe_b64decode(bundle[\"nonce\"])\n    tag = urlsafe_b64decode(bundle[\"tag\"])\n    ciphertext = urlsafe_b64decode(bundle[\"ciphertext\"])\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag).decode()\n# === AHE Core Encryption Function ===\ndef ahe_encrypt_v7_2(message: str) -> dict:\n    print(\"\\n AHE v7.2 :: Adaptive Encryption Begins\")\n    start_time = time.time()",
        "detail": "ahe_7",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt_v7_2",
        "kind": 2,
        "importPath": "ahe_7",
        "description": "ahe_7",
        "peekOfCode": "def ahe_encrypt_v7_2(message: str) -> dict:\n    print(\"\\n AHE v7.2 :: Adaptive Encryption Begins\")\n    start_time = time.time()\n    print(\"1 Reading user input and calculating input entropy...\")\n    input_bytes = message.encode()\n    input_entropy = calculate_shannon_entropy(input_bytes)\n    print(f\"    Input Entropy Score: {round(input_entropy, 4)}\")\n    print(\"2 Collecting system entropy for chrono-harmonic behavior...\")\n    system_entropy = get_environment_entropy()\n    system_entropy_score = calculate_shannon_entropy(system_entropy)",
        "detail": "ahe_7",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ahe_7",
        "description": "ahe_7",
        "peekOfCode": "def main():\n    print(\"\\n Welcome to Adaptive Hashing Encryption v7.2\\n\")\n    while True:\n        command = input(\" Enter text to encrypt, 'd' to decrypt, or 'exit': \").strip()\n        if command.lower() == \"exit\":\n            print(\" Exiting.\")\n            break\n        elif command.lower() == \"d\":\n            print(\" Decryption mode (manual input)...\")\n            aes_bundle = eval(input(\"    AES Bundle (as dict): \"))",
        "detail": "ahe_7",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_LOW",
        "kind": 5,
        "importPath": "ahe_7",
        "description": "ahe_7",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_LOW = 3.5\nENTROPY_WARN_THRESHOLD_HIGH = 4.75\nPBKDF2_ITERATIONS = 100_000\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}",
        "detail": "ahe_7",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_HIGH",
        "kind": 5,
        "importPath": "ahe_7",
        "description": "ahe_7",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_HIGH = 4.75\nPBKDF2_ITERATIONS = 100_000\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())",
        "detail": "ahe_7",
        "documentation": {}
    },
    {
        "label": "PBKDF2_ITERATIONS",
        "kind": 5,
        "importPath": "ahe_7",
        "description": "ahe_7",
        "peekOfCode": "PBKDF2_ITERATIONS = 100_000\nAES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:",
        "detail": "ahe_7",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "ahe_7",
        "description": "ahe_7",
        "peekOfCode": "AES_KEY_SIZE = 32\nHASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (",
        "detail": "ahe_7",
        "documentation": {}
    },
    {
        "label": "HASH_ALGORITHMS",
        "kind": 5,
        "importPath": "ahe_7",
        "description": "ahe_7",
        "peekOfCode": "HASH_ALGORITHMS = [\"sha3_512\", \"blake2b\", \"sha512\", \"blake2s\"]\n# === UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    return -sum(p * math.log2(p) for p in freq.values())\ndef get_environment_entropy() -> bytes:\n    raw = (\n        str(uuid.getnode()) +",
        "detail": "ahe_7",
        "documentation": {}
    },
    {
        "label": "derive_key",
        "kind": 2,
        "importPath": "ahe_appv1",
        "description": "ahe_appv1",
        "peekOfCode": "def derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    key = hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\n    print(f\"Derived key (SHA3-512 truncated): {key.hex()}\")\n    return key\ndef aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext_bytes)\n    print(f\"AES encrypt: nonce({len(nonce)} bytes), tag({len(tag)} bytes), ciphertext({len(ciphertext)} bytes)\")",
        "detail": "ahe_appv1",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "ahe_appv1",
        "description": "ahe_appv1",
        "peekOfCode": "def aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext_bytes)\n    print(f\"AES encrypt: nonce({len(nonce)} bytes), tag({len(tag)} bytes), ciphertext({len(ciphertext)} bytes)\")\n    return ciphertext, nonce, tag\ndef aes_decrypt(ciphertext, nonce, tag, key):\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    plaintext = cipher.decrypt_and_verify(ciphertext, tag)\n    print(f\"AES decrypt successful: plaintext length {len(plaintext)} bytes\")",
        "detail": "ahe_appv1",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "ahe_appv1",
        "description": "ahe_appv1",
        "peekOfCode": "def aes_decrypt(ciphertext, nonce, tag, key):\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    plaintext = cipher.decrypt_and_verify(ciphertext, tag)\n    print(f\"AES decrypt successful: plaintext length {len(plaintext)} bytes\")\n    return plaintext\ndef encrypt_file(filepath, password):\n    print(f\"\\n--- Encryption start for: {filepath} ---\")\n    start_time = time.time()\n    with open(filepath, \"rb\") as f:\n        plaintext = f.read()",
        "detail": "ahe_appv1",
        "documentation": {}
    },
    {
        "label": "encrypt_file",
        "kind": 2,
        "importPath": "ahe_appv1",
        "description": "ahe_appv1",
        "peekOfCode": "def encrypt_file(filepath, password):\n    print(f\"\\n--- Encryption start for: {filepath} ---\")\n    start_time = time.time()\n    with open(filepath, \"rb\") as f:\n        plaintext = f.read()\n    print(f\"Read plaintext: {len(plaintext)} bytes\")\n    kem_name = random.choice(PQC_KEMS)\n    print(f\"Selected PQC KEM: {kem_name}\")\n    kem = oqs.KeyEncapsulation(kem_name)\n    pubkey = kem.generate_keypair()",
        "detail": "ahe_appv1",
        "documentation": {}
    },
    {
        "label": "decrypt_file",
        "kind": 2,
        "importPath": "ahe_appv1",
        "description": "ahe_appv1",
        "peekOfCode": "def decrypt_file(enc_path, password):\n    print(f\"\\n--- Decryption start for: {enc_path} ---\")\n    start_time = time.time()\n    meta_path = enc_path.replace(ENC_EXT, META_EXT)\n    if not os.path.exists(meta_path):\n        raise FileNotFoundError(f\"Metadata file not found: {meta_path}\")\n    print(f\"Found metadata file: {meta_path}\")\n    with open(enc_path, \"rb\") as f:\n        ciphertext = f.read()\n    print(f\"Read ciphertext: {len(ciphertext)} bytes\")",
        "detail": "ahe_appv1",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ahe_appv1",
        "description": "ahe_appv1",
        "peekOfCode": "def main():\n    print(\"=== Adaptive Hashing Encryption v10.5 with Metrics ===\")\n    while True:\n        print(\"\\nOptions:\")\n        print(\"1. Encrypt a file\")\n        print(\"2. Decrypt a file\")\n        print(\"3. Exit\")\n        choice = input(\"Choice: \").strip()\n        if choice == \"1\":\n            path = input(\"File to encrypt: \").strip()",
        "detail": "ahe_appv1",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "ahe_appv1",
        "description": "ahe_appv1",
        "peekOfCode": "AES_KEY_SIZE = 32\nMETA_EXT = \".meta\"\nENC_EXT = \".ahe\"\nPQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\ndef derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    key = hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\n    print(f\"Derived key (SHA3-512 truncated): {key.hex()}\")\n    return key\ndef aes_encrypt(plaintext_bytes, key):",
        "detail": "ahe_appv1",
        "documentation": {}
    },
    {
        "label": "META_EXT",
        "kind": 5,
        "importPath": "ahe_appv1",
        "description": "ahe_appv1",
        "peekOfCode": "META_EXT = \".meta\"\nENC_EXT = \".ahe\"\nPQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\ndef derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    key = hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\n    print(f\"Derived key (SHA3-512 truncated): {key.hex()}\")\n    return key\ndef aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)",
        "detail": "ahe_appv1",
        "documentation": {}
    },
    {
        "label": "ENC_EXT",
        "kind": 5,
        "importPath": "ahe_appv1",
        "description": "ahe_appv1",
        "peekOfCode": "ENC_EXT = \".ahe\"\nPQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\ndef derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    key = hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\n    print(f\"Derived key (SHA3-512 truncated): {key.hex()}\")\n    return key\ndef aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)",
        "detail": "ahe_appv1",
        "documentation": {}
    },
    {
        "label": "PQC_KEMS",
        "kind": 5,
        "importPath": "ahe_appv1",
        "description": "ahe_appv1",
        "peekOfCode": "PQC_KEMS = [\"Kyber768\", \"Kyber512\", \"ML-KEM-768\"]\ndef derive_key(password_bytes, pubkey_bytes, ciphertext_bytes):\n    fusion = password_bytes + pubkey_bytes + ciphertext_bytes\n    key = hashlib.sha3_512(fusion).digest()[:AES_KEY_SIZE]\n    print(f\"Derived key (SHA3-512 truncated): {key.hex()}\")\n    return key\ndef aes_encrypt(plaintext_bytes, key):\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(plaintext_bytes)",
        "detail": "ahe_appv1",
        "documentation": {}
    },
    {
        "label": "calculate_shannon_entropy",
        "kind": 2,
        "importPath": "ahe_keygen",
        "description": "ahe_keygen",
        "peekOfCode": "def calculate_shannon_entropy(data: bytes) -> float:\n    \"\"\"\n    Calculate Shannon entropy of a byte string.\n    \"\"\"\n    if not data:\n        return 0.0\n    freq = {b: data.count(b) / len(data) for b in set(data)}\n    entropy = -sum(p * math.log2(p) for p in freq.values())\n    return entropy\ndef get_environment_entropy() -> bytes:",
        "detail": "ahe_keygen",
        "documentation": {}
    },
    {
        "label": "get_environment_entropy",
        "kind": 2,
        "importPath": "ahe_keygen",
        "description": "ahe_keygen",
        "peekOfCode": "def get_environment_entropy() -> bytes:\n    \"\"\"\n    Gather system/environment-specific entropy.\n    Combines device identifiers, OS info, time, hostname.\n    \"\"\"\n    raw = (\n        str(uuid.getnode()) +\n        str(platform.system()) +\n        str(platform.release()) +\n        str(os.cpu_count()) +",
        "detail": "ahe_keygen",
        "documentation": {}
    },
    {
        "label": "generate_fractal_id",
        "kind": 2,
        "importPath": "ahe_keygen",
        "description": "ahe_keygen",
        "peekOfCode": "def generate_fractal_id() -> str:\n    \"\"\"\n    Generate a unique fractal session ID for the encryption instance.\n    \"\"\"\n    now = datetime.datetime.now(datetime.UTC)\n    entropy = secrets.token_bytes(16)\n    data = f\"{now.timestamp()}_{entropy.hex()}\".encode()\n    return hashlib.blake2b(data).hexdigest()[:16]\ndef detect_anomaly(input_data: str, entropy_score: float) -> bool:\n    \"\"\"",
        "detail": "ahe_keygen",
        "documentation": {}
    },
    {
        "label": "detect_anomaly",
        "kind": 2,
        "importPath": "ahe_keygen",
        "description": "ahe_keygen",
        "peekOfCode": "def detect_anomaly(input_data: str, entropy_score: float) -> bool:\n    \"\"\"\n    Detect if the input is anomalous based on entropy and presence of\n    suspicious characters typical for encoded or gibberish data.\n    \"\"\"\n    suspicious_chars = \"0123456789+/=\\n\"\n    if entropy_score < ENTROPY_WARN_THRESHOLD_LOW:\n        return True\n    if entropy_score > ENTROPY_WARN_THRESHOLD_HIGH:\n        return True",
        "detail": "ahe_keygen",
        "documentation": {}
    },
    {
        "label": "hash_stage",
        "kind": 2,
        "importPath": "ahe_keygen",
        "description": "ahe_keygen",
        "peekOfCode": "def hash_stage(data: bytes, algo: str) -> bytes:\n    \"\"\"\n    Perform one stage of hashing using the specified algorithm.\n    \"\"\"\n    h = hashlib.new(algo)\n    h.update(data)\n    return h.digest()\n# === AES ENCRYPTION UTILITIES ===\ndef aes_encrypt(message: str, key: bytes) -> dict:\n    \"\"\"",
        "detail": "ahe_keygen",
        "documentation": {}
    },
    {
        "label": "aes_encrypt",
        "kind": 2,
        "importPath": "ahe_keygen",
        "description": "ahe_keygen",
        "peekOfCode": "def aes_encrypt(message: str, key: bytes) -> dict:\n    \"\"\"\n    Encrypt the message using AES-GCM with the given key.\n    Returns ciphertext, nonce, and tag, all base64 encoded.\n    \"\"\"\n    nonce = get_random_bytes(12)\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    ciphertext, tag = cipher.encrypt_and_digest(message.encode())\n    return {\n        \"ciphertext\": urlsafe_b64encode(ciphertext).decode(),",
        "detail": "ahe_keygen",
        "documentation": {}
    },
    {
        "label": "aes_decrypt",
        "kind": 2,
        "importPath": "ahe_keygen",
        "description": "ahe_keygen",
        "peekOfCode": "def aes_decrypt(bundle: dict, key: bytes) -> str:\n    \"\"\"\n    Decrypt AES-GCM encrypted bundle with the given key.\n    \"\"\"\n    nonce = urlsafe_b64decode(bundle[\"nonce\"])\n    tag = urlsafe_b64decode(bundle[\"tag\"])\n    ciphertext = urlsafe_b64decode(bundle[\"ciphertext\"])\n    cipher = AES.new(key, AES.MODE_GCM, nonce=nonce)\n    return cipher.decrypt_and_verify(ciphertext, tag).decode()\n# === MAIN AHE FUNCTION ===",
        "detail": "ahe_keygen",
        "documentation": {}
    },
    {
        "label": "ahe_encrypt",
        "kind": 2,
        "importPath": "ahe_keygen",
        "description": "ahe_keygen",
        "peekOfCode": "def ahe_encrypt(message: str) -> dict:\n    \"\"\"\n    Adaptive Hashing Encryption core:\n    - Calculate input entropy and anomaly detection\n    - Gather environment entropy\n    - Generate unique fractal session ID\n    - Multi-stage shuffled hashing combined with environment entropy\n    - Derive AES-GCM key from hash output + environment entropy\n    - Encrypt message with AES-GCM\n    - Print detailed verbose info in logical sequence",
        "detail": "ahe_keygen",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ahe_keygen",
        "description": "ahe_keygen",
        "peekOfCode": "def main():\n    print(\"\\n Adaptive Hashing Encryption v5.1 :: Fully Verbose Execution Mode ::\")\n    while True:\n        msg = input(\"\\n Enter message to encrypt (or 'exit'): \")\n        if msg.lower() == \"exit\":\n            print(\" Goodbye.\")\n            break\n        result = ahe_encrypt(msg)\n        print(\"\\n--- END OF SESSION ---\")\nif __name__ == \"__main__\":",
        "detail": "ahe_keygen",
        "documentation": {}
    },
    {
        "label": "MAX_INPUT_LENGTH",
        "kind": 5,
        "importPath": "ahe_keygen",
        "description": "ahe_keygen",
        "peekOfCode": "MAX_INPUT_LENGTH = 4096\nENTROPY_WARN_THRESHOLD_LOW = 3.5\nENTROPY_WARN_THRESHOLD_HIGH = 4.75\nPBKDF2_ITERATIONS = 200_000\nAES_KEY_SIZE = 32  # 256-bit AES key\nHASH_ALGORITHMS = [\n    \"sha3_512\",\n    \"blake2b\",\n    \"sha512\",\n    \"blake2s\"",
        "detail": "ahe_keygen",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_LOW",
        "kind": 5,
        "importPath": "ahe_keygen",
        "description": "ahe_keygen",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_LOW = 3.5\nENTROPY_WARN_THRESHOLD_HIGH = 4.75\nPBKDF2_ITERATIONS = 200_000\nAES_KEY_SIZE = 32  # 256-bit AES key\nHASH_ALGORITHMS = [\n    \"sha3_512\",\n    \"blake2b\",\n    \"sha512\",\n    \"blake2s\"\n]",
        "detail": "ahe_keygen",
        "documentation": {}
    },
    {
        "label": "ENTROPY_WARN_THRESHOLD_HIGH",
        "kind": 5,
        "importPath": "ahe_keygen",
        "description": "ahe_keygen",
        "peekOfCode": "ENTROPY_WARN_THRESHOLD_HIGH = 4.75\nPBKDF2_ITERATIONS = 200_000\nAES_KEY_SIZE = 32  # 256-bit AES key\nHASH_ALGORITHMS = [\n    \"sha3_512\",\n    \"blake2b\",\n    \"sha512\",\n    \"blake2s\"\n]\n# === ENTROPY UTILITIES ===",
        "detail": "ahe_keygen",
        "documentation": {}
    },
    {
        "label": "PBKDF2_ITERATIONS",
        "kind": 5,
        "importPath": "ahe_keygen",
        "description": "ahe_keygen",
        "peekOfCode": "PBKDF2_ITERATIONS = 200_000\nAES_KEY_SIZE = 32  # 256-bit AES key\nHASH_ALGORITHMS = [\n    \"sha3_512\",\n    \"blake2b\",\n    \"sha512\",\n    \"blake2s\"\n]\n# === ENTROPY UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:",
        "detail": "ahe_keygen",
        "documentation": {}
    },
    {
        "label": "AES_KEY_SIZE",
        "kind": 5,
        "importPath": "ahe_keygen",
        "description": "ahe_keygen",
        "peekOfCode": "AES_KEY_SIZE = 32  # 256-bit AES key\nHASH_ALGORITHMS = [\n    \"sha3_512\",\n    \"blake2b\",\n    \"sha512\",\n    \"blake2s\"\n]\n# === ENTROPY UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    \"\"\"",
        "detail": "ahe_keygen",
        "documentation": {}
    },
    {
        "label": "HASH_ALGORITHMS",
        "kind": 5,
        "importPath": "ahe_keygen",
        "description": "ahe_keygen",
        "peekOfCode": "HASH_ALGORITHMS = [\n    \"sha3_512\",\n    \"blake2b\",\n    \"sha512\",\n    \"blake2s\"\n]\n# === ENTROPY UTILITIES ===\ndef calculate_shannon_entropy(data: bytes) -> float:\n    \"\"\"\n    Calculate Shannon entropy of a byte string.",
        "detail": "ahe_keygen",
        "documentation": {}
    },
    {
        "label": "benchmark_kem",
        "kind": 2,
        "importPath": "metricstest",
        "description": "metricstest",
        "peekOfCode": "def benchmark_kem(kem_name):\n    print(f\"\\nBenchmarking KEM: {kem_name}\")\n    try:\n        with oqs.KeyEncapsulation(kem_name) as kem:\n            # Key generation timing\n            start = time.perf_counter()\n            public_key = kem.generate_keypair()\n            keygen_time = time.perf_counter() - start\n            # Encapsulation timing\n            start = time.perf_counter()",
        "detail": "metricstest",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "metricstest",
        "description": "metricstest",
        "peekOfCode": "def main():\n    for kem in selected_kems:\n        benchmark_kem(kem)\nif __name__ == \"__main__\":\n    main()",
        "detail": "metricstest",
        "documentation": {}
    },
    {
        "label": "selected_kems",
        "kind": 5,
        "importPath": "metricstest",
        "description": "metricstest",
        "peekOfCode": "selected_kems = [\n    \"Kyber512\",\n    \"Kyber768\",\n    \"Kyber1024\",\n    \"ML-KEM-512\",\n    \"ML-KEM-768\",\n    \"ML-KEM-1024\",\n    \"sntrup761\"\n]\ndef benchmark_kem(kem_name):",
        "detail": "metricstest",
        "documentation": {}
    },
    {
        "label": "create_file_if_not_exists",
        "kind": 2,
        "importPath": "sdk",
        "description": "sdk",
        "peekOfCode": "def create_file_if_not_exists(path):\n    if not os.path.exists(path):\n        with open(path, 'w') as f:\n            f.write(\"# Placeholder for \" + os.path.basename(path) + \"\\n\")\n        print(f\"Created file: {path}\")\n    else:\n        print(f\"File already exists: {path}\")\ndef create_sdk_v5_structure(base_path=\"AHE_SDK_v5\"):\n    structure = {\n        \"aes\": [\"aes.py\", \"utils.py\"],",
        "detail": "sdk",
        "documentation": {}
    },
    {
        "label": "create_sdk_v5_structure",
        "kind": 2,
        "importPath": "sdk",
        "description": "sdk",
        "peekOfCode": "def create_sdk_v5_structure(base_path=\"AHE_SDK_v5\"):\n    structure = {\n        \"aes\": [\"aes.py\", \"utils.py\"],\n        \"kdf\": [\"kdf.py\", \"utils.py\"],\n        \"pqc\": [\"pqc.py\", \"utils.py\"],\n        \"crypto\": [\"crypto.py\", \"utils.py\"],\n        \"core\": [\"core.py\", \"utils.py\"],\n        \"utils\": [\"entropy.py\", \"hashing.py\", \"anomaly.py\"]\n    }\n    # Create base folder",
        "detail": "sdk",
        "documentation": {}
    },
    {
        "label": "benchmark_kem",
        "kind": 2,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "def benchmark_kem(kem_name):\n    print(f\"\\nBenchmarking KEM: {kem_name}\")\n    try:\n        with oqs.KeyEncapsulation(kem_name) as kem:\n            # Try to generate keypair and handle unpacking robustly\n            keypair = kem.generate_keypair()\n            if isinstance(keypair, tuple) and len(keypair) == 2:\n                public_key, secret_key = keypair\n            else:\n                # If just public_key returned, secret_key is internal",
        "detail": "test",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "test",
        "description": "test",
        "peekOfCode": "def main():\n    # Use only enabled KEMs to avoid errors\n    enabled_kems = oqs.get_enabled_kem_mechanisms()\n    for kem in enabled_kems:\n        benchmark_kem(kem)\nif __name__ == \"__main__\":\n    main()",
        "detail": "test",
        "documentation": {}
    }
]